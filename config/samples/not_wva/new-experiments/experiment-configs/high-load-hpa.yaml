# High Load HPA Experiment Configuration
# Tests HPA under OVERLAPPING heavy load to force aggressive scaling
# Jobs run in parallel with staggered start times to create cumulative pressure
# Pattern: Job1 (0s) → Job2 (+120s, overlap with Job1) → Job3 (+120s, overlap with Job2)
# This creates sustained 40-50 req/s load periods to saturate pods and force scale-up

name: "high-load-hpa"
description: "HPA stress test with overlapping 20-30 req/s jobs to force scaling"
namespace: "llm-d-inference-scheduler"
deployment: "ms-inference-scheduling-llm-d-modelservice-decode"
model_name: "unsloth/Meta-Llama-3.1-8B"

hpa:
  enabled: true
  manifest: "../../manifests/hpa-vllm-combined.yaml"

jobs:
  - name: "phase-1-high-load"
    manifest: "../../workloads/sharegpt-load-job-high-20.yaml"  # 20 req/s
    duration: 900  # 15 minutes
    start_delay: 0  # Start immediately
    
  - name: "phase-2-peak-load"
    manifest: "../../workloads/sharegpt-load-job-high-30.yaml"  # 30 req/s
    duration: 900  # 15 minutes
    start_delay: 120  # Start 2min after experiment begins (780s overlap with phase-1)
    
  - name: "phase-3-sustained"
    manifest: "../../workloads/sharegpt-load-job-high-20.yaml"  # Back to 20 req/s
    duration: 900  # 15 minutes
    start_delay: 240  # Start 4min after experiment begins (780s overlap with phase-2)

# Timeline visualization:
# Time:    0s        120s       240s       360s       480s       600s       720s       840s       960s       1080s      1140s
# Job1:    [============================================================================================]  (20 req/s)
# Job2:              [============================================================================================]  (30 req/s)
# Job3:                         [============================================================================================]  (20 req/s)
# Load:    20        50         70         70         70         70         70         70         50         20         0
# 
# Expected behavior:
# - 0-120s: 20 req/s (single job, may not trigger scale-up)
# - 120-240s: 50 req/s (job1+job2, should saturate and trigger scale-up)
# - 240-900s: 70 req/s (all three jobs for 11 minutes, sustained very high load, should scale above 2)
# - 900-1020s: 50 req/s (job2+job3, sustained high load)
# - 1020-1140s: 20 req/s (job3 only, scale-down period)

metrics:
  interval: 5
  prometheus:
    ttft:
      query: 'sum(rate(vllm:time_to_first_token_seconds_sum{model_name="unsloth/Meta-Llama-3.1-8B",namespace="llm-d-inference-scheduler"}[1m]))/sum(rate(vllm:time_to_first_token_seconds_count{model_name="unsloth/Meta-Llama-3.1-8B",namespace="llm-d-inference-scheduler"}[1m])) * 1000'
    itl:
      query: 'sum(rate(vllm:time_per_output_token_seconds_sum{model_name="unsloth/Meta-Llama-3.1-8B",namespace="llm-d-inference-scheduler"}[1m]))/sum(rate(vllm:time_per_output_token_seconds_count{model_name="unsloth/Meta-Llama-3.1-8B",namespace="llm-d-inference-scheduler"}[1m])) * 1000'
    request_rate:
      query: 'sum(rate(vllm:request_success_total{model_name="unsloth/Meta-Llama-3.1-8B",namespace="llm-d-inference-scheduler"}[1m])) * 60'
    num_requests_waiting:
      query: 'vllm:num_requests_waiting{model_name="unsloth/Meta-Llama-3.1-8B",namespace="llm-d-inference-scheduler"}'
    kv_cache_usage:
      query: 'vllm:kv_cache_usage_perc{model_name="unsloth/Meta-Llama-3.1-8B",namespace="llm-d-inference-scheduler"}'

output:
  base_dir: "experiment-data"
  include_pod_logs: true
  include_events: true

# Observation period after jobs complete to capture scale-down behavior
cooldown:
  enabled: true
  duration: 180  # Monitor for 3 minutes after jobs complete to observe scale-down
