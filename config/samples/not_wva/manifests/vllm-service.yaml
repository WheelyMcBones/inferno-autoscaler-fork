apiVersion: v1
kind: Service
metadata:
  name: vllm-service
  namespace: llm-d-inference-scheduler
  labels:
    llm-d.ai/model: ms-inference-scheduling-llm-d-modelservice-decode
spec:
  type: ClusterIP
  ports:
  - name: vllm-api
    port: 8200
    targetPort: 8200
    protocol: TCP
  selector:
    llm-d.ai/model: ms-inference-scheduling-llm-d-modelservice
    llm-d.ai/role: decode
