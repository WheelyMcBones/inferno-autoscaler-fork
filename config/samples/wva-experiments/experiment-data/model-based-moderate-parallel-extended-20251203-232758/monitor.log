[0;32m[INFO][0m WVA Log Collector Started
[0;32m[INFO][0m Namespace: workload-variant-autoscaler-system
[0;32m[INFO][0m Pod prefix: workload-variant-autoscaler-controller-manager
[0;32m[INFO][0m Output: experiment-data/model-based-moderate-parallel-extended-20251203-232758/wva-controller-logs.jsonl
[0;32m[INFO][0m Poll interval: 5s

[0;32m[INFO][0m Finding WVA controller pod...
[0;32m[INFO][0m Found leader pod from lease: workload-variant-autoscaler-controller-manager-54c86c48c8-lt2fm

[0;32m[INFO][0m Creating new log file: experiment-data/model-based-moderate-parallel-extended-20251203-232758/wva-controller-logs.jsonl
[0;32m[INFO][0m Starting log collection (press Ctrl+C to stop)...

[0;32m[INFO][0m Collected 10 lines | Latest: Collected capacity metrics for observability in model-only mode: modelID=unsloth...
[0;32m[INFO][0m Collected 20 lines | Latest: Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.683155 16....
[0;32m[INFO][0m Collected 30 lines | Latest: Operating in MODEL-ONLY mode: model-based optimization only...
[0;32m[INFO][0m Collected 40 lines | Latest: Found SLO for model: model=unsloth/Meta-Llama-3.1-8B, class=Premium, slo-tpot=10...
[0;32m[INFO][0m Collected 50 lines | Latest: Model-based optimization completed for model: unsloth/Meta-Llama-3.1-8B - model-...
[0;32m[INFO][0m Collected 60 lines | Latest: Grouped VAs by model: modelCount=1, totalVAs=1...
[0;32m[INFO][0m Collected 70 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 80 lines | Latest: Capacity analysis unavailable, using model-based targets only: modelID=unsloth/M...
[0;32m[INFO][0m Collected 90 lines | Latest: Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1...
[0;32m[INFO][0m Collected 100 lines | Latest: Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=t...
[0;32m[INFO][0m Collected 110 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 120 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cb...
[0;32m[INFO][0m Collected 130 lines | Latest: Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-mo...
[0;32m[INFO][0m Collected 140 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 150 lines | Latest: Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namesp...
[0;32m[INFO][0m Collected 160 lines | Latest: [Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-i...
[0;32m[INFO][0m Collected 170 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 180 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cbk75...
[0;32m[INFO][0m Collected 190 lines | Latest: Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservic...
[0;32m[INFO][0m Collected 200 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 210 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cb...
[0;32m[INFO][0m Collected 220 lines | Latest: Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservic...
[0;32m[INFO][0m Collected 230 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 240 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cbk75...
[0;32m[INFO][0m Collected 250 lines | Latest: Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservic...
[0;32m[INFO][0m Collected 260 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 270 lines | Latest: KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, nam...
[0;32m[INFO][0m Collected 280 lines | Latest: Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-mo...
[0;32m[INFO][0m Collected 290 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 300 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cjqdq...
[0;32m[INFO][0m Collected 310 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 320 lines | Latest: Model-based optimization completed for model: unsloth/Meta-Llama-3.1-8B - model-...
[0;32m[INFO][0m Collected 330 lines | Latest: Grouped VAs by model: modelCount=1, totalVAs=1...
[0;32m[INFO][0m Collected 340 lines | Latest: Collected capacity metrics for observability in model-only mode: modelID=unsloth...
[0;32m[INFO][0m Collected 350 lines | Latest: Optimization solution - system: Solution: 
s=ms-inference-scheduling-llm-d-model...
[0;32m[INFO][0m Collected 360 lines | Latest: Reconciliation completed successfully: mode=model-only, modelsProcessed=1, decis...
[0;32m[INFO][0m Collected 370 lines | Latest: Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 380 lines | Latest: Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-deco...
[0;32m[INFO][0m Collected 390 lines | Latest: Successfully emitted metrics for external autoscalers: variant=ms-inference-sche...
[0;32m[INFO][0m Collected 400 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cxzkb...
[0;32m[INFO][0m Collected 410 lines | Latest: Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-mo...
[0;32m[INFO][0m Collected 420 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 430 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cj...
[0;32m[INFO][0m Collected 440 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 450 lines | Latest: Model-based optimization completed for model: unsloth/Meta-Llama-3.1-8B - model-...
[0;32m[INFO][0m Collected 460 lines | Latest: Grouped VAs by model: modelCount=1, totalVAs=1...
[0;32m[INFO][0m Collected 470 lines | Latest: Collected capacity metrics for observability in model-only mode: modelID=unsloth...
[0;32m[INFO][0m Collected 480 lines | Latest: Optimization solution - system: Solution: 
s=ms-inference-scheduling-llm-d-model...
[0;32m[INFO][0m Collected 490 lines | Latest: Reconciliation completed successfully: mode=model-only, modelsProcessed=1, decis...
[0;32m[INFO][0m Collected 500 lines | Latest: Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 510 lines | Latest: Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-deco...
[0;32m[INFO][0m Collected 520 lines | Latest: Successfully emitted metrics for external autoscalers: variant=ms-inference-sche...
[0;32m[INFO][0m Collected 530 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cjqdq...
[0;32m[INFO][0m Collected 540 lines | Latest: Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-mo...
[0;32m[INFO][0m Collected 550 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 560 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cj...
[0;32m[INFO][0m Collected 570 lines | Latest: Collected capacity metrics for observability in model-only mode: modelID=unsloth...
[0;32m[INFO][0m Collected 580 lines | Latest: Optimization solution - system: Solution: 
s=ms-inference-scheduling-llm-d-model...
[0;32m[INFO][0m Collected 590 lines | Latest: Reconciliation completed successfully: mode=model-only, modelsProcessed=1, decis...
[0;32m[INFO][0m Collected 600 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cwmkb...
[0;32m[INFO][0m Collected 610 lines | Latest: Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservic...
[0;32m[INFO][0m Collected 620 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 630 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cw...
[0;32m[INFO][0m Collected 640 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 650 lines | Latest: Model-based optimization completed for model: unsloth/Meta-Llama-3.1-8B - model-...
[0;32m[INFO][0m Collected 660 lines | Latest: Grouped VAs by model: modelCount=1, totalVAs=1...
[0;32m[INFO][0m Collected 670 lines | Latest: Pod-to-variant matching successful: totalPods=3, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 680 lines | Latest: Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-deco...
[0;32m[INFO][0m Collected 690 lines | Latest: Successfully emitted metrics for external autoscalers: variant=ms-inference-sche...
[0;32m[INFO][0m Collected 700 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cj...
[0;32m[INFO][0m Collected 710 lines | Latest: Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-mo...
[0;32m[INFO][0m Collected 720 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 730 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cj...
[0;32m[INFO][0m Collected 740 lines | Latest: Collected capacity metrics for observability in model-only mode: modelID=unsloth...
[0;32m[INFO][0m Collected 750 lines | Latest: Optimization solution - system: Solution: 
s=ms-inference-scheduling-llm-d-model...
[0;32m[INFO][0m Collected 760 lines | Latest: Reconciliation completed successfully: mode=model-only, modelsProcessed=1, decis...
[0;32m[INFO][0m Collected 770 lines | Latest: Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 780 lines | Latest: Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-deco...
[0;32m[INFO][0m Collected 790 lines | Latest: Successfully emitted metrics for external autoscalers: variant=ms-inference-sche...
[0;32m[INFO][0m Collected 800 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-666b5f4cbk75...
[0;32m[INFO][0m Collected 810 lines | Latest: Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservic...
[0;32m[INFO][0m Collected 820 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Stopping log collection. Collected 824 log lines.
[0;32m[INFO][0m Stopping log collection. Collected 824 log lines.
