[0;32m[INFO][0m WVA Log Collector Started
[0;32m[INFO][0m Namespace: workload-variant-autoscaler-system
[0;32m[INFO][0m Pod prefix: workload-variant-autoscaler-controller-manager
[0;32m[INFO][0m Output: ./experiment-data/capacity-based-high-parallel-20251128-152808/wva-controller-logs.jsonl
[0;32m[INFO][0m Poll interval: 5s

[0;32m[INFO][0m Finding WVA controller pod...
[0;32m[INFO][0m Found leader pod from lease: workload-variant-autoscaler-controller-manager-6bbb5b4846-s2vq2

[0;32m[INFO][0m Creating new log file: ./experiment-data/capacity-based-high-parallel-20251128-152808/wva-controller-logs.jsonl
[0;32m[INFO][0m Starting log collection (press Ctrl+C to stop)...

[0;32m[INFO][0m Collected 10 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 20 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 30 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 40 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 50 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 60 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 70 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 80 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 90 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 100 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 110 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 120 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 130 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 140 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 150 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 160 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 170 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 180 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 190 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 200 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 210 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 220 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 230 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 240 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 250 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 260 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 270 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 280 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 290 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 300 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 310 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 320 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 330 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 340 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 350 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 360 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 370 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 380 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 390 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 400 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 410 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 420 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 430 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 440 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 450 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 460 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 470 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 480 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 490 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 500 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 510 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 520 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 530 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 540 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 550 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 560 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 570 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 580 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 590 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 600 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 610 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 620 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 630 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 640 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 650 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 660 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 670 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 680 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 690 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 700 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 710 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 720 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 730 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 740 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 750 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 760 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 770 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 780 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 790 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 800 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 810 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 820 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 830 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 840 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 850 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 860 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 870 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 880 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 890 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 900 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 910 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 920 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 930 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 940 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 950 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 960 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 970 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 980 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 990 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1,...
[0;32m[INFO][0m Collected 1000 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 1010 lines | Latest: KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, nam...
[0;32m[INFO][0m Collected 1020 lines | Latest: Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision cou...
[0;32m[INFO][0m Collected 1030 lines | Latest: Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1...
[0;32m[INFO][0m Collected 1040 lines | Latest: Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-i...
[0;32m[INFO][0m Collected 1050 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 1060 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 1070 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 1080 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 1090 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 1100 lines | Latest: Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-i...
[0;32m[INFO][0m Collected 1110 lines | Latest: Grouped VAs by model: modelCount=1, totalVAs=1...
[0;32m[INFO][0m Collected 1120 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 1130 lines | Latest: Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, ...
[0;32m[INFO][0m Collected 1140 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9x...
[0;32m[INFO][0m Collected 1150 lines | Latest: Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required...
[0;32m[INFO][0m Collected 1160 lines | Latest: Successfully emitted metrics for external autoscalers: variant=ms-inference-sche...
[0;32m[INFO][0m Collected 1170 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9x...
[0;32m[INFO][0m Collected 1180 lines | Latest: Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-...
[0;32m[INFO][0m Collected 1190 lines | Latest: Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only...
[0;32m[INFO][0m Collected 1200 lines | Latest: Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 1210 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1220 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1230 lines | Latest: Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice...
[0;32m[INFO][0m Collected 1240 lines | Latest: EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservi...
[0;32m[INFO][0m Collected 1250 lines | Latest: Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namesp...
[0;32m[INFO][0m Collected 1260 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2,...
[0;32m[INFO][0m Collected 1270 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 1280 lines | Latest: KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, nam...
[0;32m[INFO][0m Collected 1290 lines | Latest: Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision cou...
[0;32m[INFO][0m Collected 1300 lines | Latest: Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1...
[0;32m[INFO][0m Collected 1310 lines | Latest: Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-i...
[0;32m[INFO][0m Collected 1320 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 1330 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f92j4j...
[0;32m[INFO][0m Collected 1340 lines | Latest: Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice...
[0;32m[INFO][0m Collected 1350 lines | Latest: EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservi...
[0;32m[INFO][0m Collected 1360 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76m...
[0;32m[INFO][0m Collected 1370 lines | Latest: Scale-down unsafe: insufficient headroom after redistribution: remainingSpareKv=...
[0;32m[INFO][0m Collected 1380 lines | Latest: Successfully emitted metrics for external autoscalers: variant=ms-inference-sche...
[0;32m[INFO][0m Collected 1390 lines | Latest: Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namesp...
[0;32m[INFO][0m Collected 1400 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=3,...
[0;32m[INFO][0m Collected 1410 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 1420 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f92j4j...
[0;32m[INFO][0m Collected 1430 lines | Latest: Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-i...
[0;32m[INFO][0m Collected 1440 lines | Latest: Grouped VAs by model: modelCount=1, totalVAs=1...
[0;32m[INFO][0m Collected 1450 lines | Latest: KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, nam...
[0;32m[INFO][0m Collected 1460 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1470 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1480 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 1490 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 1500 lines | Latest: Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f92j4j...
[0;32m[INFO][0m Collected 1510 lines | Latest: Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice...
[0;32m[INFO][0m Collected 1520 lines | Latest: Successfully emitted metrics for external autoscalers: variant=ms-inference-sche...
[0;32m[INFO][0m Collected 1530 lines | Latest: Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namesp...
[0;32m[INFO][0m Collected 1540 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=3,...
[0;32m[INFO][0m Collected 1550 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 1560 lines | Latest: KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, nam...
[0;32m[INFO][0m Collected 1570 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1580 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1590 lines | Latest: Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice...
[0;32m[INFO][0m Collected 1600 lines | Latest: Successfully emitted metrics for external autoscalers: variant=ms-inference-sche...
[0;32m[INFO][0m Collected 1610 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9x...
[0;32m[INFO][0m Collected 1620 lines | Latest: Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-i...
[0;32m[INFO][0m Collected 1630 lines | Latest: Grouped VAs by model: modelCount=1, totalVAs=1...
[0;32m[INFO][0m Collected 1640 lines | Latest: Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-in...
[0;32m[INFO][0m Collected 1650 lines | Latest: Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasC...
[0;32m[INFO][0m Collected 1660 lines | Latest: KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l...
[0;32m[INFO][0m Collected 1670 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2,...
[0;32m[INFO][0m Collected 1680 lines | Latest: Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, de...
[0;32m[INFO][0m Collected 1690 lines | Latest: Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namesp...
[0;32m[INFO][0m Collected 1700 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1710 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1720 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 1730 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 1740 lines | Latest: Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 1750 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1760 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1770 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 1780 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 1790 lines | Latest: Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 1800 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1810 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1820 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 1830 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 1840 lines | Latest: Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 1850 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1860 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1870 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 1880 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 1890 lines | Latest: Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 1900 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1910 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1920 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 1930 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 1940 lines | Latest: Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 1950 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 1960 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 1970 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 1980 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 1990 lines | Latest: Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 2000 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 2010 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 2020 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 2030 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 2040 lines | Latest: Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 2050 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Collected 2060 lines | Latest: Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-dec...
[0;32m[INFO][0m Collected 2070 lines | Latest: Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-...
[0;32m[INFO][0m Collected 2080 lines | Latest: Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-de...
[0;32m[INFO][0m Collected 2090 lines | Latest: Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-...
[0;32m[INFO][0m Collected 2100 lines | Latest: Applying scaling decisions: totalDecisions=1...
[0;32m[INFO][0m Stopping log collection. Collected 2106 log lines.
[0;32m[INFO][0m Stopping log collection. Collected 2106 log lines.
