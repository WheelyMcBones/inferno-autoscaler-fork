{"level":"INFO","ts":"2025-12-09T20:58:35.024Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T20:58:35.024Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T20:58:35.024Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T20:58:35.024Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T20:58:35.024Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T20:58:35.024Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T20:58:35.044Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T20:58:35.045Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.045Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T20:58:35.045Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.045Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T20:58:35.047Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T20:58:35.047Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T20:58:35.047Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T20:58:35.047Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T20:58:35.047Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T20:58:35.047Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T20:58:35.047Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T20:58:35.052Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T20:58:35.052Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T20:59:35.052Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T20:59:35.052Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T20:59:35.052Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T20:59:35.052Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T20:59:35.052Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T20:59:35.052Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T20:59:35.070Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T20:59:35.071Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.071Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T20:59:35.072Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.072Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T20:59:35.073Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T20:59:35.073Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T20:59:35.073Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T20:59:35.073Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T20:59:35.073Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T20:59:35.073Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T20:59:35.073Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T20:59:35.079Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T20:59:35.079Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:00:35.080Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:00:35.080Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:00:35.080Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:00:35.080Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:00:35.080Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:00:35.080Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:00:35.104Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T21:00:35.106Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.106Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:00:35.106Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.106Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:00:35.108Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:00:35.108Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:00:35.108Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:00:35.108Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:00:35.108Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:00:35.108Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:00:35.108Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:00:35.112Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:00:35.112Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:01:35.113Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:01:35.113Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:01:35.113Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:01:35.113Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:01:35.113Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:01:35.113Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:01:35.130Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T21:01:35.132Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.132Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:01:35.132Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.132Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:01:35.133Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:01:35.133Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:01:35.133Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:01:35.133Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:01:35.133Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:01:35.133Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:01:35.133Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:01:35.138Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:01:35.138Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:02:35.139Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:02:35.139Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:02:35.139Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:02:35.139Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:02:35.139Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:02:35.139Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:02:35.161Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T21:02:35.163Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.163Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:02:35.163Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.163Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:02:35.164Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:02:35.164Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:02:35.164Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:02:35.164Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:02:35.164Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:02:35.164Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:02:35.164Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:02:35.171Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:02:35.171Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:03:35.172Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:03:35.172Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:03:35.172Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:03:35.172Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:03:35.172Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:03:35.172Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:03:35.187Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T21:03:35.190Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.190Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:03:35.190Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.190Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:03:35.192Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:03:35.192Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:03:35.192Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:03:35.192Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:03:35.192Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:03:35.192Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:03:35.192Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:03:35.197Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:03:35.197Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:04:35.198Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:04:35.198Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:04:35.198Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:04:35.198Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:04:35.198Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:04:35.198Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:04:35.218Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.27ms, itl=8.34ms, cost=10.00, arrivalRate=324.98"}
{"level":"INFO","ts":"2025-12-09T21:04:35.220Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.069 (6.9%)"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.220Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:04:35.220Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.220Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.431, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:04:35.222Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.431, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:04:35.222Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:04:35.222Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:04:35.222Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:04:35.222Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:04:35.222Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:04:35.222Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:04:35.226Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:04:35.226Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:05:35.227Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:05:35.227Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:05:35.227Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:05:35.227Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:05:35.227Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:05:35.227Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:05:35.249Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=18.83ms, itl=10.16ms, cost=10.00, arrivalRate=727.84"}
{"level":"INFO","ts":"2025-12-09T21:05:35.250Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.134 (13.4%)"}
{"level":"INFO","ts":"2025-12-09T21:05:35.250Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.250Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.250Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.251Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.251Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.251Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.251Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.251Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.251Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.366, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:05:35.251Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.251Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.251Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.366, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:05:35.252Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:05:35.252Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:05:35.252Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:05:35.252Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:05:35.252Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:05:35.252Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:05:35.256Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:05:35.256Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:06:35.257Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:06:35.257Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:06:35.257Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:06:35.257Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:06:35.257Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:06:35.257Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:06:35.278Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=35.42ms, itl=19.94ms, cost=10.00, arrivalRate=1286.48"}
{"level":"INFO","ts":"2025-12-09T21:06:35.279Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.279Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:06:35.279Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.400 (40.0%)"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.279Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.100, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:06:35.281Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.100, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:06:35.281Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:06:35.281Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:06:35.281Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:06:35.281Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:06:35.281Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:06:35.281Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:06:35.286Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:06:35.286Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:07:35.287Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:07:35.287Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:07:35.287Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:07:35.287Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:07:35.287Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:07:35.287Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:07:35.308Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=51.00ms, itl=30.70ms, cost=10.00, arrivalRate=1575.20"}
{"level":"INFO","ts":"2025-12-09T21:07:35.310Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.310Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:07:35.310Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.504 (50.4%)"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.310Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.312Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.312Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.312Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.312Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.312Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.312Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:07:35.312Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.312Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"INFO","ts":"2025-12-09T21:07:35.312Z","msg":"Saturation target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=1, readyReplicas=1, baseTarget=1, target=2, reason=both KV spare (0.000 < 0.100) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-12-09T21:07:35.312Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T21:07:35.312Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:07:35.312Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:07:35.312Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-up, current=1→target=2"}
{"level":"INFO","ts":"2025-12-09T21:07:35.312Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:07:35.312Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:07:35.316Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-up, current=1, target=2, reason=saturation-only mode: scale-up"}
{"level":"INFO","ts":"2025-12-09T21:07:35.316Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:08:35.317Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:08:35.317Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:08:35.317Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:08:35.317Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:08:35.317Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:08:35.317Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.339Z","msg":"Replica count mismatch for llm-d-inference-scheduler/unsloth/Meta-Llama-3.1-8B: spec=2, reporting_metrics=1"}
{"level":"INFO","ts":"2025-12-09T21:08:35.339Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=68.74ms, itl=41.80ms, cost=10.00, arrivalRate=1567.14"}
{"level":"INFO","ts":"2025-12-09T21:08:35.340Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.724 (72.4%)"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.340Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:08:35.340Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.340Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.342Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.342Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.342Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.342Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.342Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.342Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:08:35.342Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.342Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"INFO","ts":"2025-12-09T21:08:35.342Z","msg":"Saturation target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, baseTarget=1, target=2, reason=both KV spare (0.000 < 0.100) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-12-09T21:08:35.342Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T21:08:35.342Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:08:35.342Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:08:35.342Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"INFO","ts":"2025-12-09T21:08:35.342Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:08:35.342Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:08:35.556Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:08:35.556Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:09:35.557Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:09:35.557Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:09:35.557Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:09:35.557Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:09:35.557Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:09:35.557Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.576Z","msg":"Replica count mismatch for llm-d-inference-scheduler/unsloth/Meta-Llama-3.1-8B: spec=2, reporting_metrics=1"}
{"level":"INFO","ts":"2025-12-09T21:09:35.576Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=86.45ms, itl=53.92ms, cost=10.00, arrivalRate=1567.14"}
{"level":"INFO","ts":"2025-12-09T21:09:35.578Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.948 (94.8%)"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.578Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:09:35.578Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.578Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.580Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.580Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.580Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.580Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.580Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.580Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:09:35.580Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.580Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"INFO","ts":"2025-12-09T21:09:35.580Z","msg":"Saturation target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, baseTarget=1, target=2, reason=both KV spare (0.000 < 0.100) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-12-09T21:09:35.580Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T21:09:35.580Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:09:35.580Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:09:35.580Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"INFO","ts":"2025-12-09T21:09:35.580Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:09:35.580Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:09:35.585Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:09:35.585Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:10:35.588Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:10:35.588Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:10:35.588Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:10:35.588Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:10:35.589Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:10:35.589Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:10:35.622Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=122.13ms, itl=43.82ms, cost=20.00, arrivalRate=1915.49"}
{"level":"INFO","ts":"2025-12-09T21:10:35.623Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.989 (98.9%)"}
{"level":"INFO","ts":"2025-12-09T21:10:35.623Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dsqkm4, usage=0.045 (4.5%)"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.623Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-12-09T21:10:35.624Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=55"}
{"level":"INFO","ts":"2025-12-09T21:10:35.624Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dsqkm4, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.624Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=2, matched=2"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=1, avgSpareKv=0.455, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:10:35.626Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=2"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.455, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:10:35.626Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T21:10:35.626Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:10:35.626Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:10:35.626Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"INFO","ts":"2025-12-09T21:10:35.626Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:10:35.626Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:10:35.630Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:10:35.630Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:11:35.631Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:11:35.631Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:11:35.631Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:11:35.631Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:11:35.631Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:11:35.631Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:11:35.649Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=28.83ms, itl=16.19ms, cost=20.00, arrivalRate=2103.48"}
{"level":"INFO","ts":"2025-12-09T21:11:35.650Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"INFO","ts":"2025-12-09T21:11:35.650Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dsqkm4, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.650Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-12-09T21:11:35.650Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.569 (56.9%)"}
{"level":"INFO","ts":"2025-12-09T21:11:35.650Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dsqkm4, usage=0.077 (7.7%)"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.650Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=2, matched=2"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=1, avgSpareKv=0.423, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:11:35.652Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=2"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.423, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:11:35.652Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T21:11:35.652Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:11:35.652Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:11:35.652Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"INFO","ts":"2025-12-09T21:11:35.652Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:11:35.652Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:11:35.657Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:11:35.657Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:12:35.658Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:12:35.658Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:12:35.658Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:12:35.658Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:12:35.658Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:12:35.658Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:12:35.682Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=17.17ms, itl=8.62ms, cost=20.00, arrivalRate=947.29"}
{"level":"INFO","ts":"2025-12-09T21:12:35.684Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.083 (8.3%)"}
{"level":"INFO","ts":"2025-12-09T21:12:35.684Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dsqkm4, usage=0.048 (4.8%)"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.684Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-12-09T21:12:35.684Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"INFO","ts":"2025-12-09T21:12:35.684Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dsqkm4, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.684Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.686Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=2, matched=2"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.686Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.686Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.686Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.686Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.435, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-12-09T21:12:35.686Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.686Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=2"}
{"level":"INFO","ts":"2025-12-09T21:12:35.686Z","msg":"Saturation target: scale-down most expensive variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=2, baseTarget=2, target=1"}
{"level":"DEBUG","ts":"2025-12-09T21:12:35.686Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:12:35.686Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:12:35.686Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:12:35.686Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-down, current=2→target=1"}
{"level":"INFO","ts":"2025-12-09T21:12:35.686Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:12:35.686Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:12:35.691Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-down, current=2, target=1, reason=saturation-only mode: scale-down"}
{"level":"INFO","ts":"2025-12-09T21:12:35.691Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:13:35.692Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:13:35.692Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:13:35.692Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:13:35.692Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:13:35.692Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:13:35.692Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:13:35.707Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=19.06ms, itl=9.93ms, cost=10.00, arrivalRate=738.59"}
{"level":"INFO","ts":"2025-12-09T21:13:35.709Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.709Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:13:35.709Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.091 (9.1%)"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.709Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.409, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:13:35.710Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.409, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:13:35.710Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:13:35.710Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:13:35.710Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:13:35.710Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:13:35.710Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:13:35.710Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:13:35.716Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:13:35.716Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:14:35.716Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:14:35.716Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:14:35.716Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:14:35.716Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:14:35.716Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:14:35.716Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:14:35.736Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.68ms, itl=10.49ms, cost=10.00, arrivalRate=813.79"}
{"level":"INFO","ts":"2025-12-09T21:14:35.737Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.737Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:14:35.737Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.112 (11.2%)"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.737Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.388, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:14:35.739Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.388, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:14:35.739Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:14:35.739Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:14:35.739Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:14:35.739Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:14:35.739Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:14:35.739Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:14:35.744Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:14:35.744Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:15:35.744Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:15:35.745Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:15:35.745Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:15:35.745Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:15:35.745Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:15:35.745Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:15:35.761Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=20.77ms, itl=10.38ms, cost=10.00, arrivalRate=827.22"}
{"level":"INFO","ts":"2025-12-09T21:15:35.762Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.089 (8.9%)"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.762Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:15:35.762Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.762Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.411, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:15:35.764Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.411, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:15:35.764Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:15:35.764Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:15:35.764Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:15:35.764Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:15:35.764Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:15:35.764Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:15:35.769Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:15:35.769Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:16:35.770Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:16:35.770Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:16:35.770Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:16:35.770Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:16:35.770Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:16:35.770Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:16:35.795Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=20.79ms, itl=10.34ms, cost=10.00, arrivalRate=833.93"}
{"level":"INFO","ts":"2025-12-09T21:16:35.796Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.796Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:16:35.796Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.094 (9.4%)"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.796Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.406, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:16:35.798Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.406, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:16:35.798Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:16:35.798Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:16:35.798Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:16:35.798Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:16:35.798Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:16:35.798Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:16:35.803Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:16:35.803Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:17:35.803Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:17:35.804Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:17:35.804Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:17:35.804Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:17:35.804Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:17:35.804Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:17:35.821Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.27ms, itl=10.51ms, cost=10.00, arrivalRate=813.79"}
{"level":"INFO","ts":"2025-12-09T21:17:35.822Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.102 (10.2%)"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.822Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:17:35.822Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.822Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.398, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:17:35.824Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.398, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:17:35.824Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:17:35.824Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:17:35.824Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:17:35.824Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:17:35.824Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:17:35.824Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:17:35.829Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:17:35.829Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:18:35.829Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:18:35.830Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:18:35.830Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:18:35.830Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:18:35.830Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:18:35.830Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:18:35.853Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.95ms, itl=10.92ms, cost=10.00, arrivalRate=844.67"}
{"level":"INFO","ts":"2025-12-09T21:18:35.854Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.104 (10.4%)"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.854Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:18:35.854Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.854Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.396, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:18:35.856Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.396, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:18:35.856Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:18:35.856Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:18:35.856Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:18:35.856Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:18:35.856Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:18:35.856Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:18:35.862Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:18:35.862Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:19:35.863Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:19:35.863Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:19:35.863Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:19:35.863Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:19:35.863Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:19:35.863Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:19:35.879Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=22.25ms, itl=10.73ms, cost=10.00, arrivalRate=852.73"}
{"level":"INFO","ts":"2025-12-09T21:19:35.881Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.881Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:19:35.881Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.096 (9.6%)"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.881Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.404, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:19:35.883Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.404, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:19:35.883Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:19:35.883Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:19:35.883Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:19:35.883Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:19:35.883Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:19:35.883Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:19:35.889Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:19:35.889Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:20:35.892Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:20:35.892Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:20:35.892Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:20:35.892Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:20:35.893Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:20:35.893Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:20:35.915Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.39ms, itl=10.30ms, cost=10.00, arrivalRate=807.07"}
{"level":"INFO","ts":"2025-12-09T21:20:35.916Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.098 (9.8%)"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.916Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:20:35.916Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.916Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.402, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:20:35.918Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.402, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:20:35.918Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:20:35.918Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:20:35.918Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:20:35.918Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:20:35.918Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:20:35.918Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:20:35.927Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:20:35.927Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:21:35.927Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:21:35.928Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:21:35.928Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:21:35.928Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:21:35.928Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:21:35.928Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:21:35.943Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=20.46ms, itl=9.87ms, cost=10.00, arrivalRate=765.44"}
{"level":"INFO","ts":"2025-12-09T21:21:35.944Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.067 (6.7%)"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.944Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:21:35.944Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.944Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.433, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:21:35.946Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.433, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:21:35.946Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:21:35.946Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:21:35.946Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:21:35.946Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:21:35.946Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:21:35.946Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:21:35.951Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:21:35.951Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:22:35.951Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:22:35.951Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:22:35.951Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:22:35.951Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:22:35.951Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:22:35.951Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:22:35.972Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.03ms, itl=10.10ms, cost=10.00, arrivalRate=781.56"}
{"level":"INFO","ts":"2025-12-09T21:22:35.974Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.103 (10.3%)"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.974Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:22:35.974Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.974Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.397, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:22:35.975Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.397, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:22:35.975Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:22:35.975Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:22:35.975Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:22:35.975Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:22:35.975Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:22:35.975Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:22:35.980Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:22:35.980Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:23:35.980Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:23:35.980Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:23:35.980Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:23:35.980Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:23:35.981Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:23:35.981Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:23:35.995Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.91ms, itl=8.82ms, cost=10.00, arrivalRate=479.41"}
{"level":"INFO","ts":"2025-12-09T21:23:35.997Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.997Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:23:35.997Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.094 (9.4%)"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.997Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.406, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:23:35.998Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.406, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:23:35.998Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:23:35.998Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:23:35.998Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:23:35.998Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:23:35.998Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:23:35.998Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:23:36.003Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:23:36.003Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:24:36.003Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:24:36.003Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:24:36.003Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:24:36.003Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:24:36.003Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:24:36.003Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:24:36.023Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=18.03ms, itl=8.35ms, cost=10.00, arrivalRate=440.47"}
{"level":"INFO","ts":"2025-12-09T21:24:36.024Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.043 (4.3%)"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.024Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:24:36.024Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.024Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.025Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.025Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.025Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.025Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.025Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.025Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.457, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:24:36.025Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.025Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.026Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.457, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:24:36.026Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:24:36.026Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:24:36.026Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:24:36.026Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:24:36.026Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:24:36.026Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:24:36.031Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:24:36.031Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:25:36.032Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:25:36.032Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:25:36.032Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:25:36.032Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:25:36.032Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:25:36.032Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:25:36.047Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.46ms, itl=7.99ms, cost=10.00, arrivalRate=362.58"}
{"level":"INFO","ts":"2025-12-09T21:25:36.048Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.048Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:25:36.048Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.036 (3.6%)"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.048Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.464, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:25:36.050Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.464, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:25:36.050Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:25:36.050Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:25:36.050Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:25:36.050Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:25:36.050Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:25:36.050Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:25:36.054Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:25:36.054Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:26:36.055Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:26:36.055Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:26:36.055Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:26:36.055Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:26:36.055Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:26:36.055Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:26:36.079Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.26ms, itl=8.38ms, cost=10.00, arrivalRate=439.12"}
{"level":"INFO","ts":"2025-12-09T21:26:36.081Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.036 (3.6%)"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.081Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:26:36.082Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.082Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.086Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.086Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.086Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.086Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.086Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.086Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.464, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:26:36.086Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.087Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.087Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.464, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:26:36.087Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:26:36.087Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:26:36.087Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:26:36.087Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:26:36.087Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:26:36.087Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:26:36.092Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:26:36.092Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:27:36.093Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:27:36.093Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:27:36.093Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:27:36.093Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:27:36.093Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:27:36.093Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:27:36.113Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.18ms, itl=8.16ms, cost=10.00, arrivalRate=401.52"}
{"level":"INFO","ts":"2025-12-09T21:27:36.114Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.114Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:27:36.114Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.045 (4.5%)"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.114Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.115Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.115Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.115Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.115Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.115Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.115Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.455, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:27:36.115Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.116Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.116Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.455, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:27:36.116Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:27:36.116Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:27:36.116Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:27:36.116Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:27:36.116Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:27:36.116Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:27:36.120Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:27:36.120Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:28:36.120Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:28:36.120Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:28:36.120Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:28:36.120Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:28:36.120Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:28:36.120Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:28:36.139Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.13ms, itl=8.22ms, cost=10.00, arrivalRate=401.52"}
{"level":"INFO","ts":"2025-12-09T21:28:36.140Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.140Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:28:36.140Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.045 (4.5%)"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.140Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.455, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:28:36.142Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.455, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:28:36.142Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:28:36.142Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:28:36.142Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:28:36.142Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:28:36.142Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:28:36.142Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:28:36.146Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:28:36.146Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:29:36.146Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:29:36.147Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:29:36.147Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:29:36.147Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:29:36.147Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:29:36.147Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:29:36.161Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.12ms, itl=8.41ms, cost=10.00, arrivalRate=448.52"}
{"level":"INFO","ts":"2025-12-09T21:29:36.163Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.046 (4.6%)"}
{"level":"INFO","ts":"2025-12-09T21:29:36.163Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.163Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.163Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.454, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:29:36.164Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.454, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:29:36.164Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:29:36.164Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:29:36.164Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:29:36.164Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:29:36.164Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:29:36.164Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:29:36.169Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:29:36.169Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:30:36.170Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:30:36.170Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:30:36.170Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:30:36.170Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:30:36.170Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:30:36.170Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:30:36.187Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=18.21ms, itl=8.51ms, cost=10.00, arrivalRate=456.58"}
{"level":"INFO","ts":"2025-12-09T21:30:36.188Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.052 (5.2%)"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.188Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:30:36.188Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.188Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.448, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:30:36.190Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.448, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:30:36.190Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:30:36.190Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:30:36.190Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:30:36.190Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:30:36.190Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:30:36.190Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:30:36.195Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:30:36.195Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:31:36.196Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:31:36.196Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:31:36.196Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:31:36.196Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:31:36.196Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:31:36.196Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:31:36.225Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.44ms, itl=8.50ms, cost=10.00, arrivalRate=455.24"}
{"level":"INFO","ts":"2025-12-09T21:31:36.227Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.227Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:31:36.227Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.040 (4.0%)"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.227Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.460, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:31:36.229Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.460, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:31:36.229Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:31:36.229Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:31:36.229Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:31:36.229Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:31:36.229Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:31:36.229Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:31:36.233Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:31:36.233Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T21:32:36.234Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T21:32:36.234Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T21:32:36.234Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T21:32:36.234Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T21:32:36.234Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T21:32:36.234Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T21:32:36.257Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.58ms, itl=8.22ms, cost=10.00, arrivalRate=410.92"}
{"level":"INFO","ts":"2025-12-09T21:32:36.258Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.258Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T21:32:36.259Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.034 (3.4%)"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.259Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.466, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T21:32:36.260Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.466, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T21:32:36.260Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T21:32:36.260Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T21:32:36.260Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T21:32:36.260Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T21:32:36.260Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T21:32:36.260Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T21:32:36.265Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T21:32:36.265Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
