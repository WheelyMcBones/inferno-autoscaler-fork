{"level":"INFO","ts":"2025-12-09T22:08:37.363Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:08:37.363Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:08:37.363Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:08:37.383Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:08:37.385Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.385Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:08:37.385Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.385Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:08:37.386Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:08:37.386Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:08:37.386Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:08:37.386Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:08:37.386Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:08:37.386Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:08:37.386Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:08:37.391Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:08:37.391Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:09:37.392Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:09:37.392Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:09:37.392Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:09:37.392Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:09:37.392Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:09:37.392Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:09:37.413Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:09:37.414Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.414Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:09:37.414Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.414Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:09:37.416Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:09:37.416Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:09:37.416Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:09:37.416Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:09:37.416Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:09:37.416Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:09:37.416Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:09:37.421Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:09:37.421Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:10:37.421Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:10:37.421Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:10:37.421Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:10:37.421Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:10:37.421Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:10:37.421Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:10:37.444Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:10:37.446Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.446Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:10:37.446Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.446Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:10:37.447Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:10:37.447Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:10:37.447Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:10:37.447Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:10:37.447Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:10:37.447Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:10:37.447Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:10:37.461Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:10:37.461Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:11:37.462Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:11:37.462Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:11:37.462Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:11:37.462Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:11:37.462Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:11:37.462Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:11:37.478Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:11:37.479Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.479Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:11:37.479Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.479Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:11:37.481Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:11:37.481Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:11:37.481Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:11:37.481Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:11:37.481Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:11:37.481Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:11:37.481Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:11:37.485Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:11:37.485Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:12:37.487Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:12:37.487Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:12:37.487Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:12:37.487Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:12:37.487Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:12:37.487Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:12:37.506Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=15.01ms, itl=6.89ms, cost=10.00, arrivalRate=10.74"}
{"level":"INFO","ts":"2025-12-09T22:12:37.507Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.009 (0.9%)"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.507Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:12:37.508Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.508Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.491, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:12:37.509Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.491, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:12:37.509Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:12:37.509Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:12:37.509Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:12:37.509Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:12:37.509Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:12:37.509Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:12:37.514Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:12:37.514Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:13:37.514Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:13:37.515Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:13:37.515Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:13:37.515Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:13:37.515Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:13:37.515Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:13:37.544Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.72ms, itl=8.58ms, cost=10.00, arrivalRate=463.29"}
{"level":"INFO","ts":"2025-12-09T22:13:37.545Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.545Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:13:37.545Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.037 (3.7%)"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.545Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.463, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:13:37.547Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.463, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:13:37.547Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:13:37.547Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:13:37.547Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:13:37.547Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:13:37.547Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:13:37.547Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:13:37.553Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:13:37.553Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:14:37.553Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:14:37.554Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:14:37.554Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:14:37.554Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:14:37.554Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:14:37.554Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:14:37.571Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=22.18ms, itl=11.11ms, cost=10.00, arrivalRate=884.96"}
{"level":"INFO","ts":"2025-12-09T22:14:37.573Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.573Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:14:37.573Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.108 (10.8%)"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.573Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.392, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:14:37.574Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.392, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:14:37.574Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:14:37.574Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:14:37.574Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:14:37.574Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:14:37.574Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:14:37.574Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:14:37.580Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:14:37.580Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:15:37.581Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:15:37.581Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:15:37.581Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:15:37.581Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:15:37.581Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:15:37.581Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:15:37.598Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=43.45ms, itl=25.52ms, cost=10.00, arrivalRate=1487.91"}
{"level":"INFO","ts":"2025-12-09T22:15:37.600Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.465 (46.5%)"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.600Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:15:37.600Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.600Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.602Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.602Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.602Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.602Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.602Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.602Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.035, avgSpareQueue=5.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:15:37.602Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.602Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"INFO","ts":"2025-12-09T22:15:37.602Z","msg":"Saturation target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=1, readyReplicas=1, baseTarget=1, target=2, reason=KV spare Saturation low (0.035 < 0.100)"}
{"level":"DEBUG","ts":"2025-12-09T22:15:37.602Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T22:15:37.602Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:15:37.602Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:15:37.602Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-up, current=1→target=2"}
{"level":"INFO","ts":"2025-12-09T22:15:37.602Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:15:37.602Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:15:37.607Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-up, current=1, target=2, reason=saturation-only mode: scale-up"}
{"level":"INFO","ts":"2025-12-09T22:15:37.607Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:16:37.607Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:16:37.608Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:16:37.608Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:16:37.608Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:16:37.608Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:16:37.608Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.628Z","msg":"Replica count mismatch for llm-d-inference-scheduler/unsloth/Meta-Llama-3.1-8B: spec=2, reporting_metrics=1"}
{"level":"INFO","ts":"2025-12-09T22:16:37.628Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=57.28ms, itl=34.74ms, cost=10.00, arrivalRate=1634.29"}
{"level":"INFO","ts":"2025-12-09T22:16:37.629Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.630 (63.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.630Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:16:37.630Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.630Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.632Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.632Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.632Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.632Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.632Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.632Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:16:37.632Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.632Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"INFO","ts":"2025-12-09T22:16:37.632Z","msg":"Saturation target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, baseTarget=1, target=2, reason=both KV spare (0.000 < 0.100) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-12-09T22:16:37.632Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T22:16:37.632Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:16:37.632Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:16:37.632Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"INFO","ts":"2025-12-09T22:16:37.632Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:16:37.632Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:16:37.636Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:16:37.636Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:17:37.637Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:17:37.637Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:17:37.637Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:17:37.637Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:17:37.637Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:17:37.637Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.658Z","msg":"Replica count mismatch for llm-d-inference-scheduler/unsloth/Meta-Llama-3.1-8B: spec=2, reporting_metrics=1"}
{"level":"INFO","ts":"2025-12-09T22:17:37.658Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=75.80ms, itl=47.26ms, cost=10.00, arrivalRate=1587.29"}
{"level":"INFO","ts":"2025-12-09T22:17:37.659Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.659Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:17:37.659Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.792 (79.2%)"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.659Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.661Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.661Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.661Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.661Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.661Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.661Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:17:37.661Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.661Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"INFO","ts":"2025-12-09T22:17:37.661Z","msg":"Saturation target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, baseTarget=1, target=2, reason=both KV spare (0.000 < 0.100) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-12-09T22:17:37.661Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T22:17:37.661Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:17:37.661Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:17:37.661Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"INFO","ts":"2025-12-09T22:17:37.661Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:17:37.661Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:17:37.665Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:17:37.665Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:18:37.666Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:18:37.666Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:18:37.666Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:18:37.666Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:18:37.666Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:18:37.666Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:18:37.687Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=73.41ms, itl=45.88ms, cost=20.00, arrivalRate=1780.94"}
{"level":"INFO","ts":"2025-12-09T22:18:37.689Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"INFO","ts":"2025-12-09T22:18:37.689Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dwtbwp, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.689Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-12-09T22:18:37.689Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.894 (89.4%)"}
{"level":"INFO","ts":"2025-12-09T22:18:37.689Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dwtbwp, usage=0.059 (5.9%)"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.689Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=2, matched=2"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=1, avgSpareKv=0.441, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:18:37.692Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=2"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.441, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:18:37.692Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T22:18:37.692Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:18:37.692Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:18:37.692Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"INFO","ts":"2025-12-09T22:18:37.692Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:18:37.692Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:18:37.698Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:18:37.698Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:19:37.699Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:19:37.699Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:19:37.699Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:19:37.699Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:19:37.699Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:19:37.699Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:19:37.716Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=36.39ms, itl=21.19ms, cost=20.00, arrivalRate=2045.03"}
{"level":"INFO","ts":"2025-12-09T22:19:37.717Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"INFO","ts":"2025-12-09T22:19:37.717Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dwtbwp, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.717Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-12-09T22:19:37.717Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.643 (64.3%)"}
{"level":"INFO","ts":"2025-12-09T22:19:37.717Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dwtbwp, usage=0.069 (6.9%)"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.717Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=2, matched=2"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=1, avgSpareKv=0.431, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:19:37.719Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=2"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.431, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:19:37.719Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-12-09T22:19:37.719Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:19:37.719Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:19:37.719Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"INFO","ts":"2025-12-09T22:19:37.719Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:19:37.719Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:19:37.724Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:19:37.724Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:20:37.725Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:20:37.725Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:20:37.725Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:20:37.725Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:20:37.725Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:20:37.725Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:20:37.745Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=21.97ms, itl=11.07ms, cost=20.00, arrivalRate=1678.50"}
{"level":"INFO","ts":"2025-12-09T22:20:37.747Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"INFO","ts":"2025-12-09T22:20:37.747Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dwtbwp, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.747Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-12-09T22:20:37.747Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.148 (14.8%)"}
{"level":"INFO","ts":"2025-12-09T22:20:37.747Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dwtbwp, usage=0.074 (7.4%)"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.747Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.749Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=2, matched=2"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.749Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.749Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.749Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.749Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.389, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-12-09T22:20:37.749Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.749Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=2"}
{"level":"INFO","ts":"2025-12-09T22:20:37.749Z","msg":"Saturation target: scale-down most expensive variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=2, baseTarget=2, target=1"}
{"level":"DEBUG","ts":"2025-12-09T22:20:37.749Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:20:37.749Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:20:37.749Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:20:37.749Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-down, current=2→target=1"}
{"level":"INFO","ts":"2025-12-09T22:20:37.749Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:20:37.749Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:20:37.754Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-down, current=2, target=1, reason=saturation-only mode: scale-down"}
{"level":"INFO","ts":"2025-12-09T22:20:37.754Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:21:37.754Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:21:37.755Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:21:37.755Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:21:37.755Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:21:37.755Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:21:37.755Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:21:37.772Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=19.79ms, itl=9.56ms, cost=10.00, arrivalRate=671.44"}
{"level":"INFO","ts":"2025-12-09T22:21:37.773Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.089 (8.9%)"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.773Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:21:37.773Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.773Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.411, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:21:37.775Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.411, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:21:37.775Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:21:37.775Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:21:37.775Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:21:37.775Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:21:37.775Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:21:37.775Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:21:37.781Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:21:37.781Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:22:37.782Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:22:37.782Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:22:37.782Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:22:37.782Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:22:37.782Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:22:37.782Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:22:37.806Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=20.99ms, itl=10.21ms, cost=10.00, arrivalRate=860.79"}
{"level":"INFO","ts":"2025-12-09T22:22:37.807Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.108 (10.8%)"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.807Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:22:37.807Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.807Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.392, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:22:37.809Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.392, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:22:37.809Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:22:37.809Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:22:37.809Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:22:37.809Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:22:37.809Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:22:37.809Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:22:37.817Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:22:37.817Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:23:37.818Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:23:37.818Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:23:37.818Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:23:37.818Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:23:37.818Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:23:37.818Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:23:37.834Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.32ms, itl=10.79ms, cost=10.00, arrivalRate=854.07"}
{"level":"INFO","ts":"2025-12-09T22:23:37.836Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.836Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:23:37.836Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.103 (10.3%)"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.836Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.397, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:23:37.837Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.397, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:23:37.837Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:23:37.837Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:23:37.837Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:23:37.837Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:23:37.837Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:23:37.837Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:23:37.843Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:23:37.843Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:24:37.843Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:24:37.843Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:24:37.843Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:24:37.843Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:24:37.843Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:24:37.843Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:24:37.869Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=20.90ms, itl=10.40ms, cost=10.00, arrivalRate=820.50"}
{"level":"INFO","ts":"2025-12-09T22:24:37.871Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.871Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:24:37.871Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.099 (9.9%)"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.871Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.401, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:24:37.872Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.401, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:24:37.872Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:24:37.872Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:24:37.872Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:24:37.872Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:24:37.872Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:24:37.872Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:24:37.877Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:24:37.877Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:25:37.878Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:25:37.878Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:25:37.878Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:25:37.878Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:25:37.878Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:25:37.878Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:25:37.896Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.09ms, itl=10.49ms, cost=10.00, arrivalRate=796.33"}
{"level":"INFO","ts":"2025-12-09T22:25:37.898Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.092 (9.2%)"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.898Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:25:37.898Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.898Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.408, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:25:37.900Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.408, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:25:37.900Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:25:37.900Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:25:37.900Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:25:37.900Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:25:37.900Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:25:37.900Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:25:37.905Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:25:37.905Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:26:37.905Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:26:37.905Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:26:37.905Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:26:37.905Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:26:37.905Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:26:37.905Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:26:37.925Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.97ms, itl=10.85ms, cost=10.00, arrivalRate=828.56"}
{"level":"INFO","ts":"2025-12-09T22:26:37.927Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.927Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:26:37.927Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.111 (11.1%)"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.927Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.389, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:26:37.929Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.389, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:26:37.929Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:26:37.929Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:26:37.929Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:26:37.929Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:26:37.929Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:26:37.929Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:26:37.934Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:26:37.934Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:27:37.934Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:27:37.935Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:27:37.935Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:27:37.935Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:27:37.935Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:27:37.935Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:27:37.958Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.29ms, itl=10.76ms, cost=10.00, arrivalRate=837.96"}
{"level":"INFO","ts":"2025-12-09T22:27:37.959Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.107 (10.7%)"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.959Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:27:37.959Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.959Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.393, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:27:37.961Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.393, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:27:37.961Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:27:37.961Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:27:37.961Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:27:37.961Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:27:37.961Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:27:37.961Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:27:37.966Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:27:37.966Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:28:37.967Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:28:37.968Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:28:37.968Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:28:37.968Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:28:37.968Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:28:37.968Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:28:37.987Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=22.15ms, itl=10.86ms, cost=10.00, arrivalRate=866.16"}
{"level":"INFO","ts":"2025-12-09T22:28:37.988Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.988Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:28:37.989Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.104 (10.4%)"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.989Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.396, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:28:37.990Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.396, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:28:37.990Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:28:37.990Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:28:37.990Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:28:37.990Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:28:37.990Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:28:37.990Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:28:37.995Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:28:37.995Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:29:37.996Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:29:37.996Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:29:37.996Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:29:37.996Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:29:37.996Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:29:37.996Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:29:38.015Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=20.42ms, itl=9.91ms, cost=10.00, arrivalRate=801.70"}
{"level":"INFO","ts":"2025-12-09T22:29:38.017Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.099 (9.9%)"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.017Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:29:38.017Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.017Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.401, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:29:38.018Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.401, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:29:38.018Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:29:38.018Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:29:38.018Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:29:38.018Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:29:38.018Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:29:38.018Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:29:38.024Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:29:38.024Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:30:38.025Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:30:38.025Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:30:38.025Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:30:38.025Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:30:38.025Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:30:38.025Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:30:38.043Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=20.02ms, itl=9.81ms, cost=10.00, arrivalRate=780.21"}
{"level":"INFO","ts":"2025-12-09T22:30:38.044Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.044Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:30:38.044Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.086 (8.6%)"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.044Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.414, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:30:38.046Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.414, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:30:38.046Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:30:38.046Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:30:38.046Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:30:38.046Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:30:38.046Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:30:38.046Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:30:38.051Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:30:38.051Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:31:38.052Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:31:38.052Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:31:38.052Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:31:38.052Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:31:38.052Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:31:38.052Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:31:38.066Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=20.65ms, itl=10.12ms, cost=10.00, arrivalRate=811.10"}
{"level":"INFO","ts":"2025-12-09T22:31:38.068Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.095 (9.5%)"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.068Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:31:38.068Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.068Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.405, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:31:38.069Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.405, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:31:38.069Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:31:38.069Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:31:38.069Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:31:38.069Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:31:38.070Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:31:38.070Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:31:38.074Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:31:38.074Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:32:38.075Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:32:38.075Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:32:38.075Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:32:38.075Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:32:38.075Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:32:38.075Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:32:38.099Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.66ms, itl=8.23ms, cost=10.00, arrivalRate=408.24"}
{"level":"INFO","ts":"2025-12-09T22:32:38.100Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"INFO","ts":"2025-12-09T22:32:38.100Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.046 (4.6%)"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.100Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.100Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.454, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:32:38.102Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.454, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:32:38.102Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:32:38.102Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:32:38.102Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:32:38.102Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:32:38.102Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:32:38.102Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:32:38.107Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:32:38.107Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:33:38.107Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:33:38.108Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:33:38.108Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:33:38.108Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:33:38.108Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:33:38.108Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:33:38.143Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.68ms, itl=8.30ms, cost=10.00, arrivalRate=431.07"}
{"level":"INFO","ts":"2025-12-09T22:33:38.145Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.145Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:33:38.145Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.043 (4.3%)"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.145Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.457, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:33:38.147Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.457, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:33:38.147Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:33:38.147Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:33:38.147Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:33:38.147Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:33:38.147Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:33:38.147Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:33:38.152Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:33:38.152Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:34:38.152Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:34:38.153Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:34:38.153Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:34:38.153Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:34:38.153Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:34:38.153Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:34:38.170Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.24ms, itl=8.12ms, cost=10.00, arrivalRate=365.26"}
{"level":"INFO","ts":"2025-12-09T22:34:38.172Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.172Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:34:38.172Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.040 (4.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.172Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.460, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:34:38.174Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.460, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:34:38.174Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:34:38.174Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:34:38.174Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:34:38.174Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:34:38.174Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:34:38.174Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:34:38.179Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:34:38.179Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:35:38.180Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:35:38.180Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:35:38.180Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:35:38.180Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:35:38.180Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:35:38.180Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:35:38.197Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=19.02ms, itl=8.56ms, cost=10.00, arrivalRate=449.87"}
{"level":"INFO","ts":"2025-12-09T22:35:38.198Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.042 (4.2%)"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.198Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:35:38.198Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.198Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.458, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:35:38.200Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.458, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:35:38.200Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:35:38.200Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:35:38.200Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:35:38.200Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:35:38.200Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:35:38.200Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:35:38.206Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:35:38.206Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:36:38.209Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:36:38.211Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:36:38.211Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:36:38.211Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:36:38.212Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:36:38.212Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:36:38.263Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.24ms, itl=8.19ms, cost=10.00, arrivalRate=414.95"}
{"level":"INFO","ts":"2025-12-09T22:36:38.265Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.042 (4.2%)"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.265Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:36:38.265Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.265Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.266Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.266Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.266Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.266Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.266Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.266Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.458, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:36:38.266Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.267Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.267Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.458, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:36:38.267Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:36:38.267Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:36:38.267Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:36:38.267Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:36:38.267Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:36:38.267Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:36:38.272Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:36:38.272Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:37:38.272Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:37:38.272Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:37:38.272Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:37:38.272Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:37:38.273Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:37:38.273Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:37:38.290Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.74ms, itl=8.25ms, cost=10.00, arrivalRate=382.72"}
{"level":"INFO","ts":"2025-12-09T22:37:38.292Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.292Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:37:38.292Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.056 (5.6%)"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.292Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.444, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:37:38.293Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.444, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:37:38.293Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:37:38.293Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:37:38.293Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:37:38.293Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:37:38.293Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:37:38.293Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:37:38.299Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:37:38.299Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:38:38.299Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:38:38.300Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:38:38.300Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:38:38.300Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:38:38.300Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:38:38.300Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:38:38.319Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.44ms, itl=8.22ms, cost=10.00, arrivalRate=423.01"}
{"level":"INFO","ts":"2025-12-09T22:38:38.320Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.320Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:38:38.320Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.038 (3.8%)"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.320Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.462, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:38:38.322Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.462, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:38:38.322Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:38:38.322Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:38:38.322Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:38:38.322Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:38:38.322Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:38:38.322Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:38:38.327Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:38:38.327Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:39:38.328Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:39:38.328Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:39:38.328Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:39:38.328Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:39:38.328Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:39:38.328Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:39:38.343Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.46ms, itl=8.42ms, cost=10.00, arrivalRate=437.78"}
{"level":"INFO","ts":"2025-12-09T22:39:38.344Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.344Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:39:38.345Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.055 (5.5%)"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.345Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.445, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:39:38.346Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.445, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:39:38.346Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:39:38.346Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:39:38.346Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:39:38.346Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:39:38.346Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:39:38.346Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:39:38.351Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:39:38.351Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:40:38.351Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:40:38.351Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:40:38.351Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:40:38.351Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:40:38.352Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:40:38.352Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:40:38.372Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.34ms, itl=8.23ms, cost=10.00, arrivalRate=390.78"}
{"level":"INFO","ts":"2025-12-09T22:40:38.374Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.374Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:40:38.374Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.050 (5.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.374Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.450, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:40:38.375Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.450, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:40:38.375Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:40:38.375Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:40:38.375Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:40:38.375Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:40:38.375Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:40:38.375Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:40:38.381Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:40:38.381Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:41:38.382Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:41:38.382Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:41:38.382Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:41:38.382Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:41:38.382Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:41:38.382Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:41:38.398Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.25ms, itl=8.16ms, cost=10.00, arrivalRate=417.64"}
{"level":"INFO","ts":"2025-12-09T22:41:38.400Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.037 (3.7%)"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.400Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:41:38.400Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.400Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.463, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:41:38.402Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.463, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:41:38.402Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:41:38.402Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:41:38.402Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:41:38.402Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:41:38.402Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:41:38.402Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:41:38.406Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:41:38.406Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:42:38.407Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:42:38.407Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:42:38.407Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:42:38.407Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:42:38.407Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:42:38.407Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:42:38.426Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=17.52ms, itl=8.16ms, cost=10.00, arrivalRate=405.55"}
{"level":"INFO","ts":"2025-12-09T22:42:38.428Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.045 (4.5%)"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.428Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:42:38.428Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.428Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.455, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:42:38.429Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.455, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:42:38.429Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:42:38.429Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:42:38.429Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:42:38.429Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:42:38.429Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:42:38.429Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:42:38.435Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:42:38.435Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:43:38.436Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:43:38.436Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:43:38.436Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:43:38.436Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:43:38.436Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:43:38.436Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:43:38.454Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:43:38.455Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.455Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:43:38.455Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.455Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:43:38.457Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:43:38.457Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:43:38.457Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:43:38.457Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:43:38.457Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:43:38.457Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:43:38.457Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:43:38.463Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:43:38.463Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:44:38.463Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:44:38.464Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:44:38.464Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:44:38.464Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:44:38.464Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:44:38.464Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:44:38.486Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:44:38.487Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.487Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:44:38.487Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.487Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:44:38.489Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:44:38.489Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:44:38.489Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:44:38.489Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:44:38.489Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:44:38.489Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:44:38.489Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:44:38.494Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:44:38.494Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:45:38.495Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:45:38.495Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:45:38.495Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:45:38.495Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:45:38.495Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:45:38.495Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:45:38.516Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:45:38.518Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.518Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:45:38.518Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.518Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:45:38.519Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:45:38.519Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:45:38.519Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:45:38.519Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:45:38.519Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:45:38.519Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:45:38.519Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:45:38.526Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:45:38.526Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:46:38.527Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:46:38.527Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:46:38.527Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:46:38.527Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:46:38.527Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:46:38.527Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:46:38.548Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:46:38.549Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.549Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:46:38.549Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.549Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:46:38.551Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:46:38.551Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:46:38.551Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:46:38.551Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:46:38.551Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:46:38.551Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:46:38.551Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:46:38.556Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:46:38.556Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:47:38.557Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:47:38.557Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:47:38.557Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:47:38.557Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:47:38.557Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:47:38.557Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:47:38.577Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:47:38.578Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.578Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:47:38.578Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.578Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:47:38.580Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:47:38.580Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:47:38.580Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:47:38.580Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:47:38.580Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:47:38.580Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:47:38.580Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:47:38.585Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:47:38.585Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:48:38.586Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:48:38.586Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:48:38.586Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:48:38.586Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:48:38.586Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:48:38.586Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:48:38.607Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:48:38.609Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.609Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:48:38.609Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.609Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.610Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.610Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.610Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.610Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.610Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.610Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:48:38.610Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.611Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.611Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:48:38.611Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:48:38.611Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:48:38.611Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:48:38.611Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:48:38.611Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:48:38.611Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:48:38.615Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:48:38.615Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-12-09T22:49:38.616Z","msg":"Reconciling VariantAutoscaling: name=ms-inference-scheduling-llm-d-modelservice-decode, namespace=llm-d-inference-scheduler, modelID=unsloth/Meta-Llama-3.1-8B"}
{"level":"INFO","ts":"2025-12-09T22:49:38.616Z","msg":"saturation scaling config cache updated: entries=1, has_default=true"}
{"level":"INFO","ts":"2025-12-09T22:49:38.616Z","msg":"saturation scaling configuration loaded successfully"}
{"level":"INFO","ts":"2025-12-09T22:49:38.616Z","msg":"Operating in saturation-only mode: reactive saturation-based scaling only"}
{"level":"INFO","ts":"2025-12-09T22:49:38.616Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-12-09T22:49:38.616Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-12-09T22:49:38.635Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-12-09T22:49:38.636Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, queueLength=0"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.636Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-12-09T22:49:38.636Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-7b86984dgftqv, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.636Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"Pod to owner mapping: namespace=llm-d-inference-scheduler, candidatePods=1, matched=1"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"Collected Saturation metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-12-09T22:49:38.637Z","msg":"saturation analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"Target initialized to metrics count: variant=ms-inference-scheduling-llm-d-modelservice-decode, count=1"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"Saturation targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-12-09T22:49:38.637Z","msg":"Saturation targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-12-09T22:49:38.637Z","msg":"saturation-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-12-09T22:49:38.637Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-12-09T22:49:38.637Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"INFO","ts":"2025-12-09T22:49:38.637Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-12-09T22:49:38.637Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, SaturationOnly=true"}
{"level":"INFO","ts":"2025-12-09T22:49:38.643Z","msg":"Applied Saturation decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=saturation-only mode: no-change"}
{"level":"INFO","ts":"2025-12-09T22:49:38.643Z","msg":"Reconciliation completed successfully: mode=saturation-only, modelsProcessed=1, decisionsApplied=1"}
