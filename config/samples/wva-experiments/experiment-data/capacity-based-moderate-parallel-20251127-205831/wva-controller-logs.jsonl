{"level":"INFO","ts":"2025-11-28T01:57:45.460Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:57:45.460Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.460Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.472Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:57:45.473Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.473Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.474Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:57:45.474Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:57:45.474Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.474Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.474Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.474Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:57:45.474Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:57:45.474Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:57:45.479Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:57:45.479Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.479Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:57:45.479Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.479Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.488Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:57:45.489Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.489Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:57:45.489Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:57:45.489Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.489Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:57:45.489Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:57:45.489Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:57:45.489Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:57:45.489Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:57:45.493Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:57:45.493Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.480Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:58:15.480Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.480Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.502Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:58:15.504Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.504Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:58:15.504Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:58:15.504Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.504Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.504Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.504Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:58:15.504Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:58:15.504Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:58:15.510Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:58:15.510Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.510Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:58:15.510Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.510Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.525Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:58:15.526Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.526Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.526Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.526Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:58:15.527Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:58:15.527Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.527Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:58:15.527Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:15.527Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:58:15.527Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:58:15.527Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:58:15.531Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:58:15.531Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.510Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:58:45.510Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.510Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.522Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:58:45.523Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.523Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.523Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.523Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:58:45.524Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:58:45.524Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.524Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.524Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.524Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:58:45.524Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:58:45.524Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:58:45.529Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:58:45.529Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.532Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:58:45.532Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.532Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.540Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:58:45.542Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.542Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:58:45.542Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:58:45.542Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.542Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:58:45.542Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:58:45.542Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:58:45.542Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:58:45.542Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:58:45.546Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:58:45.546Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.530Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:59:15.530Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.530Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.552Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:59:15.554Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.554Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:59:15.554Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:59:15.554Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.554Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.554Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.554Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:59:15.554Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:59:15.554Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:59:15.559Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:59:15.559Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.559Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:59:15.559Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.559Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.568Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:59:15.569Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.569Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:59:15.569Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:59:15.569Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.569Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:59:15.569Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:15.569Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:59:15.569Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:59:15.569Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:59:15.574Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:59:15.574Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.559Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:59:45.559Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.559Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.572Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=38.18ms, itl=7.87ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:59:45.573Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.003 (0.3%)"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.573Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.573Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.573Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.497, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:59:45.574Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.497, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:59:45.574Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.574Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.574Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.574Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:59:45.574Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:59:45.574Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:59:45.578Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:59:45.578Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.578Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T01:59:45.578Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.578Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.586Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=38.18ms, itl=7.87ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T01:59:45.588Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.003 (0.3%)"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.588Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.497, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T01:59:45.588Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.497, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T01:59:45.588Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.588Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T01:59:45.588Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T01:59:45.588Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T01:59:45.588Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T01:59:45.588Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T01:59:45.592Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T01:59:45.592Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.578Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:00:15.578Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.578Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.593Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.94ms, itl=10.26ms, cost=10.00, arrivalRate=381.36"}
{"level":"INFO","ts":"2025-11-28T02:00:15.594Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.068 (6.8%)"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.594Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.432, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:00:15.594Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.432, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:00:15.594Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.594Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.594Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.594Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:00:15.594Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:00:15.594Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:00:15.598Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:00:15.598Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.598Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:00:15.598Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.598Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.607Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.94ms, itl=10.26ms, cost=10.00, arrivalRate=381.46"}
{"level":"INFO","ts":"2025-11-28T02:00:15.608Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.608Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.068 (6.8%)"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.432, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:00:15.608Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.432, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:00:15.608Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.608Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:00:15.608Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:15.608Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:00:15.608Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:00:15.608Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:00:15.613Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:00:15.613Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.675Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:00:45.675Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.675Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.688Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=22.69ms, itl=10.94ms, cost=10.00, arrivalRate=414.74"}
{"level":"INFO","ts":"2025-11-28T02:00:45.689Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.075 (7.5%)"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.689Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.425, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:00:45.689Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.425, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:00:45.689Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.689Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.689Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.689Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:00:45.689Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:00:45.689Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:00:45.695Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:00:45.695Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.695Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:00:45.695Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.695Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.703Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=22.69ms, itl=10.94ms, cost=10.00, arrivalRate=414.55"}
{"level":"INFO","ts":"2025-11-28T02:00:45.705Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.705Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.075 (7.5%)"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.425, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:00:45.705Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.425, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:00:45.705Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.705Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:00:45.705Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:00:45.705Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:00:45.705Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:00:45.705Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:00:45.709Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:00:45.709Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.696Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:01:15.696Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.696Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.708Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=26.77ms, itl=14.49ms, cost=10.00, arrivalRate=910.00"}
{"level":"INFO","ts":"2025-11-28T02:01:15.710Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.710Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.229 (22.9%)"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.271, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:01:15.710Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.271, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:01:15.710Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.710Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.710Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.710Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:01:15.710Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:01:15.710Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:01:15.715Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:01:15.715Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.715Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:01:15.715Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.715Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.723Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=26.77ms, itl=14.49ms, cost=10.00, arrivalRate=910.00"}
{"level":"INFO","ts":"2025-11-28T02:01:15.725Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.725Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.229 (22.9%)"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.271, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:01:15.725Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.271, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:01:15.725Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.725Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:01:15.725Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:15.725Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:01:15.725Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:01:15.725Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:01:15.729Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:01:15.729Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.717Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:01:45.717Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.717Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.729Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=38.15ms, itl=21.47ms, cost=10.00, arrivalRate=1356.00"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.313 (31.3%)"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.187, avgSpareQueue=5.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=1, readyReplicas=1, target=2, reason=KV spare capacity low (0.187 < 0.200)"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-up, current=1→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.731Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:01:45.731Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:01:45.737Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-up, current=1, target=2, reason=capacity-only mode: scale-up"}
{"level":"INFO","ts":"2025-11-28T02:01:45.737Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.737Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:01:45.737Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.737Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.745Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=38.15ms, itl=21.47ms, cost=10.00, arrivalRate=1356.00"}
{"level":"INFO","ts":"2025-11-28T02:01:45.746Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.313 (31.3%)"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.746Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.187, avgSpareQueue=5.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:01:45.746Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Preserving desired replicas: variant=ms-inference-scheduling-llm-d-modelservice-decode, currentReplicas=1, readyReplicas=1, desired=2"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:01:45.746Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.746Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:01:45.746Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-up, current=1→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:01:45.746Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:01:45.746Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:01:45.746Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:01:45.750Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-up, current=1, target=2, reason=capacity-only mode: scale-up"}
{"level":"INFO","ts":"2025-11-28T02:01:45.750Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.737Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:02:15.737Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.737Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.764Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=45.80ms, itl=25.92ms, cost=20.00, arrivalRate=1532.00"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.477 (47.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.023, avgSpareQueue=5.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, target=2, reason=KV spare capacity low (0.023 < 0.200)"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.766Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:02:15.766Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:02:15.771Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:02:15.771Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.771Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:02:15.771Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.771Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.780Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=45.80ms, itl=25.92ms, cost=20.00, arrivalRate=1532.00"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.477 (47.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.023, avgSpareQueue=5.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, target=2, reason=KV spare capacity low (0.023 < 0.200)"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:02:15.782Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:02:15.782Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:02:15.786Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:02:15.786Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.775Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:02:45.775Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.775Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.789Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=75.16ms, itl=46.99ms, cost=20.00, arrivalRate=1688.00"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.812 (81.2%)"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, target=2, reason=both KV spare (0.000 < 0.200) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.875Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:02:45.875Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:02:45.881Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:02:45.881Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.881Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:02:45.881Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.881Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.891Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=75.16ms, itl=46.99ms, cost=20.00, arrivalRate=1688.00"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.812 (81.2%)"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, target=2, reason=both KV spare (0.000 < 0.200) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:02:45.893Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:02:45.893Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:02:45.897Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:02:45.897Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.881Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:03:15.881Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.881Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.902Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=87.37ms, itl=54.07ms, cost=20.00, arrivalRate=1510.00"}
{"level":"INFO","ts":"2025-11-28T02:03:15.903Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.903Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.903Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.897 (89.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.903Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.904Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.904Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.904Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.904Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.904Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.904Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:03:15.904Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:03:15.904Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, target=2, reason=both KV spare (0.000 < 0.200) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.904Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:03:15.904Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.904Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.904Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.904Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:03:15.904Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:03:15.904Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:03:15.908Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:03:15.908Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.909Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:03:15.909Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.909Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.917Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=87.37ms, itl=54.07ms, cost=20.00, arrivalRate=1510.00"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.897 (89.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, target=2, reason=both KV spare (0.000 < 0.200) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:03:15.918Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:03:15.918Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:03:15.924Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:03:15.924Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.910Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:03:45.910Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.910Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.933Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=77.24ms, itl=47.70ms, cost=20.00, arrivalRate=1676.00"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.897 (89.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, target=2, reason=both KV spare (0.000 < 0.200) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.934Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:03:45.934Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:03:45.939Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:03:45.939Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.939Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:03:45.939Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.939Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.948Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=77.24ms, itl=47.70ms, cost=20.00, arrivalRate=1676.00"}
{"level":"INFO","ts":"2025-11-28T02:03:45.949Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.897 (89.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.949Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.949Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.949Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.950Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.950Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.950Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.950Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.950Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=0, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.950Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=0, avgSpareKv=0.000, avgSpareQueue=0.0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:03:45.950Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=0, shouldScaleUp=true, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:03:45.950Z","msg":"Capacity target: scale-up cheapest variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=1, target=2, reason=both KV spare (0.000 < 0.200) and queue spare (0.0 < 3.0)"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.950Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:03:45.950Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.950Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:03:45.950Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:03:45.950Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:03:45.950Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:03:45.950Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:03:45.954Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:03:45.954Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.940Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:04:15.940Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.940Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.957Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=64.21ms, itl=38.85ms, cost=20.00, arrivalRate=1632.00"}
{"level":"INFO","ts":"2025-11-28T02:04:15.959Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:04:15.959Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:04:15.959Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.110 (11.0%)"}
{"level":"INFO","ts":"2025-11-28T02:04:15.959Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.707 (70.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=1, avgSpareKv=0.390, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:04:15.959Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.390, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:04:15.959Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.959Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.959Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.959Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:04:15.960Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:04:15.960Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:04:15.965Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:04:15.965Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.965Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:04:15.965Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.965Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.974Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=64.21ms, itl=38.85ms, cost=20.00, arrivalRate=1632.00"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.110 (11.0%)"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.707 (70.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=1, avgSpareKv=0.390, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.390, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:15.976Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:04:15.976Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:04:15.981Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:04:15.981Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:04:45.966Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:04:45.966Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:04:45.966Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:04:45.989Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=39.38ms, itl=24.47ms, cost=20.00, arrivalRate=2512.00"}
{"level":"INFO","ts":"2025-11-28T02:04:45.990Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.155 (15.5%)"}
{"level":"INFO","ts":"2025-11-28T02:04:45.990Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.625 (62.5%)"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.990Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:04:45.990Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:04:45.990Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.990Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.990Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.990Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.990Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.990Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.990Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.990Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=1, avgSpareKv=0.345, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:04:45.990Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.991Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.345, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.991Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:04:45.991Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:04:45.991Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:04:45.991Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:45.991Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:04:45.991Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:04:45.991Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:04:45.997Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:04:45.997Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:04:45.997Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:04:45.997Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:04:45.997Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:04:46.006Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=39.38ms, itl=24.47ms, cost=20.00, arrivalRate=2512.00"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.155 (15.5%)"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.625 (62.5%)"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=1, avgSpareKv=0.345, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.345, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:04:46.008Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:04:46.008Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:04:46.013Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:04:46.013Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:05:15.997Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:05:15.997Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:05:15.997Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:05:16.010Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=31.02ms, itl=17.44ms, cost=20.00, arrivalRate=2504.00"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.155 (15.5%)"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.416 (41.6%)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Scale-down unsafe: insufficient headroom after redistribution: remainingSpareKv=-0.071, kvTrigger=0.200, kvSafe=false, remainingSpareQueue=5.0, queueTrigger=3.0%!(EXTRA bool=true)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.215, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.215, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.012Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:05:16.012Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:05:16.017Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:05:16.017Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:05:16.017Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:05:16.017Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:05:16.017Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:05:16.042Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=31.02ms, itl=17.44ms, cost=20.00, arrivalRate=2504.00"}
{"level":"INFO","ts":"2025-11-28T02:05:16.055Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:05:16.055Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.055Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:05:16.055Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.155 (15.5%)"}
{"level":"INFO","ts":"2025-11-28T02:05:16.055Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.416 (41.6%)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.055Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.056Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.056Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.056Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.056Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.056Z","msg":"Scale-down unsafe: insufficient headroom after redistribution: remainingSpareKv=-0.071, kvTrigger=0.200, kvSafe=false, remainingSpareQueue=5.0, queueTrigger=3.0%!(EXTRA bool=true)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.056Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.215, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:05:16.056Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.056Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.215, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.056Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:05:16.056Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:05:16.057Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:05:16.057Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:16.057Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:05:16.057Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:05:16.057Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:05:16.063Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:05:16.063Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.019Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:05:46.020Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.020Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.038Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=28.38ms, itl=14.98ms, cost=20.00, arrivalRate=2160.00"}
{"level":"INFO","ts":"2025-11-28T02:05:46.039Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:05:46.039Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.039Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:05:46.039Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.184 (18.4%)"}
{"level":"INFO","ts":"2025-11-28T02:05:46.039Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.215 (21.5%)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.039Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Scale-down unsafe: insufficient headroom after redistribution: remainingSpareKv=0.101, kvTrigger=0.200, kvSafe=false, remainingSpareQueue=5.0, queueTrigger=3.0%!(EXTRA bool=true)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.300, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:05:46.040Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.300, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:05:46.040Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.040Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.040Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.040Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:05:46.040Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:05:46.040Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:05:46.044Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:05:46.044Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.064Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:05:46.064Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.064Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.073Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=28.38ms, itl=14.98ms, cost=20.00, arrivalRate=2160.00"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.184 (18.4%)"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.215 (21.5%)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Scale-down unsafe: insufficient headroom after redistribution: remainingSpareKv=0.101, kvTrigger=0.200, kvSafe=false, remainingSpareQueue=5.0, queueTrigger=3.0%!(EXTRA bool=true)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.300, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.300, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:05:46.075Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:05:46.075Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:05:46.081Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:05:46.081Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.045Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:06:16.045Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.045Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.061Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=25.46ms, itl=13.37ms, cost=20.00, arrivalRate=1970.00"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.184 (18.4%)"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.215 (21.5%)"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Scale-down unsafe: insufficient headroom after redistribution: remainingSpareKv=0.101, kvTrigger=0.200, kvSafe=false, remainingSpareQueue=5.0, queueTrigger=3.0%!(EXTRA bool=true)"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.300, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.300, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.063Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:06:16.063Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:06:16.068Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:06:16.068Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.082Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:06:16.082Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.082Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.091Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=25.46ms, itl=13.37ms, cost=20.00, arrivalRate=1970.00"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.184 (18.4%)"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.215 (21.5%)"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Scale-down unsafe: insufficient headroom after redistribution: remainingSpareKv=0.101, kvTrigger=0.200, kvSafe=false, remainingSpareQueue=5.0, queueTrigger=3.0%!(EXTRA bool=true)"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.300, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.300, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2→target=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:16.093Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:06:16.093Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=2, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:06:16.098Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=2, target=2, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:06:16.098Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.069Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:06:46.069Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.069Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.087Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=22.23ms, itl=11.43ms, cost=20.00, arrivalRate=1568.00"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.081 (8.1%)"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.103 (10.3%)"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.408, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"Capacity target: scale-down most expensive variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=2, readyReplicas=2, target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.088Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-down, current=2→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.088Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:06:46.089Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:06:46.089Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:06:46.176Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-down, current=2, target=1, reason=capacity-only mode: scale-down"}
{"level":"INFO","ts":"2025-11-28T02:06:46.176Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.176Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:06:46.176Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.176Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.186Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=2, accelerator=H100, ttft=22.23ms, itl=11.43ms, cost=20.00, arrivalRate=1568.00"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.081 (8.1%)"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.103 (10.3%)"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.408, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Preserving desired replicas: variant=ms-inference-scheduling-llm-d-modelservice-decode, currentReplicas=2, readyReplicas=2, desired=1"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-down, current=2→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:06:46.188Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:06:46.188Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:06:46.192Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=scale-down, current=2, target=1, reason=capacity-only mode: scale-down"}
{"level":"INFO","ts":"2025-11-28T02:06:46.192Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.177Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:07:16.177Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.177Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.197Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.52ms, itl=10.92ms, cost=10.00, arrivalRate=1068.00"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.081 (8.1%)"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.097 (9.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.411, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"Capacity target: scale-down most expensive variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=1, readyReplicas=2, target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.199Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:07:16.199Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:07:16.204Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:07:16.204Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.204Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:07:16.204Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.204Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.213Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=21.52ms, itl=10.92ms, cost=10.00, arrivalRate=1068.00"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.081 (8.1%)"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.097 (9.7%)"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.411, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"Capacity target: scale-down most expensive variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=1, readyReplicas=2, target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:07:16.214Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:07:16.214Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:07:16.219Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:07:16.219Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.204Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:07:46.205Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.205Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.225Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=19.72ms, itl=9.59ms, cost=10.00, arrivalRate=396.00"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.032 (3.2%)"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.060 (6.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.454, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"Capacity target: scale-down most expensive variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=1, readyReplicas=2, target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.227Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:07:46.227Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:07:46.239Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:07:46.239Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.240Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:07:46.240Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.240Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.249Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=19.72ms, itl=9.59ms, cost=10.00, arrivalRate=396.00"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, usage=0.032 (3.2%)"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.060 (6.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f994t2p, queueLength=0"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"Pod-to-variant matching successful: totalPods=2, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:2]"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=2"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=2, nonSaturated=2, avgSpareKv=0.454, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=2, nonSaturated=2, shouldScaleUp=false, scaleDownSafe=true"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"Capacity target: scale-down most expensive variant: variant=ms-inference-scheduling-llm-d-modelservice-decode, cost=10.00, currentReplicas=1, readyReplicas=2, target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:07:46.250Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:07:46.250Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:07:46.254Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:07:46.254Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.240Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:08:16.241Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.241Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.256Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=22.51ms, itl=10.87ms, cost=10.00, arrivalRate=438.00"}
{"level":"INFO","ts":"2025-11-28T02:08:16.257Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.257Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.257Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.060 (6.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.257Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.257Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.257Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.257Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.257Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.257Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.257Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.440, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:08:16.257Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.258Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.440, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.258Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:08:16.258Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.258Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.258Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.258Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:08:16.258Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:08:16.258Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:08:16.262Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:08:16.262Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.263Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:08:16.263Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.263Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.271Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=22.51ms, itl=10.87ms, cost=10.00, arrivalRate=438.00"}
{"level":"INFO","ts":"2025-11-28T02:08:16.273Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.060 (6.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.273Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.440, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:08:16.273Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.440, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:08:16.273Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.273Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:08:16.273Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:16.273Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:08:16.273Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:08:16.273Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:08:16.278Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:08:16.278Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.276Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:08:46.277Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.277Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.302Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:08:46.303Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.303Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.375Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.375Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.375Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.375Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.375Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.376Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.376Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.376Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:08:46.376Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.376Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.376Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:08:46.376Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.376Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.376Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.376Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:08:46.376Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:08:46.376Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:08:46.382Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:08:46.382Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.382Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:08:46.382Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.382Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.392Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:08:46.394Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.394Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:08:46.394Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:08:46.394Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.394Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:08:46.394Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:08:46.394Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:08:46.394Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:08:46.394Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:08:46.483Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:08:46.483Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.383Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:09:16.383Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.383Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.404Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:09:16.406Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.406Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:09:16.406Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:09:16.406Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.406Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.406Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.406Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:09:16.406Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:09:16.406Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:09:16.412Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:09:16.412Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.483Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:09:16.483Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.483Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.493Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:09:16.495Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.495Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:09:16.495Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:09:16.495Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.495Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:09:16.495Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:16.495Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:09:16.495Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:09:16.495Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:09:16.502Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:09:16.502Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.412Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:09:46.412Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.412Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.425Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:09:46.426Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.426Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.427Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:09:46.427Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:09:46.427Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.427Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.427Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.427Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:09:46.427Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:09:46.427Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:09:46.432Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:09:46.432Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.502Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:09:46.502Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.502Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.513Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:09:46.514Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.514Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:09:46.514Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:09:46.514Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.514Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:09:46.514Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:09:46.514Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:09:46.514Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:09:46.514Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:09:46.519Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:09:46.519Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.433Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:10:16.433Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.433Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.448Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:10:16.450Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.450Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:10:16.450Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:10:16.450Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.450Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.450Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.450Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:10:16.450Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:10:16.450Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:10:16.456Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:10:16.456Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.519Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:10:16.519Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.519Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.530Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:10:16.531Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Queue metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.531Z","msg":"KV cache metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, usage=0.000 (0.0%)"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"KV cache metrics collected (max over 1m): modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, podCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Pod-to-variant matching successful: totalPods=1, variantCounts=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Collected replica metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Collected capacity metrics: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, metricsCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Variant analysis initialized: variant=ms-inference-scheduling-llm-d-modelservice-decode, accelerator=H100, cost=10.00, replicaCount=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Scale-down unsafe: insufficient non-saturated replicas: nonSaturated=1, required=2"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, namespace=llm-d-inference-scheduler, totalReplicas=1, nonSaturated=1, avgSpareKv=0.500, avgSpareQueue=5.0, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"INFO","ts":"2025-11-28T02:10:16.531Z","msg":"Capacity analysis completed: modelID=unsloth/Meta-Llama-3.1-8B, totalReplicas=1, nonSaturated=1, shouldScaleUp=false, scaleDownSafe=false"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Capacity targets: no scaling needed (avgSpareKv=0.500, avgSpareQueue=5.0, all variants stable)"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Capacity targets calculated: modelID=unsloth/Meta-Llama-3.1-8B, targets=map[ms-inference-scheduling-llm-d-modelservice-decode:1]"}
{"level":"INFO","ts":"2025-11-28T02:10:16.531Z","msg":"Capacity-only decisions made for model: unsloth/Meta-Llama-3.1-8B - decision count: 1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.531Z","msg":"Applying scaling decisions: totalDecisions=1"}
{"level":"INFO","ts":"2025-11-28T02:10:16.531Z","msg":"Processing decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1→target=1"}
{"level":"DEBUG","ts":"2025-11-28T02:10:16.531Z","msg":"Found VA in map: variant=ms-inference-scheduling-llm-d-modelservice-decode, hasCurrentAlloc=true, accelerator=H100"}
{"level":"INFO","ts":"2025-11-28T02:10:16.531Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-28T02:10:16.531Z","msg":"Successfully emitted metrics for external autoscalers: variant=ms-inference-scheduling-llm-d-modelservice-decode, targetReplicas=1, accelerator=H100, capacityOnly=true"}
{"level":"INFO","ts":"2025-11-28T02:10:16.535Z","msg":"Applied capacity decision: variant=ms-inference-scheduling-llm-d-modelservice-decode, action=no-change, current=1, target=1, reason=capacity-only mode: no-change"}
{"level":"INFO","ts":"2025-11-28T02:10:16.535Z","msg":"Reconciliation completed successfully: mode=capacity-only, modelsProcessed=1, decisionsApplied=1"}
{"level":"INFO","ts":"2025-11-28T02:10:46.459Z","msg":"Operating in CAPACITY-ONLY mode: reactive capacity-based scaling only"}
{"level":"INFO","ts":"2025-11-28T02:10:46.475Z","msg":"Grouped VAs by model: modelCount=1, totalVAs=1"}
{"level":"INFO","ts":"2025-11-28T02:10:46.475Z","msg":"Processing model: modelID=unsloth/Meta-Llama-3.1-8B, variantCount=1"}
{"level":"INFO","ts":"2025-11-28T02:10:46.489Z","msg":"Metrics collected for VA: variant=ms-inference-scheduling-llm-d-modelservice-decode, replicas=1, accelerator=H100, ttft=0.00ms, itl=0.00ms, cost=10.00, arrivalRate=0.00"}
{"level":"INFO","ts":"2025-11-28T02:10:46.491Z","msg":"Queue metric: pod=ms-inference-scheduling-llm-d-modelservice-decode-789945f9l76md, queueLength=0"}
