{"level":"INFO","ts":"2025-11-19T21:59:49.491Z","msg":"Zap logger initialized"}
{"level":"INFO","ts":"2025-11-19T21:59:49.493Z","msg":"Creating metrics emitter instance"}
{"level":"INFO","ts":"2025-11-19T21:59:49.493Z","msg":"Metrics emitter created successfully"}
{"level":"INFO","ts":"2025-11-19T21:59:49.493Z","msg":"Using Prometheus configuration from environment variablesaddresshttps://thanos-querier.openshift-monitoring.svc.cluster.local:9091"}
{"level":"WARN","ts":"2025-11-19T21:59:49.493Z","msg":"TLS certificate verification is disabled - this is not recommended for production"}
{"level":"INFO","ts":"2025-11-19T21:59:49.493Z","msg":"Initializing Prometheus client -> address: https://thanos-querier.openshift-monitoring.svc.cluster.local:9091 tls_enabled: true"}
{"level":"INFO","ts":"2025-11-19T21:59:49.493Z","msg":"CA certificate loaded successfullypath/etc/ssl/certs/prometheus-ca.crt"}
{"level":"INFO","ts":"2025-11-19T21:59:49.493Z","msg":"TLS configuration applied to Prometheus HTTPS transport"}
{"level":"INFO","ts":"2025-11-19T21:59:49.493Z","msg":"Bearer token loaded from filepath/var/run/secrets/kubernetes.io/serviceaccount/token"}
{"level":"INFO","ts":"2025-11-19T21:59:49.579Z","msg":"Prometheus API validation successful with queryqueryup"}
{"level":"INFO","ts":"2025-11-19T21:59:49.579Z","msg":"Prometheus client and API wrapper initialized and validated successfully"}
{"level":"INFO","ts":"2025-11-19T21:59:49.579Z","msg":"Starting manager"}
{"level":"INFO","ts":"2025-11-19T21:59:49.579Z","msg":"Registering custom metrics with Prometheus registry"}
{"level":"info","ts":"2025-11-19T21:59:49Z","logger":"controller-runtime.metrics","msg":"Starting metrics server"}
{"level":"INFO","ts":"2025-11-19T21:59:49.579Z","msg":"disabling http/2"}
{"level":"info","ts":"2025-11-19T21:59:49Z","msg":"starting server","name":"health probe","addr":"[::]:8081"}
I1119 21:59:49.580026       1 leaderelection.go:257] attempting to acquire leader lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai...
{"level":"info","ts":"2025-11-19T21:59:49Z","logger":"controller-runtime.metrics","msg":"Serving metrics server","bindAddress":":8443","secure":true}
I1119 22:00:08.320587       1 leaderelection.go:271] successfully acquired lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai
{"level":"info","ts":"2025-11-19T22:00:08Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1.ConfigMap"}
{"level":"info","ts":"2025-11-19T22:00:08Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1alpha1.VariantAutoscaling"}
{"level":"info","ts":"2025-11-19T22:00:09Z","msg":"Starting Controller","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling"}
{"level":"info","ts":"2025-11-19T22:00:09Z","msg":"Starting workers","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","worker count":1}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.540Z","msg":"ConfigMap watch enqueueing requests: count=1"}
{"level":"INFO","ts":"2025-11-19T22:00:09.541Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.664Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.664Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.664Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:00:09.664Z","msg":"Tuner failed completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 6}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T22:00:09.664Z","msg":"Using tuned parameters from status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.664Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.664Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 6,    maxBatch: 256,    cost: 600,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-500, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:00:09.665396348 +0000 UTC m=+20.263073352 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.665Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:00:09.665Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 6, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:00:09.665Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.682Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:00:09.682Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:00:09.682Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-19T22:00:09.696Z","msg":"Tuner failed completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 6}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T22:00:09.696Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 6,    maxBatch: 256,    cost: 600,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-500, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:00:09.696911528 +0000 UTC m=+20.294588539 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.696Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:00:09.697Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 6, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:00:09.697Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:00:09.703Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:00:09.703Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:01:09.683Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-19T22:01:09.696Z","msg":"Tuner failed completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T22:01:09.696Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:01:09.696492618 +0000 UTC m=+80.294169615 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.696Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:01:09.696Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:01:09.696Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:01:09.703Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:01:09.703Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:02:09.704Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.720Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.720Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.720Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"INFO","ts":"2025-11-19T22:02:09.721Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 5.053199"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.721Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.616579, beta=0.068847, gamma=23.475477, delta=0.003931, NIS=5.05"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.721Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.616579, beta=0.068847, gamma=23.475477, delta=0.003931, NIS=5.053199"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.721Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=10.616579, beta=0.068847, gamma=23.475477, delta=0.003931 | NIS=5.053199"}
{"level":"INFO","ts":"2025-11-19T22:02:09.721Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.616579, beta: 0.068847, gamma: 23.475477, delta: 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.616579,    beta: 0.06884661   },   prefillParms: {    gamma: 23.475477,    delta: 0.003930655   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.28,    ttftAverage: 23.6,    load: {     arrivalRate: 46.67,     avgInTokens: 269,     avgOutTokens: 289    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=46.67; inTk=269; outTk=289; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=10.854281, ttft=27.126108, rho=0.0095805945, maxRPM=852.4895}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 10.854281 27.126108 {46.67 269 289}}"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:02:09.723813228 +0000 UTC m=+140.321490226 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.723Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:02:09.723Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:02:09.723Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:02:09.732Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:02:09.732Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:03:09.735Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.752Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.752Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.616579, beta= 0.068847, gamma= 23.475477, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.752Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.616579, beta=0.068847, gamma=23.475477, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:03:09.752Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.616579, beta=0.068847, gamma=23.475477, delta=0.003931, NIS=5.053199). Validation error: tuning validation failed: normalized innovation squared (NIS=26.44) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.752Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=10.616579, beta=0.068847, gamma=23.475477, delta=0.003931 | NIS=5.053199 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:03:09.752Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.752Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.616579, beta=0.068847, gamma=23.475477, delta=0.003931, NIS=5.05"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.752Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.616579,    beta: 0.068847   },   prefillParms: {    gamma: 23.475477,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.6,    ttftAverage: 25.2,    load: {     arrivalRate: 775.16,     avgInTokens: 270,     avgOutTokens: 519    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=775.16; inTk=270; outTk=519; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=100, itl=13.926892, ttft=74.50845, rho=0.18391475, maxRPM=478.3262}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 13.926892 74.50845 {775.16 270 519}}"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:03:09.75774659 +0000 UTC m=+200.355423587 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.757Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:03:09.757Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:03:09.757Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:03:09.764Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:03:09.764Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:04:09.765Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.780Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.780Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.616579, beta= 0.068847, gamma= 23.475477, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.780Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.616579, beta=0.068847, gamma=23.475477, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:04:09.780Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.477808"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.780Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919, NIS=3.48"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.780Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919, NIS=3.477808"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.780Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919 | NIS=3.477808"}
{"level":"INFO","ts":"2025-11-19T22:04:09.780Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.791566, beta: 0.066658, gamma: 23.299740, delta: 0.003919"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.787Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.791566,    beta: 0.06665799   },   prefillParms: {    gamma: 23.29974,    delta: 0.0039187297   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.39,    ttftAverage: 22.8,    load: {     arrivalRate: 500.21,     avgInTokens: 246,     avgOutTokens: 549    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=500.21; inTk=246; outTk=549; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=14.245044, ttft=87.7059, rho=0.25707373, maxRPM=556.36554}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 14.245044 87.7059 {500.21 246 549}}"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:04:09.788200618 +0000 UTC m=+260.385877616 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.788Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:04:09.788Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:04:09.788Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:04:09.796Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:04:09.796Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:05:09.797Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.809Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.809Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.791566, beta= 0.066658, gamma= 23.299740, delta= 0.003919"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.809Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:05:09.810Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919, NIS=3.477808). Validation error: tuning validation failed: normalized innovation squared (NIS=9.57) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.810Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919 | NIS=3.477808 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:05:09.810Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.810Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919, NIS=3.48"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.810Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.791566,    beta: 0.066658   },   prefillParms: {    gamma: 23.29974,    delta: 0.003919   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.11,    ttftAverage: 24.32,    load: {     arrivalRate: 620.18,     avgInTokens: 248,     avgOutTokens: 451    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=620.18; inTk=248; outTk=451; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=14.378363, ttft=90.17789, rho=0.26488635, maxRPM=675.72473}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 14.378363 90.17789 {620.18 248 451}}"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:05:09.814691731 +0000 UTC m=+320.412368728 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.814Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:05:09.814Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:05:09.814Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:05:09.825Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:05:09.825Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:06:09.826Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.845Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.845Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.791566, beta= 0.066658, gamma= 23.299740, delta= 0.003919"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.845Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:06:09.846Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919, NIS=3.477808). Validation error: tuning validation failed: normalized innovation squared (NIS=21.11) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.846Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919 | NIS=3.477808 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:06:09.846Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.846Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919, NIS=3.48"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.846Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.791566,    beta: 0.066658   },   prefillParms: {    gamma: 23.29974,    delta: 0.003919   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.72,    ttftAverage: 25.04,    load: {     arrivalRate: 810.42,     avgInTokens: 243,     avgOutTokens: 520    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=810.42; inTk=243; outTk=520; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=100, itl=12.903514, ttft=67.75893, rho=0.17845814, maxRPM=587.1323}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 12.903514 67.75893 {810.42 243 520}}"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.850Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:06:09.850985453 +0000 UTC m=+380.448662472 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.851Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.851Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:06:09.851Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:06:09.851Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:06:09.858Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:06:09.858Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:07:09.859Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.871Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.871Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.791566, beta= 0.066658, gamma= 23.299740, delta= 0.003919"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.871Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.791566, beta=0.066658, gamma=23.299740, delta=0.003919 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:07:09.872Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.439179"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.872Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905, NIS=1.44"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.872Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905, NIS=1.439179"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.872Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905 | NIS=1.439179"}
{"level":"INFO","ts":"2025-11-19T22:07:09.872Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.706884, beta: 0.066522, gamma: 23.046890, delta: 0.003905"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.706884,    beta: 0.06652244   },   prefillParms: {    gamma: 23.04689,    delta: 0.003904945   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.63,    ttftAverage: 23.51,    load: {     arrivalRate: 469.57,     avgInTokens: 269,     avgOutTokens: 614    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=469.57; inTk=269; outTk=614; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=14.429087, ttft=97.61336, rho=0.27338523, maxRPM=506.80698}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 14.429087 97.61336 {469.57 269 614}}"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:07:09.876503911 +0000 UTC m=+440.474180908 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.876Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:07:09.876Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:07:09.876Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:07:09.884Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:07:09.884Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:08:09.885Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.905Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.905Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.706884, beta= 0.066522, gamma= 23.046890, delta= 0.003905"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.905Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:08:09.907Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905, NIS=1.439179). Validation error: tuning validation failed: normalized innovation squared (NIS=11.31) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.907Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905 | NIS=1.439179 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:08:09.907Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.907Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905, NIS=1.44"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.907Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.706884,    beta: 0.066522   },   prefillParms: {    gamma: 23.04689,    delta: 0.003905   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 13.23,    ttftAverage: 26.6,    load: {     arrivalRate: 699.65,     avgInTokens: 250,     avgOutTokens: 481    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=699.65; inTk=250; outTk=481; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=100, itl=12.036403, ttft=57.233963, rho=0.13288584, maxRPM=645.71265}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 12.036403 57.233963 {699.65 250 481}}"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:08:09.911475204 +0000 UTC m=+500.509152202 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.911Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:08:09.911Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:08:09.911Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:08:09.919Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:08:09.919Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:09:09.919Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.936Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.936Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.706884, beta= 0.066522, gamma= 23.046890, delta= 0.003905"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.936Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:09:09.938Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905, NIS=1.439179). Validation error: tuning validation failed: normalized innovation squared (NIS=9.86) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.938Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905 | NIS=1.439179 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:09:09.938Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.938Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905, NIS=1.44"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.938Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.706884,    beta: 0.066522   },   prefillParms: {    gamma: 23.04689,    delta: 0.003905   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 15.63,    ttftAverage: 30.41,    load: {     arrivalRate: 1143.6,     avgInTokens: 260,     avgOutTokens: 578    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1143.6; inTk=260; outTk=578; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=256; cost=300, val=100, itl=12.9661, ttft=72.79106, rho=0.18747868, maxRPM=538.2175}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 256 300 12.9661 72.79106 {1143.6 260 578}}"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:09:09.944467185 +0000 UTC m=+560.542144182 H100 3}"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.944Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:09:09.944Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:09:09.944Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:09:09.956Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:09:09.956Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:10:09.957Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.971Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.971Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.706884, beta= 0.066522, gamma= 23.046890, delta= 0.003905"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.971Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.706884, beta=0.066522, gamma=23.046890, delta=0.003905 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:10:09.972Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.899893"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.972Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.824854, beta=0.066556, gamma=22.806705, delta=0.003897, NIS=0.90"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.972Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.824854, beta=0.066556, gamma=22.806705, delta=0.003897, NIS=0.899893"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.972Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=9.824854, beta=0.066556, gamma=22.806705, delta=0.003897 | NIS=0.899893"}
{"level":"INFO","ts":"2025-11-19T22:10:09.972Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.824854, beta: 0.066556, gamma: 22.806705, delta: 0.003897"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.824854,    beta: 0.06655636   },   prefillParms: {    gamma: 22.806705,    delta: 0.0038967466   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 11.42,    ttftAverage: 24.15,    load: {     arrivalRate: 755.81,     avgInTokens: 272,     avgOutTokens: 460    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=755.81; inTk=272; outTk=460; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=-100, itl=12.280235, ttft=61.908836, rho=0.14020218, maxRPM=658.8284}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 12.280235 61.908836 {755.81 272 460}}"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:10:09.976535215 +0000 UTC m=+620.574212219 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.976Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:10:09.976Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:10:09.976Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:10:09.984Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:10:09.984Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:11:09.985Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:11:09.996Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:11:09.996Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.824854, beta= 0.066556, gamma= 22.806705, delta= 0.003897"}
{"level":"DEBUG","ts":"2025-11-19T22:11:09.996Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.824854, beta=0.066556, gamma=22.806705, delta=0.003897 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:11:09.998Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.824854, beta=0.066556, gamma=22.806705, delta=0.003897, NIS=0.899893). Validation error: tuning validation failed: normalized innovation squared (NIS=14.80) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:11:09.998Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.824854, beta=0.066556, gamma=22.806705, delta=0.003897 | NIS=0.899893 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:11:09.998Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:11:09.998Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.824854, beta=0.066556, gamma=22.806705, delta=0.003897, NIS=0.90"}
{"level":"DEBUG","ts":"2025-11-19T22:11:09.998Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.824854,    beta: 0.066556   },   prefillParms: {    gamma: 22.806705,    delta: 0.003897   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.14,    ttftAverage: 25.27,    load: {     arrivalRate: 1371.57,     avgInTokens: 275,     avgOutTokens: 480    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1371.57; inTk=275; outTk=480; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=256; cost=300, val=100, itl=13.1160345, ttft=75.80083, rho=0.18925706, maxRPM=631.64105}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 256 300 13.1160345 75.80083 {1371.57 275 480}}"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:11:10.002656559 +0000 UTC m=+680.600333557 H100 3}"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.002Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:11:10.002Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:11:10.002Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:11:10.011Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:11:10.011Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:12:10.011Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.027Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.027Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.824854, beta= 0.066556, gamma= 22.806705, delta= 0.003897"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.027Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.824854, beta=0.066556, gamma=22.806705, delta=0.003897 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:12:10.028Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 5.335943"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.028Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864, NIS=5.34"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.028Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864, NIS=5.335943"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.028Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864 | NIS=5.335943"}
{"level":"INFO","ts":"2025-11-19T22:12:10.028Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.174342, beta: 0.061888, gamma: 22.271288, delta: 0.003864"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.174342,    beta: 0.061887898   },   prefillParms: {    gamma: 22.271288,    delta: 0.0038635337   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 11.75,    ttftAverage: 23.75,    load: {     arrivalRate: 1260.23,     avgInTokens: 260,     avgOutTokens: 525    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1260.23; inTk=260; outTk=525; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=-100, itl=14.107235, ttft=102.33838, rho=0.30744895, maxRPM=700.5224}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 14.107235 102.33838 {1260.23 260 525}}"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:12:10.034781035 +0000 UTC m=+740.632458032 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.034Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:12:10.034Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:12:10.034Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:12:10.043Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:12:10.043Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:13:10.045Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.060Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.060Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.174342, beta= 0.061888, gamma= 22.271288, delta= 0.003864"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.060Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:13:10.061Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864, NIS=5.335943). Validation error: tuning validation failed: normalized innovation squared (NIS=11.76) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.061Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864 | NIS=5.335943 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:13:10.061Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.061Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864, NIS=5.34"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.061Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.174342,    beta: 0.061888   },   prefillParms: {    gamma: 22.271288,    delta: 0.003864   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.27,    ttftAverage: 24.61,    load: {     arrivalRate: 1373.03,     avgInTokens: 248,     avgOutTokens: 519    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1373.03; inTk=248; outTk=519; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=14.70742, ttft=107.945305, rho=0.34533083, maxRPM=708.9061}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 14.70742 107.945305 {1373.03 248 519}}"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:13:10.065879389 +0000 UTC m=+800.663556386 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.065Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:13:10.065Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:13:10.065Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:13:10.072Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:13:10.072Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:14:10.073Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.087Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.087Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.174342, beta= 0.061888, gamma= 22.271288, delta= 0.003864"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.087Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:14:10.089Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864, NIS=5.335943). Validation error: tuning validation failed: normalized innovation squared (NIS=11.98) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.089Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864 | NIS=5.335943 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:14:10.089Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.089Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864, NIS=5.34"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.089Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.174342,    beta: 0.061888   },   prefillParms: {    gamma: 22.271288,    delta: 0.003864   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 13.05,    ttftAverage: 26.44,    load: {     arrivalRate: 1551.73,     avgInTokens: 249,     avgOutTokens: 488    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1551.73; inTk=249; outTk=488; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=256; cost=300, val=100, itl=12.532101, ttft=74.472374, rho=0.208029, maxRPM=753.30994}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 256 300 12.532101 74.472374 {1551.73 249 488}}"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:14:10.096314267 +0000 UTC m=+860.693991264 H100 3}"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.096Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:14:10.096Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:14:10.096Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:14:10.104Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:14:10.104Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:15:10.105Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.129Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.129Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.174342, beta= 0.061888, gamma= 22.271288, delta= 0.003864"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.129Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:15:10.129Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864, NIS=5.335943). Validation error: tuning validation failed: normalized innovation squared (NIS=20.61) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.129Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864 | NIS=5.335943 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:15:10.129Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.129Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864, NIS=5.34"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.129Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.174342,    beta: 0.061888   },   prefillParms: {    gamma: 22.271288,    delta: 0.003864   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 15.63,    ttftAverage: 30.04,    load: {     arrivalRate: 2506.67,     avgInTokens: 264,     avgOutTokens: 551    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2506.67; inTk=264; outTk=551; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=256; cost=400, val=100, itl=14.440521, ttft=109.07339, rho=0.32848474, maxRPM=667.75037}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 256 400 14.440521 109.07339 {2506.67 264 551}}"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:15:10.136936584 +0000 UTC m=+920.734613581 H100 4}"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.136Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:15:10.137Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:15:10.137Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:15:10.144Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:15:10.144Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:16:10.146Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.161Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.161Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.174342, beta= 0.061888, gamma= 22.271288, delta= 0.003864"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.161Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.174342, beta=0.061888, gamma=22.271288, delta=0.003864 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:16:10.161Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 5.628595"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.161Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.63"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.161Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.628595"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.161Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | NIS=5.628595"}
{"level":"INFO","ts":"2025-11-19T22:16:10.161Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.523766, beta: 0.064038, gamma: 21.517208, delta: 0.003819"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.523766,    beta: 0.064038314   },   prefillParms: {    gamma: 21.517208,    delta: 0.0038187744   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 13.69,    ttftAverage: 27.16,    load: {     arrivalRate: 2125.61,     avgInTokens: 253,     avgOutTokens: 505    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2125.61; inTk=253; outTk=505; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=256; cost=400, val=0, itl=13.490147, ttft=81.35824, rho=0.2380376, maxRPM=661.6401}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 256 400 13.490147 81.35824 {2125.61 253 505}}"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:16:10.168681103 +0000 UTC m=+980.766358107 H100 4}"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.168Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:16:10.168Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:16:10.168Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:16:10.177Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:16:10.177Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:17:10.179Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.194Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.194Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.523766, beta= 0.064038, gamma= 21.517208, delta= 0.003819"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.194Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:17:10.195Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.628595). Validation error: tuning validation failed: normalized innovation squared (NIS=12.20) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.195Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | NIS=5.628595 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:17:10.195Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.195Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.63"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.195Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.523766,    beta: 0.064038   },   prefillParms: {    gamma: 21.517208,    delta: 0.003819   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 14.13,    ttftAverage: 27.71,    load: {     arrivalRate: 2740.81,     avgInTokens: 272,     avgOutTokens: 526    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2740.81; inTk=272; outTk=526; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=256; cost=500, val=100, itl=13.91661, ttft=92.77406, rho=0.2640526, maxRPM=635.0282}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 256 500 13.91661 92.77406 {2740.81 272 526}}"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:17:10.202570029 +0000 UTC m=+1040.800247027 H100 5}"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.202Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:17:10.202Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:17:10.202Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:17:10.213Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:17:10.213Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:18:10.214Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.233Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.233Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.523766, beta= 0.064038, gamma= 21.517208, delta= 0.003819"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.233Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:18:10.235Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.628595). Validation error: tuning validation failed: normalized innovation squared (NIS=10.98) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.235Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | NIS=5.628595 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:18:10.235Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.235Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.63"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.235Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.523766,    beta: 0.064038   },   prefillParms: {    gamma: 21.517208,    delta: 0.003819   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 12.27,    ttftAverage: 24.97,    load: {     arrivalRate: 3085.46,     avgInTokens: 270,     avgOutTokens: 503    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=3085.46; inTk=270; outTk=503; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=256; cost=500, val=0, itl=14.422371, ttft=100.39378, rho=0.2949034, maxRPM=663.7591}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 256 500 14.422371 100.39378 {3085.46 270 503}}"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:18:10.239965577 +0000 UTC m=+1100.837642575 H100 5}"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.239Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:18:10.240Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:18:10.240Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:18:10.247Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:18:10.247Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:19:10.248Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.262Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.262Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.523766, beta= 0.064038, gamma= 21.517208, delta= 0.003819"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.262Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:19:10.262Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.628595). Validation error: tuning validation failed: normalized innovation squared (NIS=9.53) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.262Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | NIS=5.628595 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:19:10.262Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.262Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.63"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.262Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.523766,    beta: 0.064038   },   prefillParms: {    gamma: 21.517208,    delta: 0.003819   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 11.74,    ttftAverage: 22.6,    load: {     arrivalRate: 2651.45,     avgInTokens: 263,     avgOutTokens: 527    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2651.45; inTk=263; outTk=527; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=256; cost=500, val=0, itl=13.722511, ttft=87.37198, rho=0.25221273, maxRPM=634.06995}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 256 500 13.722511 87.37198 {2651.45 263 527}}"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:19:10.269818458 +0000 UTC m=+1160.867495456 H100 5}"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.269Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:19:10.269Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:19:10.269Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:19:10.276Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:19:10.276Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:20:10.277Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.296Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.296Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.523766, beta= 0.064038, gamma= 21.517208, delta= 0.003819"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.296Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:20:10.298Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.628595). Validation error: tuning validation failed: normalized innovation squared (NIS=13.62) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.298Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | NIS=5.628595 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:20:10.298Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.298Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819, NIS=5.63"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.298Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.523766,    beta: 0.064038   },   prefillParms: {    gamma: 21.517208,    delta: 0.003819   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 11.4,    ttftAverage: 21.62,    load: {     arrivalRate: 2833.83,     avgInTokens: 252,     avgOutTokens: 534    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2833.83; inTk=252; outTk=534; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=256; cost=500, val=0, itl=14.232383, ttft=92.280136, rho=0.28331438, maxRPM=626.1318}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 256 500 14.232383 92.280136 {2833.83 252 534}}"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:20:10.305218896 +0000 UTC m=+1220.902895893 H100 5}"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.305Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:20:10.305Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:20:10.305Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:20:10.311Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:20:10.311Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:21:10.312Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.332Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.332Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.523766, beta= 0.064038, gamma= 21.517208, delta= 0.003819"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.332Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.523766, beta=0.064038, gamma=21.517208, delta=0.003819 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:21:10.333Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.046397"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.333Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.031468, beta=0.065513, gamma=21.082092, delta=0.003806, NIS=2.05"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.333Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.031468, beta=0.065513, gamma=21.082092, delta=0.003806, NIS=2.046397"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.333Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=9.031468, beta=0.065513, gamma=21.082092, delta=0.003806 | NIS=2.046397"}
{"level":"INFO","ts":"2025-11-19T22:21:10.333Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.031468, beta: 0.065513, gamma: 21.082092, delta: 0.003806"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.031468,    beta: 0.065512955   },   prefillParms: {    gamma: 21.082092,    delta: 0.0038064523   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 10.88,    ttftAverage: 22.22,    load: {     arrivalRate: 1535.28,     avgInTokens: 258,     avgOutTokens: 518    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1535.28; inTk=258; outTk=518; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=256; cost=300, val=-200, itl=12.85425, ttft=78.38708, rho=0.22402944, maxRPM=687.3363}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 256 300 12.85425 78.38708 {1535.28 258 518}}"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:21:10.339818821 +0000 UTC m=+1280.937495826 H100 3}"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.339Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:21:10.339Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:21:10.339Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:21:10.349Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:21:10.349Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:22:10.351Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.366Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.366Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.031468, beta= 0.065513, gamma= 21.082092, delta= 0.003806"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.366Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.031468, beta=0.065513, gamma=21.082092, delta=0.003806 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:22:10.366Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.375021"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.366Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.38"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.366Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.375021"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.366Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | NIS=3.375021"}
{"level":"INFO","ts":"2025-11-19T22:22:10.366Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.758709, beta: 0.063995, gamma: 20.361824, delta: 0.003777"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.372Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.372Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.372Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.372Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 8.758709,    beta: 0.06399542   },   prefillParms: {    gamma: 20.361824,    delta: 0.0037765286   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.372Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.373Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 11.65,    ttftAverage: 23.3,    load: {     arrivalRate: 1434.76,     avgInTokens: 263,     avgOutTokens: 482    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.373Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1434.76; inTk=263; outTk=482; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=-100, itl=14.085552, ttft=103.03594, rho=0.32124177, maxRPM=789.8864}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.373Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 14.085552 103.03594 {1434.76 263 482}}"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.373Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.373Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.373Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:22:10.373048457 +0000 UTC m=+1340.970725454 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.373Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.373Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:22:10.373Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:22:10.373Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:22:10.384Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:22:10.384Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:23:10.385Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.400Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.400Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.758709, beta= 0.063995, gamma= 20.361824, delta= 0.003777"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.400Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:23:10.401Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.375021). Validation error: tuning validation failed: normalized innovation squared (NIS=11.25) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.401Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | NIS=3.375021 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:23:10.401Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.401Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.38"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.401Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 8.758709,    beta: 0.063995   },   prefillParms: {    gamma: 20.361824,    delta: 0.003777   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.31,    ttftAverage: 25.23,    load: {     arrivalRate: 1436.08,     avgInTokens: 287,     avgOutTokens: 488    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1436.08; inTk=287; outTk=488; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=14.20821, ttft=112.66986, rho=0.32873085, maxRPM=779.3831}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 14.20821 112.66986 {1436.08 287 488}}"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:23:10.408450485 +0000 UTC m=+1401.006127483 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.408Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:23:10.408Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:23:10.408Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:23:10.418Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:23:10.418Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:24:10.420Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.434Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.434Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.758709, beta= 0.063995, gamma= 20.361824, delta= 0.003777"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.434Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:24:10.436Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.375021). Validation error: tuning validation failed: normalized innovation squared (NIS=10.65) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.436Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | NIS=3.375021 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:24:10.436Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.436Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.38"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.436Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 8.758709,    beta: 0.063995   },   prefillParms: {    gamma: 20.361824,    delta: 0.003777   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.21,    ttftAverage: 24.6,    load: {     arrivalRate: 1395.07,     avgInTokens: 265,     avgOutTokens: 509    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1395.07; inTk=265; outTk=509; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=14.311295, ttft=107.20626, rho=0.3350231, maxRPM=748.473}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 14.311295 107.20626 {1395.07 265 509}}"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:24:10.439696122 +0000 UTC m=+1461.037373120 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.439Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:24:10.439Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:24:10.439Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:24:10.448Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:24:10.448Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:25:10.449Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.464Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.464Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.758709, beta= 0.063995, gamma= 20.361824, delta= 0.003777"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.464Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:25:10.466Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.375021). Validation error: tuning validation failed: normalized innovation squared (NIS=11.17) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.466Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | NIS=3.375021 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:25:10.466Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.466Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.38"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.466Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 8.758709,    beta: 0.063995   },   prefillParms: {    gamma: 20.361824,    delta: 0.003777   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.08,    ttftAverage: 24.27,    load: {     arrivalRate: 1430.74,     avgInTokens: 265,     avgOutTokens: 499    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1430.74; inTk=265; outTk=499; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=14.362505, ttft=108.00721, rho=0.338149, maxRPM=763.2681}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 14.362505 108.00721 {1430.74 265 499}}"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:25:10.472912766 +0000 UTC m=+1521.070589771 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.472Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:25:10.472Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:25:10.472Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:25:10.479Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:25:10.479Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:26:10.480Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.495Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.495Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.758709, beta= 0.063995, gamma= 20.361824, delta= 0.003777"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.495Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:26:10.497Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.375021). Validation error: tuning validation failed: normalized innovation squared (NIS=10.88) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.497Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | NIS=3.375021 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:26:10.497Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.497Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777, NIS=3.38"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.497Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.503Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.503Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.503Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 8.758709,    beta: 0.063995   },   prefillParms: {    gamma: 20.361824,    delta: 0.003777   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.43,    ttftAverage: 24.82,    load: {     arrivalRate: 1387.01,     avgInTokens: 259,     avgOutTokens: 529    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1387.01; inTk=259; outTk=529; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=14.609805, ttft=109.80308, rho=0.35324416, maxRPM=720.73584}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 14.609805 109.80308 {1387.01 259 529}}"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:26:10.504117769 +0000 UTC m=+1581.101794766 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.504Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:26:10.504Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:26:10.504Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:26:10.510Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:26:10.510Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:27:10.511Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.529Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.529Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.758709, beta= 0.063995, gamma= 20.361824, delta= 0.003777"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.529Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.758709, beta=0.063995, gamma=20.361824, delta=0.003777 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:27:10.530Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.674304"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.530Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=8.527062, beta=0.064279, gamma=19.816294, delta=0.003764, NIS=1.67"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.530Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.527062, beta=0.064279, gamma=19.816294, delta=0.003764, NIS=1.674304"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.530Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=8.527062, beta=0.064279, gamma=19.816294, delta=0.003764 | NIS=1.674304"}
{"level":"INFO","ts":"2025-11-19T22:27:10.530Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.527062, beta: 0.064279, gamma: 19.816294, delta: 0.003764"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 8.527062,    beta: 0.064279325   },   prefillParms: {    gamma: 19.816294,    delta: 0.0037636603   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 10.65,    ttftAverage: 21.53,    load: {     arrivalRate: 735.6,     avgInTokens: 250,     avgOutTokens: 501    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=735.6; inTk=250; outTk=501; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=14.313818, ttft=104.52231, rho=0.34775445, maxRPM=785.6016}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 14.313818 104.52231 {735.6 250 501}}"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:27:10.534431532 +0000 UTC m=+1641.132108530 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.534Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:27:10.534Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:27:10.534Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:27:10.543Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:27:10.543Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:28:10.544Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.564Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.564Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.527062, beta= 0.064279, gamma= 19.816294, delta= 0.003764"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.564Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.527062, beta=0.064279, gamma=19.816294, delta=0.003764 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:28:10.565Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.832606"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.565Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=8.585465, beta=0.064908, gamma=18.889830, delta=0.003728, NIS=3.83"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.565Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.585465, beta=0.064908, gamma=18.889830, delta=0.003728, NIS=3.832606"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.565Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=8.585465, beta=0.064908, gamma=18.889830, delta=0.003728 | NIS=3.832606"}
{"level":"INFO","ts":"2025-11-19T22:28:10.565Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.585465, beta: 0.064908, gamma: 18.889830, delta: 0.003728"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 8.585465,    beta: 0.06490795   },   prefillParms: {    gamma: 18.88983,    delta: 0.0037284822   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.23,    ttftAverage: 24,    load: {     arrivalRate: 575.26,     avgInTokens: 263,     avgOutTokens: 458    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=575.26; inTk=263; outTk=458; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=12.15153, ttft=72.763824, rho=0.21070446, maxRPM=842.0126}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 12.15153 72.763824 {575.26 263 458}}"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:28:10.571818084 +0000 UTC m=+1701.169495082 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.571Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:28:10.571Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:28:10.571Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:28:10.579Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:28:10.579Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:29:10.580Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.597Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.597Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.585465, beta= 0.064908, gamma= 18.889830, delta= 0.003728"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.597Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.585465, beta=0.064908, gamma=18.889830, delta=0.003728 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:29:10.599Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=8.585465, beta=0.064908, gamma=18.889830, delta=0.003728, NIS=3.832606). Validation error: tuning validation failed: normalized innovation squared (NIS=11.25) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.599Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=8.585465, beta=0.064908, gamma=18.889830, delta=0.003728 | NIS=3.832606 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:29:10.599Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.599Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=8.585465, beta=0.064908, gamma=18.889830, delta=0.003728, NIS=3.83"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.599Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 8.585465,    beta: 0.064908   },   prefillParms: {    gamma: 18.88983,    delta: 0.003728   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.51,    ttftAverage: 24.3,    load: {     arrivalRate: 770.2,     avgInTokens: 244,     avgOutTokens: 510    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=770.2; inTk=244; outTk=510; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=100, itl=11.006252, ttft=52.815163, rho=0.14177991, maxRPM=757.96387}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 11.006252 52.815163 {770.2 244 510}}"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:29:10.602242552 +0000 UTC m=+1761.199919557 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.602Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:29:10.602Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:29:10.602Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:29:10.614Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:29:10.614Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:30:10.615Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.632Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.632Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.585465, beta= 0.064908, gamma= 18.889830, delta= 0.003728"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.632Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.585465, beta=0.064908, gamma=18.889830, delta=0.003728 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-19T22:30:10.633Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 6.251885"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.633Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720, NIS=6.25"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.633Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720, NIS=6.251885"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.633Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Tuned params: alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720 | NIS=6.251885"}
{"level":"INFO","ts":"2025-11-19T22:30:10.633Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.815432, beta: 0.058977, gamma: 18.376692, delta: 0.003720"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.639Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.639Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.639Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.639Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.815432,    beta: 0.05897673   },   prefillParms: {    gamma: 18.376692,    delta: 0.003720452   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.639Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.639Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.05,    ttftAverage: 25.4,    load: {     arrivalRate: 512.06,     avgInTokens: 278,     avgOutTokens: 578    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.640Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=512.06; inTk=278; outTk=578; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=13.980694, ttft=91.423645, rho=0.27197465, maxRPM=594.97284}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.640Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 13.980694 91.423645 {512.06 278 578}}"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.640Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.640Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.640Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:30:10.640034454 +0000 UTC m=+1821.237711452 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.640Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.640Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:30:10.640Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:30:10.640Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:30:10.646Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:30:10.646Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:31:10.647Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.663Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.663Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.815432, beta= 0.058977, gamma= 18.376692, delta= 0.003720"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.663Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:31:10.663Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720, NIS=6.251885). Validation error: tuning validation failed: normalized innovation squared (NIS=7.67) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.663Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720 | NIS=6.251885 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:31:10.663Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.663Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720, NIS=6.25"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.663Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.815432,    beta: 0.058977   },   prefillParms: {    gamma: 18.376692,    delta: 0.00372   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.06,    ttftAverage: 23.46,    load: {     arrivalRate: 608.74,     avgInTokens: 265,     avgOutTokens: 480    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=608.74; inTk=265; outTk=480; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=13.914507, ttft=86.8927, rho=0.26758963, maxRPM=715.29114}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 13.914507 86.8927 {608.74 265 480}}"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:31:10.670775892 +0000 UTC m=+1881.268452889 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.670Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:31:10.670Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:31:10.670Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:31:10.677Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:31:10.677Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:32:10.679Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.698Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.698Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.815432, beta= 0.058977, gamma= 18.376692, delta= 0.003720"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.698Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:32:10.700Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720, NIS=6.251885). Validation error: tuning validation failed: normalized innovation squared (NIS=9.55) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.700Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720 | NIS=6.251885 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-19T22:32:10.700Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.700Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720, NIS=6.25"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.700Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.815432,    beta: 0.058977   },   prefillParms: {    gamma: 18.376692,    delta: 0.00372   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.02,    ttftAverage: 25.35,    load: {     arrivalRate: 639.3,     avgInTokens: 267,     avgOutTokens: 498    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=639.3; inTk=267; outTk=498; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=14.446977, ttft=96.377205, rho=0.3028569, maxRPM=689.6854}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 14.446977 96.377205 {639.3 267 498}}"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:32:10.707862791 +0000 UTC m=+1941.305539789 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.707Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:32:10.707Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:32:10.707Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:32:10.714Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:32:10.714Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:33:10.715Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.815432, beta= 0.058977, gamma= 18.376692, delta= 0.003720"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-19T22:33:10.731Z","msg":"Tuner failed completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T22:33:10.731Z","msg":"Using tuned parameters from status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.815432, beta=0.058977, gamma=18.376692, delta=0.003720"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.815432, 0.058977, 18.376692, 0.003720]"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.815432,    beta: 0.058977   },   prefillParms: {    gamma: 18.376692,    delta: 0.00372   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.731Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.732Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.732Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.874409, ttft=18.380411, rho=0, maxRPM=354783.97}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.732Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.874409 18.380411 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.732Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.732Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.732Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:33:10.732057864 +0000 UTC m=+2001.329734869 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.732Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.732Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:33:10.732Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:33:10.732Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:33:10.740Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:33:10.740Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:34:10.741Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.757Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.757Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.757Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-19T22:34:10.757Z","msg":"Tuner failed completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T22:34:10.757Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.757Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.757Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.757Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.757Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:34:10.758127953 +0000 UTC m=+2061.355804957 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.758Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:34:10.758Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:34:10.758Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:34:10.766Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:34:10.766Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:35:10.767Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-19T22:35:10.782Z","msg":"Tuner failed completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T22:35:10.782Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:35:10.782773271 +0000 UTC m=+2121.380450268 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.782Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:35:10.782Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:35:10.782Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:35:10.788Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:35:10.788Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:36:10.790Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-19T22:36:10.805Z","msg":"Tuner failed completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T22:36:10.805Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:36:10.805812709 +0000 UTC m=+2181.403489714 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.805Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:36:10.805Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:36:10.805Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:36:10.812Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:36:10.812Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T22:37:10.813Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-19T22:37:10.826Z","msg":"Tuner failed completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T22:37:10.826Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 22:37:10.826612034 +0000 UTC m=+2241.424289038 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.826Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T22:37:10.826Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T22:37:10.826Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T22:37:10.833Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T22:37:10.833Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
