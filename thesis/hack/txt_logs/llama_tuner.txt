{"level":"INFO","ts":"2025-11-20T15:50:22.485Z","msg":"Zap logger initialized"}
{"level":"INFO","ts":"2025-11-20T15:50:22.487Z","msg":"Creating metrics emitter instance"}
{"level":"INFO","ts":"2025-11-20T15:50:22.487Z","msg":"Metrics emitter created successfully"}
{"level":"INFO","ts":"2025-11-20T15:50:22.487Z","msg":"Using Prometheus configuration from environment variablesaddresshttps://thanos-querier.openshift-monitoring.svc.cluster.local:9091"}
{"level":"WARN","ts":"2025-11-20T15:50:22.487Z","msg":"TLS certificate verification is disabled - this is not recommended for production"}
{"level":"INFO","ts":"2025-11-20T15:50:22.487Z","msg":"Initializing Prometheus client -> address: https://thanos-querier.openshift-monitoring.svc.cluster.local:9091 tls_enabled: true"}
{"level":"INFO","ts":"2025-11-20T15:50:22.487Z","msg":"CA certificate loaded successfullypath/etc/ssl/certs/prometheus-ca.crt"}
{"level":"INFO","ts":"2025-11-20T15:50:22.487Z","msg":"TLS configuration applied to Prometheus HTTPS transport"}
{"level":"INFO","ts":"2025-11-20T15:50:22.487Z","msg":"Bearer token loaded from filepath/var/run/secrets/kubernetes.io/serviceaccount/token"}
{"level":"INFO","ts":"2025-11-20T15:50:22.530Z","msg":"Prometheus API validation successful with queryqueryup"}
{"level":"INFO","ts":"2025-11-20T15:50:22.530Z","msg":"Prometheus client and API wrapper initialized and validated successfully"}
{"level":"INFO","ts":"2025-11-20T15:50:22.530Z","msg":"Starting manager"}
{"level":"INFO","ts":"2025-11-20T15:50:22.530Z","msg":"Registering custom metrics with Prometheus registry"}
{"level":"info","ts":"2025-11-20T15:50:22Z","logger":"controller-runtime.metrics","msg":"Starting metrics server"}
{"level":"INFO","ts":"2025-11-20T15:50:22.530Z","msg":"disabling http/2"}
{"level":"info","ts":"2025-11-20T15:50:22Z","msg":"starting server","name":"health probe","addr":"[::]:8081"}
I1120 15:50:22.530709       1 leaderelection.go:257] attempting to acquire leader lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai...
{"level":"info","ts":"2025-11-20T15:50:23Z","logger":"controller-runtime.metrics","msg":"Serving metrics server","bindAddress":":8443","secure":true}
{"level":"error","ts":"2025-11-20T15:50:32Z","logger":"controller-runtime.metrics","msg":"Authentication failed","path":"/metrics","error":"[invalid bearer token, Token does not match server's copy, token lookup failed]","errorCauses":[{"error":"[invalid bearer token, Token does not match server's copy, token lookup failed]"}],"stacktrace":"sigs.k8s.io/controller-runtime/pkg/metrics/filters.WithAuthenticationAndAuthorization.func1.1\n\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.20.4/pkg/metrics/filters/filters.go:89\nnet/http.HandlerFunc.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:2220\nnet/http.(*ServeMux).ServeHTTP\n\t/usr/local/go/src/net/http/server.go:2747\nnet/http.serverHandler.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:3210\nnet/http.(*conn).serve\n\t/usr/local/go/src/net/http/server.go:2092"}
I1120 15:50:39.292345       1 leaderelection.go:271] successfully acquired lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai
{"level":"info","ts":"2025-11-20T15:50:39Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1.ConfigMap"}
{"level":"info","ts":"2025-11-20T15:50:39Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1alpha1.VariantAutoscaling"}
{"level":"DEBUG","ts":"2025-11-20T15:50:40.307Z","msg":"ConfigMap watch enqueueing requests: count=1"}
{"level":"info","ts":"2025-11-20T15:50:40Z","msg":"Starting Controller","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling"}
{"level":"info","ts":"2025-11-20T15:50:40Z","msg":"Starting workers","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","worker count":1}
{"level":"INFO","ts":"2025-11-20T15:50:40.308Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"ERROR","ts":"2025-11-20T15:50:40.409Z","msg":"Deployment.apps \"ms-inference-scheduling-llm-d-modelservice-decode\" not foundfailed to get Deployment after retries - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:50:40.409Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:50:40.409Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:50:40.409Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:50:40.409Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:50:40.409Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:50:40.409Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:50:40.409Z","msg":"System data prepared for optimization: - { servers: []}"}
{"level":"ERROR","ts":"2025-11-20T15:50:40.409Z","msg":"no feasible allocations found for all variants: unable to perform model optimization, skipping this iteration"}
{"level":"error","ts":"2025-11-20T15:50:42Z","logger":"controller-runtime.metrics","msg":"Authentication failed","path":"/metrics","error":"[invalid bearer token, Token does not match server's copy, token lookup failed]","errorCauses":[{"error":"[invalid bearer token, Token does not match server's copy, token lookup failed]"}],"stacktrace":"sigs.k8s.io/controller-runtime/pkg/metrics/filters.WithAuthenticationAndAuthorization.func1.1\n\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.20.4/pkg/metrics/filters/filters.go:89\nnet/http.HandlerFunc.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:2220\nnet/http.(*ServeMux).ServeHTTP\n\t/usr/local/go/src/net/http/server.go:2747\nnet/http.serverHandler.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:3210\nnet/http.(*conn).serve\n\t/usr/local/go/src/net/http/server.go:2092"}
{"level":"error","ts":"2025-11-20T15:50:52Z","logger":"controller-runtime.metrics","msg":"Authentication failed","path":"/metrics","error":"[invalid bearer token, Token does not match server's copy, token lookup failed]","errorCauses":[{"error":"[invalid bearer token, Token does not match server's copy, token lookup failed]"}],"stacktrace":"sigs.k8s.io/controller-runtime/pkg/metrics/filters.WithAuthenticationAndAuthorization.func1.1\n\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.20.4/pkg/metrics/filters/filters.go:89\nnet/http.HandlerFunc.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:2220\nnet/http.(*ServeMux).ServeHTTP\n\t/usr/local/go/src/net/http/server.go:2747\nnet/http.serverHandler.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:3210\nnet/http.(*conn).serve\n\t/usr/local/go/src/net/http/server.go:2092"}
{"level":"error","ts":"2025-11-20T15:51:02Z","logger":"controller-runtime.metrics","msg":"Authentication failed","path":"/metrics","error":"[invalid bearer token, Token does not match server's copy, token lookup failed]","errorCauses":[{"error":"[invalid bearer token, Token does not match server's copy, token lookup failed]"}],"stacktrace":"sigs.k8s.io/controller-runtime/pkg/metrics/filters.WithAuthenticationAndAuthorization.func1.1\n\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.20.4/pkg/metrics/filters/filters.go:89\nnet/http.HandlerFunc.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:2220\nnet/http.(*ServeMux).ServeHTTP\n\t/usr/local/go/src/net/http/server.go:2747\nnet/http.serverHandler.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:3210\nnet/http.(*conn).serve\n\t/usr/local/go/src/net/http/server.go:2092"}
{"level":"INFO","ts":"2025-11-20T15:51:40.411Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"INFO","ts":"2025-11-20T15:51:40.422Z","msg":"Set ownerReference on VariantAutoscaling - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, owner: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.470000, beta= 0.044000, gamma= 15.415000, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.470000, beta=0.044000, gamma=15.415000, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T15:51:40.442Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 2}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T15:51:40.442Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Updated SystemData for model=unsloth/Meta-Llama-3.1-8B, accelerator=H100: alpha=7.470000, beta=0.044000, gamma=15.415000, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model unsloth/Meta-Llama-3.1-8B, accelerator H100: state=[7.470000, 0.044000, 15.415000, 0.000337]"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-100, itl=7.514, ttft=15.415337, rho=0, maxRPM=676453.25}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.514 15.415337 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:51:40.442447777 +0000 UTC m=+78.037802239 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.442Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:51:40.442Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:51:40.442Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:51:40.454Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:51:40.454Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T15:52:40.455Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.470000, beta= 0.044000, gamma= 15.415000, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.470000, beta=0.044000, gamma=15.415000, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T15:52:40.481Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T15:52:40.481Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Updated SystemData for model=unsloth/Meta-Llama-3.1-8B, accelerator=H100: alpha=7.470000, beta=0.044000, gamma=15.415000, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model unsloth/Meta-Llama-3.1-8B, accelerator H100: state=[7.470000, 0.044000, 15.415000, 0.000337]"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=7.514, ttft=15.415337, rho=0, maxRPM=676453.25}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.514 15.415337 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:52:40.481641706 +0000 UTC m=+138.076996168 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.481Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:52:40.481Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:52:40.481Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:52:40.487Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:52:40.487Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T15:53:40.489Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.470000, beta= 0.044000, gamma= 15.415000, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.470000, beta=0.044000, gamma=15.415000, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T15:53:40.501Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T15:53:40.501Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Updated SystemData for model=unsloth/Meta-Llama-3.1-8B, accelerator=H100: alpha=7.470000, beta=0.044000, gamma=15.415000, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model unsloth/Meta-Llama-3.1-8B, accelerator H100: state=[7.470000, 0.044000, 15.415000, 0.000337]"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=7.514, ttft=15.415337, rho=0, maxRPM=676453.25}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.514 15.415337 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:53:40.501930585 +0000 UTC m=+198.097285054 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.501Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:53:40.501Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:53:40.502Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:53:40.507Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:53:40.507Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T15:54:40.507Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.527Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.527Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.470000, beta= 0.044000, gamma= 15.415000, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.527Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.470000, beta=0.044000, gamma=15.415000, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=false"}
{"level":"INFO","ts":"2025-11-20T15:54:40.528Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.288591"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.528Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.339625, beta=0.044651, gamma=15.424277, delta=0.000337, NIS=3.29"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.528Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.339625, beta=0.044651, gamma=15.424277, delta=0.000337, NIS=3.288591"}
{"level":"INFO","ts":"2025-11-20T15:54:40.528Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.339625, beta: 0.044651, gamma: 15.424277, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.339625,    beta: 0.044651035   },   prefillParms: {    gamma: 15.424277,    delta: 0.0003370271   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.59,    ttftAverage: 22.19,    load: {     arrivalRate: 413,     avgInTokens: 285,     avgOutTokens: 354    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=413; inTk=285; outTk=354; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.410731, ttft=17.728426, rho=0.044899184, maxRPM=611.76215}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.410731 17.728426 {413 285 354}}"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:54:40.538246917 +0000 UTC m=+258.133601379 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.538Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:54:40.538Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:54:40.538Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:54:40.543Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:54:40.543Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T15:55:40.544Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.560Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.560Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.339625, beta= 0.044651, gamma= 15.424277, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.560Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.339625, beta=0.044651, gamma=15.424277, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T15:55:40.562Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 6.074708"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.562Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.439968, beta=0.040194, gamma=15.419739, delta=0.000337, NIS=6.07"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.562Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.439968, beta=0.040194, gamma=15.419739, delta=0.000337, NIS=6.074708"}
{"level":"INFO","ts":"2025-11-20T15:55:40.562Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.439968, beta: 0.040194, gamma: 15.419739, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.439968,    beta: 0.040193737   },   prefillParms: {    gamma: 15.419739,    delta: 0.0003369819   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.93,    ttftAverage: 20.56,    load: {     arrivalRate: 859.85,     avgInTokens: 239,     avgOutTokens: 462    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=859.85; inTk=239; outTk=462; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=100, itl=8.631266, ttft=17.806816, rho=0.055935312, maxRPM=812.3303}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 8.631266 17.806816 {859.85 239 462}}"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:55:40.566723995 +0000 UTC m=+318.162078464 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.566Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:55:40.566Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:55:40.566Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:55:40.572Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:55:40.572Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T15:56:40.573Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.588Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.588Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.439968, beta= 0.040194, gamma= 15.419739, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.588Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.439968, beta=0.040194, gamma=15.419739, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T15:56:40.588Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.527162"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.588Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.954655, beta=0.038860, gamma=15.424583, delta=0.000337, NIS=1.53"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.588Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.954655, beta=0.038860, gamma=15.424583, delta=0.000337, NIS=1.527162"}
{"level":"INFO","ts":"2025-11-20T15:56:40.588Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.954655, beta: 0.038860, gamma: 15.424583, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.954655,    beta: 0.03885984   },   prefillParms: {    gamma: 15.424583,    delta: 0.00033700318   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 8.84,    ttftAverage: 18.48,    load: {     arrivalRate: 481.52,     avgInTokens: 211,     avgOutTokens: 515    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=481.52; inTk=211; outTk=515; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-100, itl=9.526259, ttft=18.300383, rho=0.077036895, maxRPM=600.4899}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.526259 18.300383 {481.52 211 515}}"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:56:40.59850177 +0000 UTC m=+378.193856240 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.598Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:56:40.598Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:56:40.598Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:56:40.603Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:56:40.603Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T15:57:40.604Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.615Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.615Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.954655, beta= 0.038860, gamma= 15.424583, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.615Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.954655, beta=0.038860, gamma=15.424583, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T15:57:40.616Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.785093"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.616Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.643609, beta=0.037444, gamma=15.420686, delta=0.000337, NIS=0.79"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.616Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.643609, beta=0.037444, gamma=15.420686, delta=0.000337, NIS=0.785093"}
{"level":"INFO","ts":"2025-11-20T15:57:40.616Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.643609, beta: 0.037444, gamma: 15.420686, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.6436086,    beta: 0.03744356   },   prefillParms: {    gamma: 15.420686,    delta: 0.0003369922   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.88,    ttftAverage: 20.02,    load: {     arrivalRate: 867.33,     avgInTokens: 244,     avgOutTokens: 423    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=867.33; inTk=244; outTk=423; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.969288, ttft=20.527882, rho=0.11935861, maxRPM=876.26965}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.969288 20.527882 {867.33 244 423}}"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:57:40.625717551 +0000 UTC m=+438.221072014 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.625Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:57:40.625Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:57:40.625Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:57:40.631Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:57:40.631Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T15:58:40.633Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.652Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.652Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.643609, beta= 0.037444, gamma= 15.420686, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.652Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.643609, beta=0.037444, gamma=15.420686, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T15:58:40.652Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.564934"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.652Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.379243, beta=0.036865, gamma=15.417480, delta=0.000337, NIS=0.56"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.652Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.379243, beta=0.036865, gamma=15.417480, delta=0.000337, NIS=0.564934"}
{"level":"INFO","ts":"2025-11-20T15:58:40.652Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.379243, beta: 0.036865, gamma: 15.417480, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.3792434,    beta: 0.03686461   },   prefillParms: {    gamma: 15.41748,    delta: 0.00033699264   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.69,    ttftAverage: 20.04,    load: {     arrivalRate: 828.53,     avgInTokens: 236,     avgOutTokens: 472    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=828.53; inTk=236; outTk=472; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.768809, ttft=20.572636, rho=0.124648504, maxRPM=888.9049}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.768809 20.572636 {828.53 236 472}}"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:58:40.661970561 +0000 UTC m=+498.257325024 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.661Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:58:40.662Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:58:40.662Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:58:40.672Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:58:40.672Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T15:59:40.672Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.688Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.688Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.379243, beta= 0.036865, gamma= 15.417480, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.688Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.379243, beta=0.036865, gamma=15.417480, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T15:59:40.689Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.001243"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.689Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.367834, beta=0.036854, gamma=15.414833, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.689Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.367834, beta=0.036854, gamma=15.414833, delta=0.000337, NIS=0.001243"}
{"level":"INFO","ts":"2025-11-20T15:59:40.689Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.367834, beta: 0.036854, gamma: 15.414833, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.367834,    beta: 0.036854453   },   prefillParms: {    gamma: 15.414833,    delta: 0.00033699756   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.62,    ttftAverage: 19.31,    load: {     arrivalRate: 860.77,     avgInTokens: 209,     avgOutTokens: 435    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=860.77; inTk=209; outTk=435; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.623331, ttft=19.725311, rho=0.11757835, maxRPM=968.99023}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.623331 19.725311 {860.77 209 435}}"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 15:59:40.698511834 +0000 UTC m=+558.293866296 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.698Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T15:59:40.698Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T15:59:40.698Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T15:59:40.707Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T15:59:40.707Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:00:40.708Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.730Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.730Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.367834, beta= 0.036854, gamma= 15.414833, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.730Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.367834, beta=0.036854, gamma=15.414833, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:00:40.731Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.137901"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.731Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.439089, beta=0.037798, gamma=15.400323, delta=0.000337, NIS=0.14"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.731Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.439089, beta=0.037798, gamma=15.400323, delta=0.000337, NIS=0.137901"}
{"level":"INFO","ts":"2025-11-20T16:00:40.731Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.439089, beta: 0.037798, gamma: 15.400323, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.4390893,    beta: 0.03779814   },   prefillParms: {    gamma: 15.400323,    delta: 0.00033697966   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.61,    ttftAverage: 22.31,    load: {     arrivalRate: 1362.43,     avgInTokens: 245,     avgOutTokens: 412    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1362.43; inTk=245; outTk=412; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=100, itl=9.08796, ttft=19.001844, rho=0.083248235, maxRPM=969.5356}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.08796 19.001844 {1362.43 245 412}}"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:00:40.736227332 +0000 UTC m=+618.331581795 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.736Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:00:40.736Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:00:40.736Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:00:40.741Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:00:40.741Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:01:40.742Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.754Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.754Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.439089, beta= 0.037798, gamma= 15.400323, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.754Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.439089, beta=0.037798, gamma=15.400323, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-20T16:01:40.755Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=7.439089, beta=0.037798, gamma=15.400323, delta=0.000337, NIS=0.137901). Validation error: tuning validation failed: normalized innovation squared (NIS=7.79) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.755Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=7.439089, beta=0.037798, gamma=15.400323, delta=0.000337 | NIS=0.137901 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-20T16:01:40.755Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.755Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.439089, beta=0.037798, gamma=15.400323, delta=0.000337, NIS=0.14"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.755Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.439089,    beta: 0.037798   },   prefillParms: {    gamma: 15.400323,    delta: 0.000337   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.01,    ttftAverage: 21.48,    load: {     arrivalRate: 1116.33,     avgInTokens: 222,     avgOutTokens: 541    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1116.33; inTk=222; outTk=541; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.23756, ttft=18.960058, rho=0.09097876, maxRPM=738.8942}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.23756 18.960058 {1116.33 222 541}}"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:01:40.76457569 +0000 UTC m=+678.359930160 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.764Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:01:40.764Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:01:40.764Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:01:40.770Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:01:40.770Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:02:40.771Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.792Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.792Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.439089, beta= 0.037798, gamma= 15.400323, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.792Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.439089, beta=0.037798, gamma=15.400323, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:02:40.792Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.449809"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.792Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.269685, beta=0.034267, gamma=15.410382, delta=0.000337, NIS=2.45"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.792Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.269685, beta=0.034267, gamma=15.410382, delta=0.000337, NIS=2.449809"}
{"level":"INFO","ts":"2025-11-20T16:02:40.792Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.269685, beta: 0.034267, gamma: 15.410382, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.801Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.801Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.801Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.269685,    beta: 0.03426743   },   prefillParms: {    gamma: 15.410382,    delta: 0.00033700635   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.4,    ttftAverage: 19.57,    load: {     arrivalRate: 844.81,     avgInTokens: 260,     avgOutTokens: 415    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=844.81; inTk=260; outTk=415; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.230127, ttft=17.86623, rho=0.052788787, maxRPM=713.89276}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.230127 17.86623 {844.81 260 415}}"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:02:40.802100297 +0000 UTC m=+738.397454760 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.802Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:02:40.802Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:02:40.802Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:02:40.807Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:02:40.807Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:03:40.808Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.825Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.825Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.269685, beta= 0.034267, gamma= 15.410382, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.825Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.269685, beta=0.034267, gamma=15.410382, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:03:40.826Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.181713"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.826Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.739792, beta=0.032209, gamma=15.400906, delta=0.000337, NIS=2.18"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.826Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.739792, beta=0.032209, gamma=15.400906, delta=0.000337, NIS=2.181713"}
{"level":"INFO","ts":"2025-11-20T16:03:40.826Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.739792, beta: 0.032209, gamma: 15.400906, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.739792,    beta: 0.032208614   },   prefillParms: {    gamma: 15.400906,    delta: 0.0003369861   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.66,    ttftAverage: 19.69,    load: {     arrivalRate: 1730.97,     avgInTokens: 243,     avgOutTokens: 447    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1730.97; inTk=243; outTk=447; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.815497, ttft=20.678207, rho=0.12391734, maxRPM=926.20337}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.815497 20.678207 {1730.97 243 447}}"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:03:40.835604514 +0000 UTC m=+798.430958983 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.835Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:03:40.835Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:03:40.835Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:03:40.840Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:03:40.840Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:04:40.841Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.863Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.863Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.739792, beta= 0.032209, gamma= 15.400906, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.863Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.739792, beta=0.032209, gamma=15.400906, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:04:40.864Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.060487"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.864Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.649166, beta=0.032101, gamma=15.392145, delta=0.000337, NIS=0.06"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.864Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.649166, beta=0.032101, gamma=15.392145, delta=0.000337, NIS=0.060487"}
{"level":"INFO","ts":"2025-11-20T16:04:40.864Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.649166, beta: 0.032101, gamma: 15.392145, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.649166,    beta: 0.03210144   },   prefillParms: {    gamma: 15.392145,    delta: 0.00033699308   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.73,    ttftAverage: 19.51,    load: {     arrivalRate: 1698.17,     avgInTokens: 227,     avgOutTokens: 467    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1698.17; inTk=227; outTk=467; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.755791, ttft=20.412212, rho=0.12621878, maxRPM=925.8483}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.755791 20.412212 {1698.17 227 467}}"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:04:40.873534602 +0000 UTC m=+858.468889072 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.873Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:04:40.873Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:04:40.873Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:04:40.879Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:04:40.879Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:05:40.881Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.899Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.899Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.649166, beta= 0.032101, gamma= 15.392145, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.899Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.649166, beta=0.032101, gamma=15.392145, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:05:40.900Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.053421"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.900Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.563023, beta=0.032047, gamma=15.381480, delta=0.000337, NIS=0.05"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.900Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.563023, beta=0.032047, gamma=15.381480, delta=0.000337, NIS=0.053421"}
{"level":"INFO","ts":"2025-11-20T16:05:40.900Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.563023, beta: 0.032047, gamma: 15.381480, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.904Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.5630226,    beta: 0.032046583   },   prefillParms: {    gamma: 15.38148,    delta: 0.00033699308   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.55,    ttftAverage: 18.99,    load: {     arrivalRate: 1731.58,     avgInTokens: 218,     avgOutTokens: 446    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1731.58; inTk=218; outTk=446; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.574568, ttft=19.992804, rho=0.12064344, maxRPM=1007.09705}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.574568 19.992804 {1731.58 218 446}}"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:05:40.905262861 +0000 UTC m=+918.500617326 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.905Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:05:40.905Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:05:40.905Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:05:40.915Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:05:40.915Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:06:40.917Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.941Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.941Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.563023, beta= 0.032047, gamma= 15.381480, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.941Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.563023, beta=0.032047, gamma=15.381480, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:06:40.943Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.927866"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.943Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.756903, beta=0.034528, gamma=15.359092, delta=0.000337, NIS=0.93"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.943Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.756903, beta=0.034528, gamma=15.359092, delta=0.000337, NIS=0.927866"}
{"level":"INFO","ts":"2025-11-20T16:06:40.943Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.756903, beta: 0.034528, gamma: 15.359092, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.7569027,    beta: 0.03452848   },   prefillParms: {    gamma: 15.359092,    delta: 0.00033698446   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.85,    ttftAverage: 22.96,    load: {     arrivalRate: 2794.98,     avgInTokens: 248,     avgOutTokens: 421    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=2794.98; inTk=248; outTk=421; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=200, itl=9.384023, ttft=19.297346, rho=0.090085946, maxRPM=909.26764}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 9.384023 19.297346 {2794.98 248 421}}"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:06:40.953511288 +0000 UTC m=+978.548865757 H100 4}"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.953Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:06:40.953Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:06:40.953Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:06:40.958Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:06:40.958Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:07:40.959Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.977Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.977Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.756903, beta= 0.034528, gamma= 15.359092, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.977Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.756903, beta=0.034528, gamma=15.359092, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:07:40.978Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 5.506335"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.978Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=9.001328, beta=0.030564, gamma=15.373440, delta=0.000337, NIS=5.51"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.978Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.001328, beta=0.030564, gamma=15.373440, delta=0.000337, NIS=5.506335"}
{"level":"INFO","ts":"2025-11-20T16:07:40.978Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.001328, beta: 0.030564, gamma: 15.373440, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.001328,    beta: 0.030564168   },   prefillParms: {    gamma: 15.37344,    delta: 0.00033701165   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 10.88,    ttftAverage: 21.02,    load: {     arrivalRate: 2230.33,     avgInTokens: 224,     avgOutTokens: 524    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=2230.33; inTk=224; outTk=524; sol=1, sat=false, alloc={acc=H100; numRep=7; maxBatch=512; cost=700, val=300, itl=9.872795, ttft=17.52588, rho=0.053735755, maxRPM=362.14365}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=7, limit=0, cost=700 \ntotalCost=700 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 7 512 700 9.872795 17.52588 {2230.33 224 524}}"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:07:40.9874586 +0000 UTC m=+1038.582813062 H100 7}"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.987Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:07:40.987Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 7, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:07:40.987Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:07:40.992Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:07:40.993Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:08:40.997Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.032Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.032Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.001328, beta= 0.030564, gamma= 15.373440, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.032Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.001328, beta=0.030564, gamma=15.373440, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:08:41.032Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.132624"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.032Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=9.169542, beta=0.030168, gamma=15.410619, delta=0.000337, NIS=0.13"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.032Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.169542, beta=0.030168, gamma=15.410619, delta=0.000337, NIS=0.132624"}
{"level":"INFO","ts":"2025-11-20T16:08:41.032Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.169542, beta: 0.030168, gamma: 15.410619, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.169542,    beta: 0.030168138   },   prefillParms: {    gamma: 15.410619,    delta: 0.00033700577   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 7,    maxBatch: 256,    cost: 700,    itlAverage: 9.76,    ttftAverage: 19.85,    load: {     arrivalRate: 1733.99,     avgInTokens: 245,     avgOutTokens: 431    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1733.99; inTk=245; outTk=431; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=512; cost=500, val=-200, itl=9.948719, ttft=17.543127, rho=0.048491802, maxRPM=368.63528}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 512 500 9.948719 17.543127 {1733.99 245 431}}"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:08:41.0428049 +0000 UTC m=+1098.638159370 H100 5}"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.042Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:08:41.042Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 7, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:08:41.042Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:08:41.048Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:08:41.048Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:09:41.049Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.062Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.062Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.169542, beta= 0.030168, gamma= 15.410619, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.062Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.169542, beta=0.030168, gamma=15.410619, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:09:41.062Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.037751"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.062Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.722628, beta=0.029309, gamma=15.429298, delta=0.000337, NIS=1.04"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.062Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.722628, beta=0.029309, gamma=15.429298, delta=0.000337, NIS=1.037751"}
{"level":"INFO","ts":"2025-11-20T16:09:41.062Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.722628, beta: 0.029309, gamma: 15.429298, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.072Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.722628,    beta: 0.029308736   },   prefillParms: {    gamma: 15.429298,    delta: 0.000337005   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 9.81,    ttftAverage: 20.22,    load: {     arrivalRate: 2813.21,     avgInTokens: 246,     avgOutTokens: 426    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=2813.21; inTk=246; outTk=426; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=512; cost=500, val=0, itl=9.915273, ttft=18.802835, rho=0.07752433, maxRPM=598.49536}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 512 500 9.915273 18.802835 {2813.21 246 426}}"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:09:41.073243613 +0000 UTC m=+1158.668598082 H100 5}"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.073Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:09:41.073Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:09:41.073Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:09:41.079Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:09:41.079Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:10:41.079Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.103Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.103Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.722628, beta= 0.029309, gamma= 15.429298, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.103Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.722628, beta=0.029309, gamma=15.429298, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:10:41.104Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.980149"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.104Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.131642, beta=0.028533, gamma=15.428106, delta=0.000337, NIS=1.98"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.104Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.131642, beta=0.028533, gamma=15.428106, delta=0.000337, NIS=1.980149"}
{"level":"INFO","ts":"2025-11-20T16:10:41.104Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.131642, beta: 0.028533, gamma: 15.428106, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.131642,    beta: 0.028532624   },   prefillParms: {    gamma: 15.428106,    delta: 0.000336997   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 9.24,    ttftAverage: 18.88,    load: {     arrivalRate: 3109.76,     avgInTokens: 237,     avgOutTokens: 442    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=3109.76; inTk=237; outTk=442; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=-100, itl=9.758614, ttft=19.98231, rho=0.10941686, maxRPM=873.20886}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 9.758614 19.98231 {3109.76 237 442}}"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:10:41.113985391 +0000 UTC m=+1218.709339854 H100 4}"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.113Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.114Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:10:41.114Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:10:41.114Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:10:41.119Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:10:41.119Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:11:41.120Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.134Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.134Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.131642, beta= 0.028533, gamma= 15.428106, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.134Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.131642, beta=0.028533, gamma=15.428106, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:11:41.135Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.203336"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.135Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.959790, beta=0.028261, gamma=15.400137, delta=0.000337, NIS=0.20"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.135Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.959790, beta=0.028261, gamma=15.400137, delta=0.000337, NIS=0.203336"}
{"level":"INFO","ts":"2025-11-20T16:11:41.135Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.959790, beta: 0.028261, gamma: 15.400137, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.95979,    beta: 0.028260618   },   prefillParms: {    gamma: 15.400137,    delta: 0.0003369889   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 9.39,    ttftAverage: 17.67,    load: {     arrivalRate: 3020.2,     avgInTokens: 233,     avgOutTokens: 431    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=3020.2; inTk=233; outTk=431; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=0, itl=9.438333, ttft=19.508072, rho=0.1002307, maxRPM=988.5388}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 9.438333 19.508072 {3020.2 233 431}}"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:11:41.145370206 +0000 UTC m=+1278.740724669 H100 4}"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.145Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:11:41.145Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:11:41.145Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:11:41.151Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:11:41.151Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:12:41.152Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.170Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.170Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.959790, beta= 0.028261, gamma= 15.400137, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.170Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.959790, beta=0.028261, gamma=15.400137, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:12:41.171Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.045073"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.171Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.870873, beta=0.028348, gamma=15.393253, delta=0.000337, NIS=0.05"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.171Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.870873, beta=0.028348, gamma=15.393253, delta=0.000337, NIS=0.045073"}
{"level":"INFO","ts":"2025-11-20T16:12:41.171Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.870873, beta: 0.028348, gamma: 15.393253, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.870873,    beta: 0.028347544   },   prefillParms: {    gamma: 15.393253,    delta: 0.00033699797   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 8.96,    ttftAverage: 17.93,    load: {     arrivalRate: 2133.95,     avgInTokens: 226,     avgOutTokens: 478    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=2133.95; inTk=226; outTk=478; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=512; cost=300, val=-100, itl=9.415064, ttft=19.542042, rho=0.10444055, maxRPM=928.0694}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 512 300 9.415064 19.542042 {2133.95 226 478}}"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:12:41.181564902 +0000 UTC m=+1338.776919365 H100 3}"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.181Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:12:41.181Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:12:41.181Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:12:41.187Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:12:41.187Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:13:41.188Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.201Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.201Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.870873, beta= 0.028348, gamma= 15.393253, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.201Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.870873, beta=0.028348, gamma=15.393253, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:13:41.201Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.000040"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.201Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.868603, beta=0.028350, gamma=15.391977, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.201Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.868603, beta=0.028350, gamma=15.391977, delta=0.000337, NIS=0.000040"}
{"level":"INFO","ts":"2025-11-20T16:13:41.201Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.868603, beta: 0.028350, gamma: 15.391977, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.868603,    beta: 0.028349757   },   prefillParms: {    gamma: 15.391977,    delta: 0.00033699974   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 8.8,    ttftAverage: 17.94,    load: {     arrivalRate: 1404.97,     avgInTokens: 237,     avgOutTokens: 463    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1404.97; inTk=237; outTk=463; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=-100, itl=9.334921, ttft=19.522991, rho=0.099067226, maxRPM=958.9645}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.334921 19.522991 {1404.97 237 463}}"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:13:41.210742643 +0000 UTC m=+1398.806097112 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.210Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:13:41.210Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:13:41.210Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:13:41.216Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:13:41.216Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:14:41.217Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.233Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.234Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.868603, beta= 0.028350, gamma= 15.391977, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.234Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.868603, beta=0.028350, gamma=15.391977, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:14:41.234Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.001458"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.234Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.861027, beta=0.028311, gamma=15.378724, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.234Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.861027, beta=0.028311, gamma=15.378724, delta=0.000337, NIS=0.001458"}
{"level":"INFO","ts":"2025-11-20T16:14:41.234Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.861027, beta: 0.028311, gamma: 15.378724, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.861027,    beta: 0.028311197   },   prefillParms: {    gamma: 15.378724,    delta: 0.0003369951   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.53,    ttftAverage: 19.44,    load: {     arrivalRate: 1637.62,     avgInTokens: 243,     avgOutTokens: 445    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1637.62; inTk=243; outTk=445; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.532357, ttft=20.213028, rho=0.113348134, maxRPM=1002.5906}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.532357 20.213028 {1637.62 243 445}}"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:14:41.243979559 +0000 UTC m=+1458.839334021 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.243Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:14:41.244Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:14:41.244Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:14:41.249Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:14:41.249Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:15:41.250Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.269Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.269Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.861027, beta= 0.028311, gamma= 15.378724, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.269Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.861027, beta=0.028311, gamma=15.378724, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:15:41.269Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.003014"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.269Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.879721, beta=0.028326, gamma=15.367590, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.269Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.879721, beta=0.028326, gamma=15.367590, delta=0.000337, NIS=0.003014"}
{"level":"INFO","ts":"2025-11-20T16:15:41.269Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.879721, beta: 0.028326, gamma: 15.367590, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.8797207,    beta: 0.028326377   },   prefillParms: {    gamma: 15.36759,    delta: 0.00033699628   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.47,    ttftAverage: 19.49,    load: {     arrivalRate: 1627.32,     avgInTokens: 252,     avgOutTokens: 427    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1627.32; inTk=252; outTk=427; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.464568, ttft=20.118994, rho=0.10732326, maxRPM=1034.8848}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.464568 20.118994 {1627.32 252 427}}"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:15:41.279531749 +0000 UTC m=+1518.874886212 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.279Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:15:41.279Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:15:41.279Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:15:41.285Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:15:41.285Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:16:41.286Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.301Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.301Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.879721, beta= 0.028326, gamma= 15.367590, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.301Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.879721, beta=0.028326, gamma=15.367590, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:16:41.302Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.010767"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.302Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.845679, beta=0.028247, gamma=15.348835, delta=0.000337, NIS=0.01"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.302Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.845679, beta=0.028247, gamma=15.348835, delta=0.000337, NIS=0.010767"}
{"level":"INFO","ts":"2025-11-20T16:16:41.302Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.845679, beta: 0.028247, gamma: 15.348835, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.845679,    beta: 0.02824697   },   prefillParms: {    gamma: 15.348835,    delta: 0.00033699276   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.63,    ttftAverage: 19.48,    load: {     arrivalRate: 1638.22,     avgInTokens: 241,     avgOutTokens: 474    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1638.22; inTk=241; outTk=474; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.640203, ttft=20.508425, rho=0.12212858, maxRPM=950.4349}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.640203 20.508425 {1638.22 241 474}}"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:16:41.312768355 +0000 UTC m=+1578.908122818 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.312Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:16:41.312Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:16:41.312Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:16:41.319Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:16:41.319Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:17:41.319Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.332Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.332Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.845679, beta= 0.028247, gamma= 15.348835, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.332Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.845679, beta=0.028247, gamma=15.348835, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:17:41.333Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.005260"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.333Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.820190, beta=0.028264, gamma=15.330539, delta=0.000337, NIS=0.01"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.333Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.820190, beta=0.028264, gamma=15.330539, delta=0.000337, NIS=0.005260"}
{"level":"INFO","ts":"2025-11-20T16:17:41.333Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.820190, beta: 0.028264, gamma: 15.330539, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.8201904,    beta: 0.028264232   },   prefillParms: {    gamma: 15.330539,    delta: 0.00033699404   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.35,    ttftAverage: 18.94,    load: {     arrivalRate: 1513.75,     avgInTokens: 250,     avgOutTokens: 451    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1513.75; inTk=250; outTk=451; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.3567915, ttft=19.910755, rho=0.10422964, maxRPM=1010.067}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.3567915 19.910755 {1513.75 250 451}}"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:17:41.343692217 +0000 UTC m=+1638.939046680 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.343Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:17:41.343Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:17:41.343Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:17:41.348Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:17:41.348Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:18:41.350Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.366Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.366Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.820190, beta= 0.028264, gamma= 15.330539, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.366Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.820190, beta=0.028264, gamma=15.330539, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:18:41.367Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.116112"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.367Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.968696, beta=0.027971, gamma=15.330662, delta=0.000337, NIS=0.12"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.367Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.968696, beta=0.027971, gamma=15.330662, delta=0.000337, NIS=0.116112"}
{"level":"INFO","ts":"2025-11-20T16:18:41.367Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.968696, beta: 0.027971, gamma: 15.330662, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.381Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.968696,    beta: 0.027971342   },   prefillParms: {    gamma: 15.330662,    delta: 0.00033700065   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.15,    ttftAverage: 18.48,    load: {     arrivalRate: 1118.7,     avgInTokens: 226,     avgOutTokens: 468    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1118.7; inTk=226; outTk=468; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.110976, ttft=18.440933, rho=0.077807665, maxRPM=916.09216}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.110976 18.440933 {1118.7 226 468}}"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:18:41.38265278 +0000 UTC m=+1698.978007250 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.382Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:18:41.382Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:18:41.382Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:18:41.389Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:18:41.389Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:19:41.389Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.402Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.402Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.968696, beta= 0.027971, gamma= 15.330662, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.402Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.968696, beta=0.027971, gamma=15.330662, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:19:41.402Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.044671"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.402Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.879568, beta=0.028101, gamma=15.324263, delta=0.000337, NIS=0.04"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.402Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.879568, beta=0.028101, gamma=15.324263, delta=0.000337, NIS=0.044671"}
{"level":"INFO","ts":"2025-11-20T16:19:41.402Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.879568, beta: 0.028101, gamma: 15.324263, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.879568,    beta: 0.02810124   },   prefillParms: {    gamma: 15.324263,    delta: 0.00033699878   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 8.75,    ttftAverage: 17.37,    load: {     arrivalRate: 889.84,     avgInTokens: 222,     avgOutTokens: 473    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=889.84; inTk=222; outTk=473; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-100, itl=9.854792, ttft=20.582886, rho=0.13533112, maxRPM=942.3003}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.854792 20.582886 {889.84 222 473}}"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:19:41.412680504 +0000 UTC m=+1759.008034973 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.412Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:19:41.412Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:19:41.412Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:19:41.425Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:19:41.425Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:20:41.426Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.455Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.455Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.879568, beta= 0.028101, gamma= 15.324263, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.455Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.879568, beta=0.028101, gamma=15.324263, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:20:41.455Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.176399"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.455Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.011617, beta=0.028978, gamma=15.325970, delta=0.000337, NIS=0.18"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.455Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.011617, beta=0.028978, gamma=15.325970, delta=0.000337, NIS=0.176399"}
{"level":"INFO","ts":"2025-11-20T16:20:41.455Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.011617, beta: 0.028978, gamma: 15.325970, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.011617,    beta: 0.028977754   },   prefillParms: {    gamma: 15.32597,    delta: 0.00033700152   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.83,    ttftAverage: 20.34,    load: {     arrivalRate: 832.53,     avgInTokens: 241,     avgOutTokens: 443    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=832.53; inTk=241; outTk=443; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.7883415, ttft=20.305683, rho=0.117799535, maxRPM=913.56433}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.7883415 20.305683 {832.53 241 443}}"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:20:41.460571275 +0000 UTC m=+1819.055925749 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.460Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:20:41.460Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:20:41.460Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:20:41.465Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:20:41.465Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:21:41.466Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.522Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.522Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.011617, beta= 0.028978, gamma= 15.325970, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.522Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.011617, beta=0.028978, gamma=15.325970, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:21:41.523Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.133094"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.523Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.899639, beta=0.028350, gamma=15.316545, delta=0.000337, NIS=0.13"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.523Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.899639, beta=0.028350, gamma=15.316545, delta=0.000337, NIS=0.133094"}
{"level":"INFO","ts":"2025-11-20T16:21:41.523Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.899639, beta: 0.028350, gamma: 15.316545, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.8996387,    beta: 0.02834951   },   prefillParms: {    gamma: 15.3165455,    delta: 0.00033699544   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.95,    ttftAverage: 20.18,    load: {     arrivalRate: 916.73,     avgInTokens: 214,     avgOutTokens: 475    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=916.73; inTk=214; outTk=475; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.987469, ttft=20.627682, rho=0.14188688, maxRPM=921.15045}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.987469 20.627682 {916.73 214 475}}"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:21:41.533837132 +0000 UTC m=+1879.129191595 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.533Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:21:41.533Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:21:41.533Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:21:41.540Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:21:41.540Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:22:41.541Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.557Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.557Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.899639, beta= 0.028350, gamma= 15.316545, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.557Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.899639, beta=0.028350, gamma=15.316545, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:22:41.558Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.009648"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.558Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.941596, beta=0.028303, gamma=15.306728, delta=0.000337, NIS=0.01"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.558Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.941596, beta=0.028303, gamma=15.306728, delta=0.000337, NIS=0.009648"}
{"level":"INFO","ts":"2025-11-20T16:22:41.558Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.941596, beta: 0.028303, gamma: 15.306728, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.941596,    beta: 0.028303359   },   prefillParms: {    gamma: 15.306728,    delta: 0.00033699724   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.68,    ttftAverage: 20.12,    load: {     arrivalRate: 808.04,     avgInTokens: 256,     avgOutTokens: 460    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=808.04; inTk=256; outTk=460; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.66949, ttft=20.57351, rho=0.11728336, maxRPM=933.21094}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.66949 20.57351 {808.04 256 460}}"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:22:41.567270302 +0000 UTC m=+1939.162624765 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.567Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:22:41.567Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:22:41.567Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:22:41.573Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:22:41.573Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:23:41.574Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.590Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.590Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.941596, beta= 0.028303, gamma= 15.306728, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.590Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.941596, beta=0.028303, gamma=15.306728, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:23:41.590Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.008650"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.590Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.908777, beta=0.028263, gamma=15.287687, delta=0.000337, NIS=0.01"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.590Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.908777, beta=0.028263, gamma=15.287687, delta=0.000337, NIS=0.008650"}
{"level":"INFO","ts":"2025-11-20T16:23:41.590Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.908777, beta: 0.028263, gamma: 15.287687, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.602Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.602Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.602Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.602Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.9087768,    beta: 0.028263383   },   prefillParms: {    gamma: 15.287687,    delta: 0.00033699395   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.602Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.602Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.71,    ttftAverage: 19.49,    load: {     arrivalRate: 861.03,     avgInTokens: 235,     avgOutTokens: 451    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.603Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=861.03; inTk=235; outTk=451; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.719224, ttft=20.360535, rho=0.12315675, maxRPM=968.65656}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.603Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.719224 20.360535 {861.03 235 451}}"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.603Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.603Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.603Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:23:41.603036437 +0000 UTC m=+1999.198390900 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.603Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.603Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:23:41.603Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:23:41.603Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:23:41.609Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:23:41.609Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:24:41.610Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.624Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.624Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.908777, beta= 0.028263, gamma= 15.287687, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.624Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=7.908777, beta=0.028263, gamma=15.287687, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T16:24:41.625Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.538688"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.625Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.551667, beta=0.024930, gamma=15.315166, delta=0.000337, NIS=1.54"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.625Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.551667, beta=0.024930, gamma=15.315166, delta=0.000337, NIS=1.538688"}
{"level":"INFO","ts":"2025-11-20T16:24:41.625Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.551667, beta: 0.024930, gamma: 15.315166, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.551667,    beta: 0.024930298   },   prefillParms: {    gamma: 15.3151655,    delta: 0.00033700303   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.28,    ttftAverage: 18.35,    load: {     arrivalRate: 242.35,     avgInTokens: 192,     avgOutTokens: 612    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=242.35; inTk=192; outTk=612; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.140685, ttft=16.843916, rho=0.044192612, maxRPM=558.9279}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.140685 16.843916 {242.35 192 612}}"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:24:41.629686765 +0000 UTC m=+2059.225041233 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.629Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:24:41.629Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:24:41.629Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:24:41.636Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:24:41.636Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T16:25:41.636Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), auto-guess=false, tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.551667, beta= 0.024930, gamma= 15.315166, delta= 0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=8.551667, beta=0.024930, gamma=15.315166, delta=0.000337 | SLO targets: TTFT=1000.00ms, ITL=10.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-20T16:25:41.656Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T16:25:41.656Z","msg":"Using tuned parameters from status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Updated SystemData for model=unsloth/Meta-Llama-3.1-8B, accelerator=H100: alpha=8.551667, beta=0.024930, gamma=15.315166, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model unsloth/Meta-Llama-3.1-8B, accelerator H100: state=[8.551667, 0.024930, 15.315166, 0.000337]"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.551667,    beta: 0.02493   },   prefillParms: {    gamma: 15.315166,    delta: 0.000337   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=8.576597, ttft=15.315503, rho=0, maxRPM=838626.44}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 8.576597 15.315503 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 16:25:41.656623014 +0000 UTC m=+2119.251977476 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.656Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T16:25:41.656Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T16:25:41.656Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T16:25:41.661Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T16:25:41.661Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
