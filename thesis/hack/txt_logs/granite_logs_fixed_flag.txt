{"level":"INFO","ts":"2025-11-20T04:33:10.311Z","msg":"Zap logger initialized"}
{"level":"INFO","ts":"2025-11-20T04:33:10.376Z","msg":"Creating metrics emitter instance"}
{"level":"INFO","ts":"2025-11-20T04:33:10.376Z","msg":"Metrics emitter created successfully"}
{"level":"INFO","ts":"2025-11-20T04:33:10.376Z","msg":"Using Prometheus configuration from environment variablesaddresshttps://thanos-querier.openshift-monitoring.svc.cluster.local:9091"}
{"level":"WARN","ts":"2025-11-20T04:33:10.376Z","msg":"TLS certificate verification is disabled - this is not recommended for production"}
{"level":"INFO","ts":"2025-11-20T04:33:10.376Z","msg":"Initializing Prometheus client -> address: https://thanos-querier.openshift-monitoring.svc.cluster.local:9091 tls_enabled: true"}
{"level":"INFO","ts":"2025-11-20T04:33:10.376Z","msg":"CA certificate loaded successfullypath/etc/ssl/certs/prometheus-ca.crt"}
{"level":"INFO","ts":"2025-11-20T04:33:10.376Z","msg":"TLS configuration applied to Prometheus HTTPS transport"}
{"level":"INFO","ts":"2025-11-20T04:33:10.376Z","msg":"Bearer token loaded from filepath/var/run/secrets/kubernetes.io/serviceaccount/token"}
{"level":"INFO","ts":"2025-11-20T04:33:10.415Z","msg":"Prometheus API validation successful with queryqueryup"}
{"level":"INFO","ts":"2025-11-20T04:33:10.415Z","msg":"Prometheus client and API wrapper initialized and validated successfully"}
{"level":"INFO","ts":"2025-11-20T04:33:10.415Z","msg":"Starting manager"}
{"level":"INFO","ts":"2025-11-20T04:33:10.415Z","msg":"Registering custom metrics with Prometheus registry"}
{"level":"info","ts":"2025-11-20T04:33:10Z","logger":"controller-runtime.metrics","msg":"Starting metrics server"}
{"level":"INFO","ts":"2025-11-20T04:33:10.415Z","msg":"disabling http/2"}
{"level":"info","ts":"2025-11-20T04:33:10Z","msg":"starting server","name":"health probe","addr":"[::]:8081"}
I1120 04:33:10.416044       1 leaderelection.go:257] attempting to acquire leader lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai...
{"level":"info","ts":"2025-11-20T04:33:10Z","logger":"controller-runtime.metrics","msg":"Serving metrics server","bindAddress":":8443","secure":true}
I1120 04:33:26.833110       1 leaderelection.go:271] successfully acquired lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai
{"level":"info","ts":"2025-11-20T04:33:26Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1.ConfigMap"}
{"level":"info","ts":"2025-11-20T04:33:26Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1alpha1.VariantAutoscaling"}
{"level":"DEBUG","ts":"2025-11-20T04:33:27.849Z","msg":"ConfigMap watch enqueueing requests: count=1"}
{"level":"info","ts":"2025-11-20T04:33:27Z","msg":"Starting Controller","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling"}
{"level":"info","ts":"2025-11-20T04:33:27Z","msg":"Starting workers","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","worker count":1}
{"level":"INFO","ts":"2025-11-20T04:33:27.877Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"ERROR","ts":"2025-11-20T04:33:27.978Z","msg":"Deployment.apps \"ms-inference-scheduling-llm-d-modelservice-decode\" not foundfailed to get Deployment after retries - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:33:27.978Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:33:27.978Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:33:27.978Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:33:27.978Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:33:27.978Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:33:27.978Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:33:27.978Z","msg":"System data prepared for optimization: - { servers: []}"}
{"level":"ERROR","ts":"2025-11-20T04:33:27.978Z","msg":"no feasible allocations found for all variants: unable to perform model optimization, skipping this iteration"}
{"level":"INFO","ts":"2025-11-20T04:34:27.979Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"ERROR","ts":"2025-11-20T04:34:27.979Z","msg":"Deployment.apps \"ms-inference-scheduling-llm-d-modelservice-decode\" not foundfailed to get Deployment after retries - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:34:27.979Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:34:27.979Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:34:27.979Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:34:27.979Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:34:27.979Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:34:27.979Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:34:27.979Z","msg":"System data prepared for optimization: - { servers: []}"}
{"level":"ERROR","ts":"2025-11-20T04:34:27.979Z","msg":"no feasible allocations found for all variants: unable to perform model optimization, skipping this iteration"}
{"level":"INFO","ts":"2025-11-20T04:35:27.982Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"ERROR","ts":"2025-11-20T04:35:27.982Z","msg":"Deployment.apps \"ms-inference-scheduling-llm-d-modelservice-decode\" not foundfailed to get Deployment after retries - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:35:27.982Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:35:27.982Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:35:27.982Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:35:27.982Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:35:27.982Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:35:27.982Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:35:27.982Z","msg":"System data prepared for optimization: - { servers: []}"}
{"level":"ERROR","ts":"2025-11-20T04:35:27.982Z","msg":"no feasible allocations found for all variants: unable to perform model optimization, skipping this iteration"}
{"level":"INFO","ts":"2025-11-20T04:36:24.920Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"ERROR","ts":"2025-11-20T04:36:24.920Z","msg":"Deployment.apps \"ms-inference-scheduling-llm-d-modelservice-decode\" not foundfailed to get Deployment after retries - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:36:24.920Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:36:24.920Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:24.920Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:24.920Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:24.920Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:24.920Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:24.920Z","msg":"System data prepared for optimization: - { servers: []}"}
{"level":"ERROR","ts":"2025-11-20T04:36:24.920Z","msg":"no feasible allocations found for all variants: unable to perform model optimization, skipping this iteration"}
{"level":"INFO","ts":"2025-11-20T04:36:25.055Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"ERROR","ts":"2025-11-20T04:36:25.055Z","msg":"Deployment.apps \"ms-inference-scheduling-llm-d-modelservice-decode\" not foundfailed to get Deployment after retries - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:36:25.055Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:36:25.055Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:25.055Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:25.055Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:25.055Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:25.055Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:25.055Z","msg":"System data prepared for optimization: - { servers: []}"}
{"level":"ERROR","ts":"2025-11-20T04:36:25.055Z","msg":"no feasible allocations found for all variants: unable to perform model optimization, skipping this iteration"}
{"level":"INFO","ts":"2025-11-20T04:36:27.983Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"ERROR","ts":"2025-11-20T04:36:27.983Z","msg":"Deployment.apps \"ms-inference-scheduling-llm-d-modelservice-decode\" not foundfailed to get Deployment after retries - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:36:27.983Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:36:27.983Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:27.983Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:27.983Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:27.983Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:27.984Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:36:27.984Z","msg":"System data prepared for optimization: - { servers: []}"}
{"level":"ERROR","ts":"2025-11-20T04:36:27.984Z","msg":"no feasible allocations found for all variants: unable to perform model optimization, skipping this iteration"}
{"level":"INFO","ts":"2025-11-20T04:37:27.985Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"INFO","ts":"2025-11-20T04:37:27.991Z","msg":"Set ownerReference on VariantAutoscaling - variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, owner: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"WARN","ts":"2025-11-20T04:37:28.024Z","msg":"Metrics unavailable, skipping optimization for variant","variant":"ms-inference-scheduling-llm-d-modelservice-decode","namespace":"llm-d-inference-scheduler","model":"ibm-granite/granite-3.3-8b-instruct","reason":"MetricsMissing","troubleshooting":"No vLLM metrics found for model 'ibm-granite/granite-3.3-8b-instruct' in namespace 'llm-d-inference-scheduler'. Check: (1) ServiceMonitor exists in monitoring namespace, (2) ServiceMonitor selector matches vLLM service labels, (3) vLLM pods are running and exposing /metrics endpoint, (4) Prometheus is scraping the monitoring namespace"}
{"level":"DEBUG","ts":"2025-11-20T04:37:28.025Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:37:28.025Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:37:28.025Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:37:28.025Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:37:28.025Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:37:28.025Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:37:28.025Z","msg":"System data prepared for optimization: - { servers: []}"}
{"level":"ERROR","ts":"2025-11-20T04:37:28.025Z","msg":"no feasible allocations found for all variants: unable to perform model optimization, skipping this iteration"}
{"level":"INFO","ts":"2025-11-20T04:38:28.026Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"INFO","ts":"2025-11-20T04:38:28.038Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 2 256 200 0 0 {0 0 0}}. Trying spec."}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T04:38:28.038Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 2}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T04:38:28.038Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 2 256 200 0 0 {0 0 0}}. Trying spec."}
{"level":"INFO","ts":"2025-11-20T04:38:28.038Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:38:28.038483421 +0000 UTC m=+317.747323127 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.038Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:38:28.038Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:38:28.038Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:38:28.045Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:38:28.045Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:39:28.046Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.068Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"INFO","ts":"2025-11-20T04:39:28.068Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.068Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.068Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T04:39:28.068Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T04:39:28.068Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"INFO","ts":"2025-11-20T04:39:28.068Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.068Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.068Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.068Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:39:28.069192449 +0000 UTC m=+377.778032154 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.069Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:39:28.069Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:39:28.069Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:39:28.075Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:39:28.075Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:40:28.077Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.094Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"INFO","ts":"2025-11-20T04:40:28.094Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.094Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.094Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T04:40:28.094Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T04:40:28.094Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"INFO","ts":"2025-11-20T04:40:28.094Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.094Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.094Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.094Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.094Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.094Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:40:28.095096304 +0000 UTC m=+437.803936009 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.095Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:40:28.095Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:40:28.095Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:40:28.101Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:40:28.101Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:41:28.102Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"INFO","ts":"2025-11-20T04:41:28.121Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T04:41:28.121Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T04:41:28.121Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"INFO","ts":"2025-11-20T04:41:28.121Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.121Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.122Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.122Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.122Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.122Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.122Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:41:28.122030349 +0000 UTC m=+497.830870048 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.122Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.122Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:41:28.122Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:41:28.122Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:41:28.129Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:41:28.129Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:42:28.129Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.145Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"INFO","ts":"2025-11-20T04:42:28.146Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T04:42:28.146Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T04:42:28.146Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"INFO","ts":"2025-11-20T04:42:28.146Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:42:28.146309716 +0000 UTC m=+557.855149415 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.146Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:42:28.146Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:42:28.146Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:42:28.152Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:42:28.152Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:43:28.153Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.170Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.170Z","msg":"Using auto-guessed initial state for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.971000, beta= 0.027644, gamma= 22.833000, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.170Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.971000, beta=0.027644, gamma=22.833000, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"INFO","ts":"2025-11-20T04:43:28.170Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.000874"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.170Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.950198, beta=0.027638, gamma=22.832769, delta=0.000205, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.170Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.950198, beta=0.027638, gamma=22.832769, delta=0.000205, NIS=0.000874"}
{"level":"INFO","ts":"2025-11-20T04:43:28.170Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.950198, beta: 0.027638, gamma: 22.832769, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.950198,    beta: 0.027637685   },   prefillParms: {    gamma: 22.83277,    delta: 0.00020547248   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.19,    ttftAverage: 25.37,    load: {     arrivalRate: 441.98,     avgInTokens: 280,     avgOutTokens: 489    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=441.98; inTk=280; outTk=489; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=12.194554, ttft=25.423096, rho=0.17196837, maxRPM=1187.8115}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 12.194554 25.423096 {441.98 280 489}}"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:43:28.176383552 +0000 UTC m=+617.885223257 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.176Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:43:28.176Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:43:28.176Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:43:28.184Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:43:28.184Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:44:28.185Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.197Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.197Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.950198, beta= 0.027638, gamma= 22.832769, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.197Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.950198, beta=0.027638, gamma=22.832769, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:44:28.198Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.318747"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.198Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.124062, beta=0.026915, gamma=22.817097, delta=0.000205, NIS=2.32"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.198Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.124062, beta=0.026915, gamma=22.817097, delta=0.000205, NIS=2.318747"}
{"level":"INFO","ts":"2025-11-20T04:44:28.198Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.124062, beta: 0.026915, gamma: 22.817097, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.124062,    beta: 0.026914855   },   prefillParms: {    gamma: 22.817097,    delta: 0.0002049906   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.9,    ttftAverage: 24.4,    load: {     arrivalRate: 703.03,     avgInTokens: 254,     avgOutTokens: 523    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=703.03; inTk=254; outTk=523; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=12.161444, ttft=26.758474, rho=0.29178637, maxRPM=1374.8867}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 12.161444 26.758474 {703.03 254 523}}"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:44:28.200867218 +0000 UTC m=+677.909706917 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.200Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:44:28.200Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:44:28.200Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:44:28.207Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:44:28.207Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:45:28.208Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.225Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.225Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.124062, beta= 0.026915, gamma= 22.817097, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.225Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.124062, beta=0.026915, gamma=22.817097, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:45:28.225Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.099770"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.225Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.973385, beta=0.026859, gamma=22.796671, delta=0.000205, NIS=0.10"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.225Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.973385, beta=0.026859, gamma=22.796671, delta=0.000205, NIS=0.099770"}
{"level":"INFO","ts":"2025-11-20T04:45:28.225Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.973385, beta: 0.026859, gamma: 22.796671, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.973385,    beta: 0.026859274   },   prefillParms: {    gamma: 22.79667,    delta: 0.00020499217   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.7,    ttftAverage: 23.95,    load: {     arrivalRate: 710.77,     avgInTokens: 272,     avgOutTokens: 468    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=710.77; inTk=272; outTk=468; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=11.755407, ttft=26.496017, rho=0.25526044, maxRPM=1586.8746}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 11.755407 26.496017 {710.77 272 468}}"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:45:28.227853157 +0000 UTC m=+737.936692855 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.227Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:45:28.227Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:45:28.227Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:45:28.236Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:45:28.236Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:46:28.237Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.250Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.250Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.973385, beta= 0.026859, gamma= 22.796671, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.250Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.973385, beta=0.026859, gamma=22.796671, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:46:28.250Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.019609"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.250Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.023016, beta=0.026905, gamma=22.772978, delta=0.000205, NIS=0.02"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.250Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.023016, beta=0.026905, gamma=22.772978, delta=0.000205, NIS=0.019609"}
{"level":"INFO","ts":"2025-11-20T04:46:28.250Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.023016, beta: 0.026905, gamma: 22.772978, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.252Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.023016,    beta: 0.026905218   },   prefillParms: {    gamma: 22.772978,    delta: 0.00020499228   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.23,    ttftAverage: 24.54,    load: {     arrivalRate: 773.61,     avgInTokens: 250,     avgOutTokens: 509    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=773.61; inTk=250; outTk=509; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=12.211205, ttft=26.940958, rho=0.3137871, maxRPM=1442.5709}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 12.211205 26.940958 {773.61 250 509}}"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:46:28.253197411 +0000 UTC m=+797.962037110 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.253Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:46:28.253Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:46:28.253Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:46:28.262Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:46:28.262Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:47:28.263Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.281Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.281Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.023016, beta= 0.026905, gamma= 22.772978, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.281Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.023016, beta=0.026905, gamma=22.772978, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:47:28.281Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.065258"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.281Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.141558, beta=0.026989, gamma=22.749941, delta=0.000205, NIS=0.07"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.281Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.141558, beta=0.026989, gamma=22.749941, delta=0.000205, NIS=0.065258"}
{"level":"INFO","ts":"2025-11-20T04:47:28.281Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.141558, beta: 0.026989, gamma: 22.749941, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.141558,    beta: 0.026989108   },   prefillParms: {    gamma: 22.74994,    delta: 0.00020499359   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.36,    ttftAverage: 25.19,    load: {     arrivalRate: 709.58,     avgInTokens: 266,     avgOutTokens: 545    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=709.58; inTk=266; outTk=545; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=12.315638, ttft=27.14241, rho=0.31075767, maxRPM=1311.0537}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 12.315638 27.14241 {709.58 266 545}}"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:47:28.283707985 +0000 UTC m=+857.992547683 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.283Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:47:28.283Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:47:28.283Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:47:28.289Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:47:28.289Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:48:28.291Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.304Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.304Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.141558, beta= 0.026989, gamma= 22.749941, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.304Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.141558, beta=0.026989, gamma=22.749941, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:48:28.304Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.018617"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.304Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.097702, beta=0.026954, gamma=22.714294, delta=0.000205, NIS=0.02"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.304Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.097702, beta=0.026954, gamma=22.714294, delta=0.000205, NIS=0.018617"}
{"level":"INFO","ts":"2025-11-20T04:48:28.304Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.097702, beta: 0.026954, gamma: 22.714294, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.097702,    beta: 0.026953587   },   prefillParms: {    gamma: 22.714294,    delta: 0.00020499129   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.3,    ttftAverage: 24.27,    load: {     arrivalRate: 730.5,     avgInTokens: 247,     avgOutTokens: 541    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=730.5; inTk=247; outTk=541; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=12.31594, ttft=26.881298, rho=0.317572, maxRPM=1334.5874}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 12.31594 26.881298 {730.5 247 541}}"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:48:28.306725927 +0000 UTC m=+918.015565626 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.306Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:48:28.306Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:48:28.306Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:48:28.313Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:48:28.313Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:49:28.315Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.333Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.333Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.097702, beta= 0.026954, gamma= 22.714294, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.333Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.097702, beta=0.026954, gamma=22.714294, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-20T04:49:28.334Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.097702, beta=0.026954, gamma=22.714294, delta=0.000205, NIS=0.018617). Validation error: tuning validation failed: normalized innovation squared (NIS=10.31) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.334Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=10.097702, beta=0.026954, gamma=22.714294, delta=0.000205 | NIS=0.018617 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-20T04:49:28.334Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.334Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.097702, beta=0.026954, gamma=22.714294, delta=0.000205, NIS=0.02"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.334Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.097702,    beta: 0.026954   },   prefillParms: {    gamma: 22.714294,    delta: 0.000205   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 16.2,    ttftAverage: 31.98,    load: {     arrivalRate: 1109.47,     avgInTokens: 262,     avgOutTokens: 479    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1109.47; inTk=262; outTk=479; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=13.310194, ttft=29.11568, rho=0.46165717, maxRPM=1506.7812}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 13.310194 29.11568 {1109.47 262 479}}"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:49:28.339749261 +0000 UTC m=+978.048588966 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.339Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:49:28.339Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:49:28.339Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:49:28.347Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:49:28.347Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:50:28.348Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.361Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.361Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.097702, beta= 0.026954, gamma= 22.714294, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.361Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.097702, beta=0.026954, gamma=22.714294, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:50:28.362Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.129775"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.362Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.503524, beta=0.031478, gamma=22.609905, delta=0.000205, NIS=3.13"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.362Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.503524, beta=0.031478, gamma=22.609905, delta=0.000205, NIS=3.129775"}
{"level":"INFO","ts":"2025-11-20T04:50:28.362Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.503524, beta: 0.031478, gamma: 22.609905, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.503524,    beta: 0.031477515   },   prefillParms: {    gamma: 22.609905,    delta: 0.00020494593   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 17.92,    ttftAverage: 34.52,    load: {     arrivalRate: 1520.28,     avgInTokens: 258,     avgOutTokens: 516    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1520.28; inTk=258; outTk=516; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=100, itl=13.271528, ttft=27.25961, rho=0.33959338, maxRPM=1097.4413}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 13.271528 27.25961 {1520.28 258 516}}"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:50:28.364964273 +0000 UTC m=+1038.073803971 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.364Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:50:28.365Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:50:28.365Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:50:28.390Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:50:28.390Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:51:28.391Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.405Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.406Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.503524, beta= 0.031478, gamma= 22.609905, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.406Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.503524, beta=0.031478, gamma=22.609905, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-20T04:51:28.406Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.503524, beta=0.031478, gamma=22.609905, delta=0.000205, NIS=3.129775). Validation error: tuning validation failed: normalized innovation squared (NIS=7.75) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.406Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=10.503524, beta=0.031478, gamma=22.609905, delta=0.000205 | NIS=3.129775 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-20T04:51:28.406Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.406Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.503524, beta=0.031478, gamma=22.609905, delta=0.000205, NIS=3.13"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.406Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.503524,    beta: 0.031478   },   prefillParms: {    gamma: 22.609905,    delta: 0.000205   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 14.93,    ttftAverage: 29.66,    load: {     arrivalRate: 1143.92,     avgInTokens: 263,     avgOutTokens: 507    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1143.92; inTk=263; outTk=507; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=12.430101, ttft=25.909716, rho=0.23517168, maxRPM=1116.847}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 12.430101 25.909716 {1143.92 263 507}}"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:51:28.409787984 +0000 UTC m=+1098.118627683 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.409Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:51:28.409Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:51:28.409Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:51:28.416Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:51:28.416Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:52:28.416Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.434Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.434Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.503524, beta= 0.031478, gamma= 22.609905, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.434Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.503524, beta=0.031478, gamma=22.609905, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:52:28.434Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.115508"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.434Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.745763, beta=0.030957, gamma=22.619066, delta=0.000205, NIS=0.12"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.434Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.745763, beta=0.030957, gamma=22.619066, delta=0.000205, NIS=0.115508"}
{"level":"INFO","ts":"2025-11-20T04:52:28.434Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.745763, beta: 0.030957, gamma: 22.619066, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.437Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.437Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.437Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.437Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.745763,    beta: 0.030956585   },   prefillParms: {    gamma: 22.619066,    delta: 0.00020500102   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.437Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.437Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.01,    ttftAverage: 25.3,    load: {     arrivalRate: 764.91,     avgInTokens: 262,     avgOutTokens: 498    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.438Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=764.91; inTk=262; outTk=498; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=13.419615, ttft=27.25825, rho=0.33349314, maxRPM=1093.5918}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.438Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 13.419615 27.25825 {764.91 262 498}}"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.438Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.438Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.438Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:52:28.438012314 +0000 UTC m=+1158.146852012 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.438Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.438Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:52:28.438Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:52:28.438Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:52:28.446Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:52:28.446Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:53:28.449Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.489Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.489Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.745763, beta= 0.030957, gamma= 22.619066, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.489Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.745763, beta=0.030957, gamma=22.619066, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:53:28.490Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.080886"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.490Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.621050, beta=0.030562, gamma=22.593775, delta=0.000205, NIS=0.08"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.490Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.621050, beta=0.030562, gamma=22.593775, delta=0.000205, NIS=0.080886"}
{"level":"INFO","ts":"2025-11-20T04:53:28.490Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.621050, beta: 0.030562, gamma: 22.593775, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.62105,    beta: 0.030561684   },   prefillParms: {    gamma: 22.593775,    delta: 0.0002049909   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 14.89,    ttftAverage: 28.88,    load: {     arrivalRate: 1159.94,     avgInTokens: 264,     avgOutTokens: 484    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1159.94; inTk=264; outTk=484; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=14.930065, ttft=30.224033, rho=0.5468517, maxRPM=1173.4084}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 14.930065 30.224033 {1159.94 264 484}}"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:53:28.496239665 +0000 UTC m=+1218.205079364 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.496Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:53:28.496Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:53:28.496Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:53:28.502Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:53:28.502Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:54:28.503Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.516Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.516Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.621050, beta= 0.030562, gamma= 22.593775, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.516Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.621050, beta=0.030562, gamma=22.593775, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:54:28.516Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.735260"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.516Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205, NIS=0.74"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.516Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205, NIS=0.735260"}
{"level":"INFO","ts":"2025-11-20T04:54:28.516Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.736358, beta: 0.030784, gamma: 22.195189, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.736358,    beta: 0.030784223   },   prefillParms: {    gamma: 22.195189,    delta: 0.00020482972   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 17.71,    ttftAverage: 33.41,    load: {     arrivalRate: 1446.52,     avgInTokens: 247,     avgOutTokens: 521    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1446.52; inTk=247; outTk=521; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=100, itl=13.353761, ttft=26.49681, rho=0.32821935, maxRPM=1053.7516}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 13.353761 26.49681 {1446.52 247 521}}"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:54:28.519779948 +0000 UTC m=+1278.228619647 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.519Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:54:28.519Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:54:28.519Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:54:28.526Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:54:28.526Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:55:28.527Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.543Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.543Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.736358, beta= 0.030784, gamma= 22.195189, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.543Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-20T04:55:28.544Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205, NIS=0.735260). Validation error: tuning validation failed: normalized innovation squared (NIS=95.97) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.544Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205 | NIS=0.735260 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-20T04:55:28.544Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.544Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205, NIS=0.74"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.544Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.736358,    beta: 0.030784   },   prefillParms: {    gamma: 22.195189,    delta: 0.000205   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 22.5,    ttftAverage: 41.37,    load: {     arrivalRate: 1561.28,     avgInTokens: 263,     avgOutTokens: 485    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1561.28; inTk=263; outTk=485; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=13.3696, ttft=26.807041, rho=0.33023173, maxRPM=1131.7545}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 13.3696 26.807041 {1561.28 263 485}}"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:55:28.547504715 +0000 UTC m=+1338.256344421 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.547Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:55:28.547Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:55:28.547Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:55:28.554Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:55:28.554Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:56:28.555Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.579Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.579Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.736358, beta= 0.030784, gamma= 22.195189, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.579Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-20T04:56:28.579Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205, NIS=0.735260). Validation error: tuning validation failed: normalized innovation squared (NIS=13.62) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.579Z","msg":"[Tuner Results] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Kept previous params: alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205 | NIS=0.735260 (NIS validation failed)"}
{"level":"INFO","ts":"2025-11-20T04:56:28.579Z","msg":"Keeping previous tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler due to NIS validation failure"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.579Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205, NIS=0.74"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.579Z","msg":"Tuned parameters unchanged for variant ms-inference-scheduling-llm-d-modelservice-decode, skipping status update"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.736358,    beta: 0.030784   },   prefillParms: {    gamma: 22.195189,    delta: 0.000205   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 16.67,    ttftAverage: 32.38,    load: {     arrivalRate: 1521.84,     avgInTokens: 266,     avgOutTokens: 477    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1521.84; inTk=266; outTk=477; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=13.237479, ttft=26.625612, rho=0.31346664, maxRPM=1150.6849}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 13.237479 26.625612 {1521.84 266 477}}"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:56:28.585867772 +0000 UTC m=+1398.294707470 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.585Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:56:28.585Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:56:28.585Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:56:28.592Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:56:28.592Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:57:28.593Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.614Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.614Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.736358, beta= 0.030784, gamma= 22.195189, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.614Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.736358, beta=0.030784, gamma=22.195189, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:57:28.615Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.482006"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.615Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=11.083365, beta=0.031137, gamma=22.150637, delta=0.000205, NIS=0.48"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.615Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=11.083365, beta=0.031137, gamma=22.150637, delta=0.000205, NIS=0.482006"}
{"level":"INFO","ts":"2025-11-20T04:57:28.615Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 11.083365, beta: 0.031137, gamma: 22.150637, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 11.083365,    beta: 0.031136937   },   prefillParms: {    gamma: 22.150637,    delta: 0.00020499992   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 17.65,    ttftAverage: 33.34,    load: {     arrivalRate: 2779.94,     avgInTokens: 251,     avgOutTokens: 508    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2779.94; inTk=251; outTk=508; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=256; cost=300, val=100, itl=14.71588, ttft=28.153507, rho=0.4518069, maxRPM=980.8269}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 256 300 14.71588 28.153507 {2779.94 251 508}}"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:57:28.621731055 +0000 UTC m=+1458.330570754 H100 3}"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.621Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:57:28.621Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:57:28.621Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:57:28.634Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:57:28.634Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:58:28.635Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.652Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.652Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 11.083365, beta= 0.031137, gamma= 22.150637, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.652Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=11.083365, beta=0.031137, gamma=22.150637, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:58:28.654Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 5.122731"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.654Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=12.695743, beta=0.029304, gamma=22.244242, delta=0.000205, NIS=5.12"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.654Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=12.695743, beta=0.029304, gamma=22.244242, delta=0.000205, NIS=5.122731"}
{"level":"INFO","ts":"2025-11-20T04:58:28.654Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 12.695743, beta: 0.029304, gamma: 22.244242, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 12.695743,    beta: 0.029304104   },   prefillParms: {    gamma: 22.244242,    delta: 0.00020501594   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 16.73,    ttftAverage: 31.43,    load: {     arrivalRate: 2507.07,     avgInTokens: 256,     avgOutTokens: 543    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2507.07; inTk=256; outTk=543; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=256; cost=500, val=200, itl=14.679837, ttft=25.797783, rho=0.2605743, maxRPM=571.07965}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 256 500 14.679837 25.797783 {2507.07 256 543}}"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:58:28.660653483 +0000 UTC m=+1518.369493181 H100 5}"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.660Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:58:28.660Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:58:28.660Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:58:28.668Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:58:28.668Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T04:59:28.669Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.702Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.702Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 12.695743, beta= 0.029304, gamma= 22.244242, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.702Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=12.695743, beta=0.029304, gamma=22.244242, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T04:59:28.703Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.056381"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.703Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=12.542521, beta=0.029490, gamma=22.301226, delta=0.000205, NIS=0.06"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.703Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=12.542521, beta=0.029490, gamma=22.301226, delta=0.000205, NIS=0.056381"}
{"level":"INFO","ts":"2025-11-20T04:59:28.703Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 12.542521, beta: 0.029490, gamma: 22.301226, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 12.5425205,    beta: 0.02949018   },   prefillParms: {    gamma: 22.301226,    delta: 0.00020500532   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 13.96,    ttftAverage: 27.52,    load: {     arrivalRate: 2074.12,     avgInTokens: 277,     avgOutTokens: 498    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2074.12; inTk=277; outTk=498; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=256; cost=400, val=-100, itl=14.402958, ttft=25.883694, rho=0.242526, maxRPM=660.2379}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 256 400 14.402958 25.883694 {2074.12 277 498}}"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 04:59:28.708458873 +0000 UTC m=+1578.417298578 H100 4}"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.708Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T04:59:28.708Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T04:59:28.708Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T04:59:28.717Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T04:59:28.717Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:00:28.718Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.734Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.734Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 12.542521, beta= 0.029490, gamma= 22.301226, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.734Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=12.542521, beta=0.029490, gamma=22.301226, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:00:28.735Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 6.577481"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.735Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.970566, beta=0.028456, gamma=22.278553, delta=0.000205, NIS=6.58"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.735Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.970566, beta=0.028456, gamma=22.278553, delta=0.000205, NIS=6.577481"}
{"level":"INFO","ts":"2025-11-20T05:00:28.735Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.970566, beta: 0.028456, gamma: 22.278553, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.740Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.740Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.740Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.740Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.970566,    beta: 0.0284563   },   prefillParms: {    gamma: 22.278553,    delta: 0.0002049947   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.740Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.741Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 12.36,    ttftAverage: 24.66,    load: {     arrivalRate: 2299.11,     avgInTokens: 265,     avgOutTokens: 511    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.741Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2299.11; inTk=265; outTk=511; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=256; cost=300, val=-100, itl=13.513943, ttft=27.133907, rho=0.345228, maxRPM=1098.4485}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.741Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 256 300 13.513943 27.133907 {2299.11 265 511}}"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.741Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.741Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.741Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:00:28.741055053 +0000 UTC m=+1638.449894752 H100 3}"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.741Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.741Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:00:28.741Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:00:28.741Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:00:28.768Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:00:28.768Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:01:28.769Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.790Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.790Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.970566, beta= 0.028456, gamma= 22.278553, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.790Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.970566, beta=0.028456, gamma=22.278553, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:01:28.791Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.381229"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.791Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.133996, beta=0.028036, gamma=22.209169, delta=0.000205, NIS=2.38"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.791Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.133996, beta=0.028036, gamma=22.209169, delta=0.000205, NIS=2.381229"}
{"level":"INFO","ts":"2025-11-20T05:01:28.791Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.133996, beta: 0.028036, gamma: 22.209169, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.795Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.795Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.795Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.133996,    beta: 0.02803613   },   prefillParms: {    gamma: 22.20917,    delta: 0.00020499043   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 11.74,    ttftAverage: 23.36,    load: {     arrivalRate: 1802.78,     avgInTokens: 272,     avgOutTokens: 547    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1802.78; inTk=272; outTk=547; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=-100, itl=13.212437, ttft=28.331478, rho=0.42501014, maxRPM=1259.2849}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 13.212437 28.331478 {1802.78 272 547}}"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:01:28.796110226 +0000 UTC m=+1698.504949931 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.796Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:01:28.796Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:01:28.796Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:01:28.804Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:01:28.804Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:02:28.805Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.827Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.828Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.133996, beta= 0.028036, gamma= 22.209169, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.828Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.133996, beta=0.028036, gamma=22.209169, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:02:28.831Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.039191"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.832Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.034675, beta=0.028064, gamma=22.167822, delta=0.000205, NIS=0.04"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.832Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.034675, beta=0.028064, gamma=22.167822, delta=0.000205, NIS=0.039191"}
{"level":"INFO","ts":"2025-11-20T05:02:28.832Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.034675, beta: 0.028064, gamma: 22.167822, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.837Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.034675,    beta: 0.028063592   },   prefillParms: {    gamma: 22.167822,    delta: 0.00020499657   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.6,    ttftAverage: 23.65,    load: {     arrivalRate: 1226.68,     avgInTokens: 249,     avgOutTokens: 470    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1226.68; inTk=249; outTk=470; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=13.790158, ttft=28.998573, rho=0.51882994, maxRPM=1493.8574}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 13.790158 28.998573 {1226.68 249 470}}"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:02:28.838541443 +0000 UTC m=+1758.547381144 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.838Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:02:28.839Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:02:28.839Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:02:28.855Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:02:28.856Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:03:28.857Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.875Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.875Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.034675, beta= 0.028064, gamma= 22.167822, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.875Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.034675, beta=0.028064, gamma=22.167822, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:03:28.876Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 6.905687"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.876Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.915078, beta=0.034078, gamma=22.186584, delta=0.000205, NIS=6.91"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.876Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.915078, beta=0.034078, gamma=22.186584, delta=0.000205, NIS=6.905687"}
{"level":"INFO","ts":"2025-11-20T05:03:28.876Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.915078, beta: 0.034078, gamma: 22.186584, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.915078,    beta: 0.034077838   },   prefillParms: {    gamma: 22.186584,    delta: 0.00020501688   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 16.51,    ttftAverage: 32.24,    load: {     arrivalRate: 1273.44,     avgInTokens: 263,     avgOutTokens: 455    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1273.44; inTk=263; outTk=455; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=100, itl=13.11103, ttft=25.661114, rho=0.2478096, maxRPM=1042.9287}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 13.11103 25.661114 {1273.44 263 455}}"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:03:28.882799726 +0000 UTC m=+1818.591639425 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.882Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:03:28.882Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:03:28.882Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:03:28.895Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:03:28.895Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:04:28.896Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.915Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.915Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.915078, beta= 0.034078, gamma= 22.186584, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.915Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.915078, beta=0.034078, gamma=22.186584, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:04:28.916Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.205777"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.916Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=11.629690, beta=0.032897, gamma=22.223843, delta=0.000205, NIS=1.21"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.916Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=11.629690, beta=0.032897, gamma=22.223843, delta=0.000205, NIS=1.205777"}
{"level":"INFO","ts":"2025-11-20T05:04:28.916Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 11.629690, beta: 0.032897, gamma: 22.223843, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 11.62969,    beta: 0.032897003   },   prefillParms: {    gamma: 22.223843,    delta: 0.00020500338   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 13.83,    ttftAverage: 26.82,    load: {     arrivalRate: 927.59,     avgInTokens: 285,     avgOutTokens: 569    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=927.59; inTk=285; outTk=569; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=0, itl=13.639148, ttft=25.792694, rho=0.23470047, maxRPM=712.0828}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 13.639148 25.792694 {927.59 285 569}}"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:04:28.923796432 +0000 UTC m=+1878.632636131 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.923Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:04:28.923Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:04:28.923Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:04:28.930Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:04:28.930Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:05:28.931Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.960Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.960Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 11.629690, beta= 0.032897, gamma= 22.223843, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.960Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=11.629690, beta=0.032897, gamma=22.223843, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:05:28.961Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.400993"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.961Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.716975, beta=0.032931, gamma=22.228519, delta=0.000205, NIS=2.40"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.961Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.716975, beta=0.032931, gamma=22.228519, delta=0.000205, NIS=2.400993"}
{"level":"INFO","ts":"2025-11-20T05:05:28.961Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.716975, beta: 0.032931, gamma: 22.228519, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.966Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.716975,    beta: 0.032931205   },   prefillParms: {    gamma: 22.22852,    delta: 0.00020499954   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.16,    ttftAverage: 25.42,    load: {     arrivalRate: 1011.52,     avgInTokens: 281,     avgOutTokens: 485    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1011.52; inTk=281; outTk=485; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=14.722021, ttft=29.234343, rho=0.47116634, maxRPM=1062.2598}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 14.722021 29.234343 {1011.52 281 485}}"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:05:28.967196492 +0000 UTC m=+1938.676036191 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.967Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:05:28.967Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:05:28.967Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:05:28.973Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:05:28.973Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:06:28.974Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.988Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.988Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.716975, beta= 0.032931, gamma= 22.228519, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.988Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.716975, beta=0.032931, gamma=22.228519, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:06:28.990Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.642157"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.990Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.410328, beta=0.031086, gamma=22.186794, delta=0.000205, NIS=0.64"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.990Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.410328, beta=0.031086, gamma=22.186794, delta=0.000205, NIS=0.642157"}
{"level":"INFO","ts":"2025-11-20T05:06:28.990Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.410328, beta: 0.031086, gamma: 22.186794, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.410328,    beta: 0.031086018   },   prefillParms: {    gamma: 22.186794,    delta: 0.00020499056   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 13.96,    ttftAverage: 27.2,    load: {     arrivalRate: 1085.47,     avgInTokens: 264,     avgOutTokens: 459    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1085.47; inTk=264; outTk=459; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=14.085508, ttft=28.5849, rho=0.45791486, maxRPM=1275.1373}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 14.085508 28.5849 {1085.47 264 459}}"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:06:28.992961634 +0000 UTC m=+1998.701801339 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:06:28.992Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:06:28.993Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:06:28.993Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:06:29.000Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:06:29.000Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:07:29.001Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.018Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.019Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.410328, beta= 0.031086, gamma= 22.186794, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.019Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.410328, beta=0.031086, gamma=22.186794, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:07:29.020Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.055372"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.020Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.496015, beta=0.031380, gamma=22.117098, delta=0.000205, NIS=0.06"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.020Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.496015, beta=0.031380, gamma=22.117098, delta=0.000205, NIS=0.055372"}
{"level":"INFO","ts":"2025-11-20T05:07:29.020Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.496015, beta: 0.031380, gamma: 22.117098, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.496015,    beta: 0.0313798   },   prefillParms: {    gamma: 22.117098,    delta: 0.00020498768   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 15.14,    ttftAverage: 28.31,    load: {     arrivalRate: 974.23,     avgInTokens: 273,     avgOutTokens: 594    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=974.23; inTk=273; outTk=594; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=256; cost=200, val=100, itl=12.408476, ttft=25.527714, rho=0.23416257, maxRPM=958.17804}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 256 200 12.408476 25.527714 {974.23 273 594}}"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:07:29.025520804 +0000 UTC m=+2058.734360502 H100 2}"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.025Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:07:29.025Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:07:29.025Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:07:29.033Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:07:29.033Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:08:29.033Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.046Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.046Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.496015, beta= 0.031380, gamma= 22.117098, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.046Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.496015, beta=0.031380, gamma=22.117098, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:08:29.047Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.029516"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.047Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.623699, beta=0.030978, gamma=22.118053, delta=0.000205, NIS=0.03"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.047Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.623699, beta=0.030978, gamma=22.118053, delta=0.000205, NIS=0.029516"}
{"level":"INFO","ts":"2025-11-20T05:08:29.047Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.623699, beta: 0.030978, gamma: 22.118053, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.052Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.623699,    beta: 0.030977506   },   prefillParms: {    gamma: 22.118053,    delta: 0.00020500003   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.58,    ttftAverage: 23.66,    load: {     arrivalRate: 579.57,     avgInTokens: 251,     avgOutTokens: 518    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=579.57; inTk=251; outTk=518; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=-100, itl=12.613616, ttft=25.423393, rho=0.24702145, maxRPM=1081.1892}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 12.613616 25.423393 {579.57 251 518}}"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:08:29.053188197 +0000 UTC m=+2118.762027895 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.053Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:08:29.053Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:08:29.053Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:08:29.060Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:08:29.060Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:09:29.061Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.082Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.082Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.623699, beta= 0.030978, gamma= 22.118053, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.082Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.623699, beta=0.030978, gamma=22.118053, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:09:29.083Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.175013"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.083Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.054413, beta=0.030566, gamma=22.047014, delta=0.000205, NIS=1.18"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.083Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.054413, beta=0.030566, gamma=22.047014, delta=0.000205, NIS=1.175013"}
{"level":"INFO","ts":"2025-11-20T05:09:29.083Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.054413, beta: 0.030566, gamma: 22.047014, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.054413,    beta: 0.03056559   },   prefillParms: {    gamma: 22.047014,    delta: 0.00020499445   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.58,    ttftAverage: 22.95,    load: {     arrivalRate: 574.65,     avgInTokens: 252,     avgOutTokens: 489    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=574.65; inTk=252; outTk=489; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=11.7743435, ttft=24.953852, rho=0.21589907, maxRPM=1312.5989}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 11.7743435 24.953852 {574.65 252 489}}"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:09:29.088523631 +0000 UTC m=+2178.797363330 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.088Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:09:29.088Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:09:29.088Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:09:29.096Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:09:29.096Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:10:29.097Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.119Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.120Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.054413, beta= 0.030566, gamma= 22.047014, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.120Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.054413, beta=0.030566, gamma=22.047014, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:10:29.120Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.018598"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.120Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.995319, beta=0.030439, gamma=22.008879, delta=0.000205, NIS=0.02"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.120Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.995319, beta=0.030439, gamma=22.008879, delta=0.000205, NIS=0.018598"}
{"level":"INFO","ts":"2025-11-20T05:10:29.120Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.995319, beta: 0.030439, gamma: 22.008879, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.995319,    beta: 0.03043881   },   prefillParms: {    gamma: 22.008879,    delta: 0.00020499587   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.49,    ttftAverage: 25.58,    load: {     arrivalRate: 748.85,     avgInTokens: 274,     avgOutTokens: 522    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=748.85; inTk=274; outTk=522; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=12.51246, ttft=26.65377, rho=0.3191215, maxRPM=1249.6517}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 12.51246 26.65377 {748.85 274 522}}"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:10:29.125418673 +0000 UTC m=+2238.834258378 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.125Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:10:29.125Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:10:29.125Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:10:29.133Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:10:29.134Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:11:29.135Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.151Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.151Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.995319, beta= 0.030439, gamma= 22.008879, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.151Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.995319, beta=0.030439, gamma=22.008879, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:11:29.152Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.104485"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.152Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.833065, beta=0.030501, gamma=21.936213, delta=0.000205, NIS=0.10"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.152Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.833065, beta=0.030501, gamma=21.936213, delta=0.000205, NIS=0.104485"}
{"level":"INFO","ts":"2025-11-20T05:11:29.152Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.833065, beta: 0.030501, gamma: 21.936213, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.833065,    beta: 0.030501194   },   prefillParms: {    gamma: 21.936213,    delta: 0.00020499429   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.67,    ttftAverage: 23.32,    load: {     arrivalRate: 656.8,     avgInTokens: 266,     avgOutTokens: 475    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=656.8; inTk=266; outTk=475; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=11.728143, ttft=25.324135, rho=0.238794, maxRPM=1414.9028}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 11.728143 25.324135 {656.8 266 475}}"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:11:29.157471563 +0000 UTC m=+2298.866311262 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.157Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:11:29.157Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:11:29.157Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:11:29.165Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:11:29.165Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:12:29.166Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.192Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.192Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.833065, beta= 0.030501, gamma= 21.936213, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.192Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.833065, beta=0.030501, gamma=21.936213, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:12:29.193Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.021992"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.193Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.771911, beta=0.030434, gamma=21.870504, delta=0.000205, NIS=0.02"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.193Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.771911, beta=0.030434, gamma=21.870504, delta=0.000205, NIS=0.021992"}
{"level":"INFO","ts":"2025-11-20T05:12:29.193Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.771911, beta: 0.030434, gamma: 21.870504, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.197Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.197Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.771911,    beta: 0.030433867   },   prefillParms: {    gamma: 21.870504,    delta: 0.00020499458   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.97,    ttftAverage: 23.81,    load: {     arrivalRate: 727.48,     avgInTokens: 249,     avgOutTokens: 494    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=727.48; inTk=249; outTk=494; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=11.993639, ttft=25.596785, rho=0.28125724, maxRPM=1379.9626}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 11.993639 25.596785 {727.48 249 494}}"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:12:29.198159609 +0000 UTC m=+2358.906999307 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.198Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:12:29.198Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:12:29.198Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:12:29.209Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:12:29.209Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:13:29.210Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.225Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.225Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.771911, beta= 0.030434, gamma= 21.870504, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.225Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.771911, beta=0.030434, gamma=21.870504, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"INFO","ts":"2025-11-20T05:13:29.225Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.055699"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.225Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.343891, beta=0.028738, gamma=21.947754, delta=0.000205, NIS=1.06"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.225Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.343891, beta=0.028738, gamma=21.947754, delta=0.000205, NIS=1.055699"}
{"level":"INFO","ts":"2025-11-20T05:13:29.225Z","msg":"Tuned performance parameters result: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.343891, beta: 0.028738, gamma: 21.947754, delta: 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.343891,    beta: 0.028738385   },   prefillParms: {    gamma: 21.947754,    delta: 0.00020500166   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.06,    ttftAverage: 25.1,    load: {     arrivalRate: 148.64,     avgInTokens: 267,     avgOutTokens: 628    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=148.64; inTk=267; outTk=628; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=10.858996, ttft=22.92883, rho=0.06610919, maxRPM=1023.86755}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 10.858996 22.92883 {148.64 267 628}}"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:13:29.230791966 +0000 UTC m=+2418.939631664 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.230Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:13:29.230Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:13:29.230Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:13:29.238Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:13:29.238Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:14:29.240Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.343891, beta= 0.028738, gamma= 21.947754, delta= 0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=10.343891, beta=0.028738, gamma=21.947754, delta=0.000205 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=true"}
{"level":"WARN","ts":"2025-11-20T05:14:29.260Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T05:14:29.260Z","msg":"Using tuned parameters from status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=10.343891, beta=0.028738, gamma=21.947754, delta=0.000205"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[10.343891, 0.028738, 21.947754, 0.000205]"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 10.343891,    beta: 0.028738   },   prefillParms: {    gamma: 21.947754,    delta: 0.000205   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=10.372629, ttft=21.947958, rho=0, maxRPM=387401.62}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 10.372629 21.947958 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:14:29.260719554 +0000 UTC m=+2478.969559252 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.260Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:14:29.260Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:14:29.260Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:14:29.267Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:14:29.267Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-20T05:15:29.269Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"INFO","ts":"2025-11-20T05:15:29.283Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.331370, beta= 0.068627, gamma= 23.490000, delta= 0.003931"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"[Tuner Config] variant=ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler | Initial state: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931 | SLO targets: TTFT=1000.00ms, ITL=15.00ms | Has covariance=false"}
{"level":"WARN","ts":"2025-11-20T05:15:29.283Z","msg":"Tuner failed update completely for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-20T05:15:29.283Z","msg":"Failed to guess initial state for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: invalid allocation data for server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler: &{H100 1 256 100 0 0 {0 0 0}}. Trying spec."}
{"level":"INFO","ts":"2025-11-20T05:15:29.283Z","msg":"Using parameters from spec for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Updated SystemData for model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100: alpha=9.331370, beta=0.068627, gamma=23.490000, delta=0.003931"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Updated VA status for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, model ibm-granite/granite-3.3-8b-instruct, accelerator H100: state=[9.331370, 0.068627, 23.490000, 0.003931]"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 256,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 256,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=256; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=304799.3}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 256 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-20 05:15:29.283950272 +0000 UTC m=+2538.992789978 H100 1}"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.283Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-20T05:15:29.284Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-20T05:15:29.284Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-20T05:15:29.290Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-20T05:15:29.290Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
