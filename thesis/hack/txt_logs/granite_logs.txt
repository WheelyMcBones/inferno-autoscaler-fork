{"level":"INFO","ts":"2025-11-19T19:33:09.985Z","msg":"Zap logger initialized"}
{"level":"INFO","ts":"2025-11-19T19:33:09.988Z","msg":"Creating metrics emitter instance"}
{"level":"INFO","ts":"2025-11-19T19:33:09.988Z","msg":"Metrics emitter created successfully"}
{"level":"INFO","ts":"2025-11-19T19:33:09.988Z","msg":"Using Prometheus configuration from environment variablesaddresshttps://thanos-querier.openshift-monitoring.svc.cluster.local:9091"}
{"level":"WARN","ts":"2025-11-19T19:33:09.988Z","msg":"TLS certificate verification is disabled - this is not recommended for production"}
{"level":"INFO","ts":"2025-11-19T19:33:09.988Z","msg":"Initializing Prometheus client -> address: https://thanos-querier.openshift-monitoring.svc.cluster.local:9091 tls_enabled: true"}
{"level":"INFO","ts":"2025-11-19T19:33:09.988Z","msg":"CA certificate loaded successfullypath/etc/ssl/certs/prometheus-ca.crt"}
{"level":"INFO","ts":"2025-11-19T19:33:09.988Z","msg":"TLS configuration applied to Prometheus HTTPS transport"}
{"level":"INFO","ts":"2025-11-19T19:33:09.988Z","msg":"Bearer token loaded from filepath/var/run/secrets/kubernetes.io/serviceaccount/token"}
{"level":"INFO","ts":"2025-11-19T19:33:10.024Z","msg":"Prometheus API validation successful with queryqueryup"}
{"level":"INFO","ts":"2025-11-19T19:33:10.024Z","msg":"Prometheus client and API wrapper initialized and validated successfully"}
{"level":"INFO","ts":"2025-11-19T19:33:10.024Z","msg":"Starting manager"}
{"level":"INFO","ts":"2025-11-19T19:33:10.024Z","msg":"Registering custom metrics with Prometheus registry"}
{"level":"info","ts":"2025-11-19T19:33:10Z","logger":"controller-runtime.metrics","msg":"Starting metrics server"}
{"level":"INFO","ts":"2025-11-19T19:33:10.025Z","msg":"disabling http/2"}
{"level":"info","ts":"2025-11-19T19:33:10Z","msg":"starting server","name":"health probe","addr":"[::]:8081"}
I1119 19:33:10.025424       1 leaderelection.go:257] attempting to acquire leader lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai...
{"level":"info","ts":"2025-11-19T19:33:10Z","logger":"controller-runtime.metrics","msg":"Serving metrics server","bindAddress":":8443","secure":true}
I1119 19:33:28.640147       1 leaderelection.go:271] successfully acquired lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai
{"level":"info","ts":"2025-11-19T19:33:28Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1alpha1.VariantAutoscaling"}
{"level":"info","ts":"2025-11-19T19:33:28Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1.ConfigMap"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.857Z","msg":"ConfigMap watch enqueueing requests: count=1"}
{"level":"info","ts":"2025-11-19T19:33:29Z","msg":"Starting Controller","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling"}
{"level":"info","ts":"2025-11-19T19:33:29Z","msg":"Starting workers","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","worker count":1}
{"level":"INFO","ts":"2025-11-19T19:33:29.875Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.989Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.989Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.517388, beta= 0.052216, gamma= 12.697859, delta= 0.003509"}
{"level":"WARN","ts":"2025-11-19T19:33:29.989Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 4}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:33:29.989Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=9.517388, beta=0.052216, gamma=12.697859, delta=0.003509"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.989Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-300, itl=9.399998, ttft=23.49393, rho=0, maxRPM=452015.12}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:33:29.990498255 +0000 UTC m=+20.089630387 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.990Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:33:29.990Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:33:29.990Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:33:29.997Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:33:29.998Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:34:29.998Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.517388, beta= 0.052216, gamma= 12.697859, delta= 0.003509"}
{"level":"WARN","ts":"2025-11-19T19:34:30.014Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:34:30.014Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=9.517388, beta=0.052216, gamma=12.697859, delta=0.003509"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=452015.12}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:34:30.01450175 +0000 UTC m=+80.113633887 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.014Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:34:30.014Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:34:30.014Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:34:30.021Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:34:30.021Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:35:30.022Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.044Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.044Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.517388, beta= 0.052216, gamma= 12.697859, delta= 0.003509"}
{"level":"INFO","ts":"2025-11-19T19:35:30.044Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.689419"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.044Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.186412, beta=0.049138, gamma=11.979431, delta=0.003496, NIS=2.69"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.044Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.186412, beta=0.049138, gamma=11.979431, delta=0.003496, NIS=2.689419"}
{"level":"INFO","ts":"2025-11-19T19:35:30.044Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.186412, beta: 0.049138, gamma: 11.979431, delta: 0.003496"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 10.186412,    beta: 0.049137518   },   prefillParms: {    gamma: 11.979431,    delta: 0.003496133   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.45,    ttftAverage: 25.24,    load: {     arrivalRate: 420.67,     avgInTokens: 306,     avgOutTokens: 470    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=420.67; inTk=306; outTk=470; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=12.231297, ttft=56.50043, rho=0.079327226, maxRPM=813.4625}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 12.231297 56.50043 {420.67 306 470}}"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:35:30.054280981 +0000 UTC m=+140.153413113 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.054Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:35:30.054Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:35:30.054Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:35:30.066Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:35:30.066Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:36:30.068Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.086Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.086Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.186412, beta= 0.049138, gamma= 11.979431, delta= 0.003496"}
{"level":"WARN","ts":"2025-11-19T19:36:30.087Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.186412, beta=0.049138, gamma=11.979431, delta=0.003496, NIS=2.689419). Validation error: tuning validation failed: normalized innovation squared (NIS=13.66) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-19T19:36:30.087Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=13.66) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:36:30.087Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=10.186412, beta=0.049138, gamma=11.979431, delta=0.003496"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.72,    ttftAverage: 25.51,    load: {     arrivalRate: 864,     avgInTokens: 259,     avgOutTokens: 531    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=864; inTk=259; outTk=531; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=100, itl=12.785089, ttft=74.7283, rho=0.09633973, maxRPM=607.63}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.785089 74.7283 {864 259 531}}"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:36:30.091660822 +0000 UTC m=+200.190792954 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.091Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:36:30.091Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:36:30.091Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:36:30.098Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:36:30.098Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:37:30.100Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.132Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.132Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.186412, beta= 0.049138, gamma= 11.979431, delta= 0.003496"}
{"level":"INFO","ts":"2025-11-19T19:37:30.132Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.328614"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.132Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.978614, beta=0.049941, gamma=11.716496, delta=0.003494, NIS=0.33"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.132Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.978614, beta=0.049941, gamma=11.716496, delta=0.003494, NIS=0.328614"}
{"level":"INFO","ts":"2025-11-19T19:37:30.132Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.978614, beta: 0.049941, gamma: 11.716496, delta: 0.003494"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.978614,    beta: 0.049941473   },   prefillParms: {    gamma: 11.7164955,    delta: 0.003494418   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.12,    ttftAverage: 22.43,    load: {     arrivalRate: 493.33,     avgInTokens: 264,     avgOutTokens: 500    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=493.33; inTk=264; outTk=500; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-100, itl=12.644479, ttft=60.960747, rho=0.10230423, maxRPM=786.975}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 12.644479 60.960747 {493.33 264 500}}"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:37:30.143375753 +0000 UTC m=+260.242507891 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.143Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:37:30.143Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:37:30.143Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:37:30.150Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:37:30.150Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:38:30.151Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.165Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.165Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.978614, beta= 0.049941, gamma= 11.716496, delta= 0.003494"}
{"level":"WARN","ts":"2025-11-19T19:38:30.166Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.978614, beta=0.049941, gamma=11.716496, delta=0.003494, NIS=0.328614). Validation error: tuning validation failed: normalized innovation squared (NIS=10.61) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-19T19:38:30.166Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=10.61) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:38:30.166Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=9.978614, beta=0.049941, gamma=11.716496, delta=0.003494"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.74,    ttftAverage: 25.16,    load: {     arrivalRate: 860,     avgInTokens: 248,     avgOutTokens: 514    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=860; inTk=248; outTk=514; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=100, itl=12.618168, ttft=70.18094, rho=0.091589175, maxRPM=627.7759}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.618168 70.18094 {860 248 514}}"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:38:30.17688296 +0000 UTC m=+320.276015098 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.176Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:38:30.176Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:38:30.176Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:38:30.184Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:38:30.184Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:39:30.186Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.206Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.206Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.978614, beta= 0.049941, gamma= 11.716496, delta= 0.003494"}
{"level":"INFO","ts":"2025-11-19T19:39:30.206Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.716512"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.206Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.156784, beta=0.050212, gamma=11.277168, delta=0.003489, NIS=0.72"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.206Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.156784, beta=0.050212, gamma=11.277168, delta=0.003489, NIS=0.716512"}
{"level":"INFO","ts":"2025-11-19T19:39:30.206Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.156784, beta: 0.050212, gamma: 11.277168, delta: 0.003489"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 10.156784,    beta: 0.05021156   },   prefillParms: {    gamma: 11.277168,    delta: 0.0034891758   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.88,    ttftAverage: 24.32,    load: {     arrivalRate: 612.67,     avgInTokens: 281,     avgOutTokens: 524    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=612.67; inTk=281; outTk=524; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-100, itl=14.007453, ttft=86.46744, rho=0.14782988, maxRPM=720.34735}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 14.007453 86.46744 {612.67 281 524}}"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:39:30.216947868 +0000 UTC m=+380.316080006 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.216Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:39:30.217Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:39:30.217Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:39:30.223Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:39:30.223Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:40:30.224Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.243Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.243Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.156784, beta= 0.050212, gamma= 11.277168, delta= 0.003489"}
{"level":"WARN","ts":"2025-11-19T19:40:30.244Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.156784, beta=0.050212, gamma=11.277168, delta=0.003489, NIS=0.716512). Validation error: tuning validation failed: normalized innovation squared (NIS=11.87) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-19T19:40:30.244Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=11.87) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:40:30.244Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=10.156784, beta=0.050212, gamma=11.277168, delta=0.003489"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.86,    ttftAverage: 25.01,    load: {     arrivalRate: 844.67,     avgInTokens: 242,     avgOutTokens: 558    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=844.67; inTk=242; outTk=558; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=100, itl=12.908518, ttft=73.076126, rho=0.09985254, maxRPM=578.9284}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.908518 73.076126 {844.67 242 558}}"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:40:30.253371449 +0000 UTC m=+440.352503587 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.253Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:40:30.253Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:40:30.253Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:40:30.260Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:40:30.260Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:41:30.262Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.276Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.276Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.156784, beta= 0.050212, gamma= 11.277168, delta= 0.003489"}
{"level":"INFO","ts":"2025-11-19T19:41:30.276Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.643554"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.276Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.287294, beta=0.050517, gamma=10.845122, delta=0.003484, NIS=0.64"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.276Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.287294, beta=0.050517, gamma=10.845122, delta=0.003484, NIS=0.643554"}
{"level":"INFO","ts":"2025-11-19T19:41:30.277Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.287294, beta: 0.050517, gamma: 10.845122, delta: 0.003484"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 10.287294,    beta: 0.050517455   },   prefillParms: {    gamma: 10.845122,    delta: 0.0034840815   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.21,    ttftAverage: 24.97,    load: {     arrivalRate: 646.67,     avgInTokens: 257,     avgOutTokens: 545    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=646.67; inTk=257; outTk=545; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-100, itl=14.758068, ttft=90.08845, rho=0.17089765, maxRPM=670.834}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 14.758068 90.08845 {646.67 257 545}}"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:41:30.280955792 +0000 UTC m=+500.380087924 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.280Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:41:30.281Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:41:30.281Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:41:30.287Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:41:30.287Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:42:30.288Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.300Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.300Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.287294, beta= 0.050517, gamma= 10.845122, delta= 0.003484"}
{"level":"WARN","ts":"2025-11-19T19:42:30.300Z","msg":"rate=26.988832, max allowed rate=21.88045model tuner observation function: failed to analyze queueing model"}
{"level":"WARN","ts":"2025-11-19T19:42:30.300Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: error on setting observation function: invalid measurement function: output dimension must match measurement dimension. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:42:30.300Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=10.287294, beta=0.050517, gamma=10.845122, delta=0.003484"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.304Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.304Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.304Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.304Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.304Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.304Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 18.8,    ttftAverage: 36.33,    load: {     arrivalRate: 1619.33,     avgInTokens: 258,     avgOutTokens: 494    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.304Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1619.33; inTk=258; outTk=494; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=512; cost=300, val=200, itl=13.589668, ttft=86.42087, rho=0.11923806, maxRPM=652.6078}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.305Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 512 300 13.589668 86.42087 {1619.33 258 494}}"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.305Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.305Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.305Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:42:30.305003057 +0000 UTC m=+560.404135189 H100 3}"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.305Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.305Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:42:30.305Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:42:30.305Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:42:30.311Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:42:30.311Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:43:30.312Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.328Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.328Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.287294, beta= 0.050517, gamma= 10.845122, delta= 0.003484"}
{"level":"INFO","ts":"2025-11-19T19:43:30.328Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.655711"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.328Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.937457, beta=0.049575, gamma=10.578485, delta=0.003483, NIS=1.66"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.328Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.937457, beta=0.049575, gamma=10.578485, delta=0.003483, NIS=1.655711"}
{"level":"INFO","ts":"2025-11-19T19:43:30.328Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.937457, beta: 0.049575, gamma: 10.578485, delta: 0.003483"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.337Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.337Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 10.937457,    beta: 0.049575206   },   prefillParms: {    gamma: 10.5784855,    delta: 0.003482575   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 12.61,    ttftAverage: 24.42,    load: {     arrivalRate: 764.67,     avgInTokens: 246,     avgOutTokens: 531    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=764.67; inTk=246; outTk=531; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=-100, itl=13.215477, ttft=49.945152, rho=0.08779452, maxRPM=604.77686}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 13.215477 49.945152 {764.67 246 531}}"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:43:30.33815102 +0000 UTC m=+620.437283153 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.338Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:43:30.338Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:43:30.338Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:43:30.344Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:43:30.344Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:44:30.346Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.360Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.360Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.937457, beta= 0.049575, gamma= 10.578485, delta= 0.003483"}
{"level":"INFO","ts":"2025-11-19T19:44:30.360Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.979898"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.360Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.477389, beta=0.044586, gamma=9.884804, delta=0.003466, NIS=2.98"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.360Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.477389, beta=0.044586, gamma=9.884804, delta=0.003466, NIS=2.979898"}
{"level":"INFO","ts":"2025-11-19T19:44:30.360Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.477389, beta: 0.044586, gamma: 9.884804, delta: 0.003466"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 10.477389,    beta: 0.044585917   },   prefillParms: {    gamma: 9.884804,    delta: 0.003466021   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.66,    ttftAverage: 25.44,    load: {     arrivalRate: 936.88,     avgInTokens: 264,     avgOutTokens: 514    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=936.88; inTk=264; outTk=514; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=12.834084, ttft=58.250854, rho=0.10128392, maxRPM=772.8125}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.834084 58.250854 {936.88 264 514}}"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:44:30.369937162 +0000 UTC m=+680.469069294 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.369Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:44:30.369Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:44:30.370Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:44:30.377Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:44:30.377Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:45:30.379Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.400Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.400Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.477389, beta= 0.044586, gamma= 9.884804, delta= 0.003466"}
{"level":"WARN","ts":"2025-11-19T19:45:30.401Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.477389, beta=0.044586, gamma=9.884804, delta=0.003466, NIS=2.979898). Validation error: tuning validation failed: normalized innovation squared (NIS=12.58) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-19T19:45:30.401Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=12.58) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:45:30.401Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=10.477389, beta=0.044586, gamma=9.884804, delta=0.003466"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.6,    ttftAverage: 25.23,    load: {     arrivalRate: 1737.65,     avgInTokens: 256,     avgOutTokens: 521    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1737.65; inTk=256; outTk=521; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=512; cost=300, val=100, itl=14.439623, ttft=98.39665, rho=0.14342779, maxRPM=619.2338}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 512 300 14.439623 98.39665 {1737.65 256 521}}"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:45:30.405441363 +0000 UTC m=+740.504573495 H100 3}"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.405Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:45:30.405Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:45:30.405Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:45:30.413Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:45:30.413Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:46:30.415Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.433Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.433Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.477389, beta= 0.044586, gamma= 9.884804, delta= 0.003466"}
{"level":"INFO","ts":"2025-11-19T19:46:30.434Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.863341"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.434Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.816831, beta=0.043824, gamma=9.301513, delta=0.003455, NIS=2.86"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.434Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.816831, beta=0.043824, gamma=9.301513, delta=0.003455, NIS=2.863341"}
{"level":"INFO","ts":"2025-11-19T19:46:30.434Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.816831, beta: 0.043824, gamma: 9.301513, delta: 0.003455"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.437Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.816831,    beta: 0.043823566   },   prefillParms: {    gamma: 9.301513,    delta: 0.003454602   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 11.74,    ttftAverage: 23.46,    load: {     arrivalRate: 1269.73,     avgInTokens: 249,     avgOutTokens: 563    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1269.73; inTk=249; outTk=563; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=-100, itl=13.385786, ttft=79.355156, rho=0.15710773, maxRPM=823.835}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 13.385786 79.355156 {1269.73 249 563}}"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:46:30.438238363 +0000 UTC m=+800.537370501 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.438Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:46:30.438Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:46:30.438Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:46:30.446Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:46:30.446Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:47:30.447Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.468Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.468Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.816831, beta= 0.043824, gamma= 9.301513, delta= 0.003455"}
{"level":"WARN","ts":"2025-11-19T19:47:30.468Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.816831, beta=0.043824, gamma=9.301513, delta=0.003455, NIS=2.863341). Validation error: tuning validation failed: normalized innovation squared (NIS=17.47) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-19T19:47:30.468Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=17.47) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:47:30.468Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=9.816831, beta=0.043824, gamma=9.301513, delta=0.003455"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 16.22,    ttftAverage: 31.11,    load: {     arrivalRate: 2255.02,     avgInTokens: 267,     avgOutTokens: 463    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2255.02; inTk=267; outTk=463; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=200, itl=13.468155, ttft=86.75773, rho=0.115779825, maxRPM=695.44196}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 13.468155 86.75773 {2255.02 267 463}}"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:47:30.472586789 +0000 UTC m=+860.571718921 H100 4}"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.472Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:47:30.472Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:47:30.472Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:47:30.479Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:47:30.479Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:48:30.480Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.495Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.495Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.816831, beta= 0.043824, gamma= 9.301513, delta= 0.003455"}
{"level":"INFO","ts":"2025-11-19T19:48:30.496Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 5.701345"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.496Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.404648, beta=0.047964, gamma=8.381922, delta=0.003431, NIS=5.70"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.496Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.404648, beta=0.047964, gamma=8.381922, delta=0.003431, NIS=5.701345"}
{"level":"INFO","ts":"2025-11-19T19:48:30.496Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.404648, beta: 0.047964, gamma: 8.381922, delta: 0.003431"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 10.404648,    beta: 0.047964327   },   prefillParms: {    gamma: 8.381922,    delta: 0.0034310631   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 14.11,    ttftAverage: 26.8,    load: {     arrivalRate: 2248.24,     avgInTokens: 253,     avgOutTokens: 539    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2248.24; inTk=253; outTk=539; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=0, itl=13.826493, ttft=70.31052, rho=0.13738568, maxRPM=696.9821}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 13.826493 70.31052 {2248.24 253 539}}"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:48:30.506740986 +0000 UTC m=+920.605873118 H100 4}"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.506Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:48:30.506Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:48:30.506Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:48:30.513Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:48:30.513Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:49:30.515Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.531Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.532Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.404648, beta= 0.047964, gamma= 8.381922, delta= 0.003431"}
{"level":"INFO","ts":"2025-11-19T19:49:30.532Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 4.179471"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.532Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.543838, beta=0.048970, gamma=7.400574, delta=0.003395, NIS=4.18"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.532Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.543838, beta=0.048970, gamma=7.400574, delta=0.003395, NIS=4.179471"}
{"level":"INFO","ts":"2025-11-19T19:49:30.532Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.543838, beta: 0.048970, gamma: 7.400574, delta: 0.003395"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 10.543838,    beta: 0.04896999   },   prefillParms: {    gamma: 7.4005737,    delta: 0.0033950834   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 14.48,    ttftAverage: 28.73,    load: {     arrivalRate: 2502.53,     avgInTokens: 269,     avgOutTokens: 510    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2502.53; inTk=269; outTk=510; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=0, itl=14.367083, ttft=78.70308, rho=0.15053362, maxRPM=698.9659}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 14.367083 78.70308 {2502.53 269 510}}"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:49:30.536663314 +0000 UTC m=+980.635795446 H100 4}"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.536Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:49:30.536Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:49:30.536Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:49:30.543Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:49:30.543Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:50:30.544Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.560Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.560Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.543838, beta= 0.048970, gamma= 7.400574, delta= 0.003395"}
{"level":"WARN","ts":"2025-11-19T19:50:30.561Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=10.543838, beta=0.048970, gamma=7.400574, delta=0.003395, NIS=4.179471). Validation error: tuning validation failed: normalized innovation squared (NIS=12.93) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-19T19:50:30.561Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=12.93) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:50:30.561Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=10.543838, beta=0.048970, gamma=7.400574, delta=0.003395"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 13.5,    ttftAverage: 27.39,    load: {     arrivalRate: 3417.94,     avgInTokens: 260,     avgOutTokens: 521    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=3417.94; inTk=260; outTk=521; sol=1, sat=false, alloc={acc=H100; numRep=6; maxBatch=512; cost=600, val=200, itl=14.313115, ttft=97.682976, rho=0.13982739, maxRPM=619.13184}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=6, limit=0, cost=600 \ntotalCost=600 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 6 512 600 14.313115 97.682976 {3417.94 260 521}}"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:50:30.571350081 +0000 UTC m=+1040.670482212 H100 6}"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.571Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:50:30.571Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 6, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:50:30.571Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:50:30.578Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:50:30.578Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:51:30.579Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.601Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.601Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.543838, beta= 0.048970, gamma= 7.400574, delta= 0.003395"}
{"level":"INFO","ts":"2025-11-19T19:51:30.601Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.396040"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.601Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.731077, beta=0.051665, gamma=6.880469, delta=0.003385, NIS=2.40"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.601Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.731077, beta=0.051665, gamma=6.880469, delta=0.003385, NIS=2.396040"}
{"level":"INFO","ts":"2025-11-19T19:51:30.601Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.731077, beta: 0.051665, gamma: 6.880469, delta: 0.003385"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.731077,    beta: 0.05166451   },   prefillParms: {    gamma: 6.8804693,    delta: 0.0033850032   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 6,    maxBatch: 256,    cost: 600,    itlAverage: 12.12,    ttftAverage: 24.53,    load: {     arrivalRate: 2800.08,     avgInTokens: 260,     avgOutTokens: 504    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2800.08; inTk=260; outTk=504; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=-200, itl=14.109868, ttft=81.472824, rho=0.16358267, maxRPM=792.8949}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 14.109868 81.472824 {2800.08 260 504}}"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:51:30.605863454 +0000 UTC m=+1100.704995586 H100 4}"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.605Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:51:30.605Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 6, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:51:30.605Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:51:30.613Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:51:30.613Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:52:30.615Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.633Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.633Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.731077, beta= 0.051665, gamma= 6.880469, delta= 0.003385"}
{"level":"INFO","ts":"2025-11-19T19:52:30.634Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 4.432957"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.634Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.238132, beta=0.047585, gamma=6.129461, delta=0.003362, NIS=4.43"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.634Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.238132, beta=0.047585, gamma=6.129461, delta=0.003362, NIS=4.432957"}
{"level":"INFO","ts":"2025-11-19T19:52:30.634Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.238132, beta: 0.047585, gamma: 6.129461, delta: 0.003362"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.238132,    beta: 0.04758505   },   prefillParms: {    gamma: 6.129461,    delta: 0.0033616307   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 12.14,    ttftAverage: 22.79,    load: {     arrivalRate: 2536.86,     avgInTokens: 258,     avgOutTokens: 490    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2536.86; inTk=258; outTk=490; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=512; cost=300, val=-100, itl=13.907991, ttft=91.243835, rho=0.1897209, maxRPM=967.6333}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 512 300 13.907991 91.243835 {2536.86 258 490}}"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:52:30.650760708 +0000 UTC m=+1160.749892846 H100 3}"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.650Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:52:30.650Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:52:30.650Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:52:30.657Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:52:30.657Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:53:30.658Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.676Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.676Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.238132, beta= 0.047585, gamma= 6.129461, delta= 0.003362"}
{"level":"WARN","ts":"2025-11-19T19:53:30.677Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=9.238132, beta=0.047585, gamma=6.129461, delta=0.003362, NIS=4.432957). Validation error: tuning validation failed: normalized innovation squared (NIS=9.06) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-19T19:53:30.677Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=9.06) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T19:53:30.677Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=9.238132, beta=0.047585, gamma=6.129461, delta=0.003362"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 12.44,    ttftAverage: 23.71,    load: {     arrivalRate: 2364.66,     avgInTokens: 268,     avgOutTokens: 550    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=2364.66; inTk=268; outTk=550; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=512; cost=500, val=200, itl=13.437292, ttft=86.5209, rho=0.11490146, maxRPM=586.66693}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 512 500 13.437292 86.5209 {2364.66 268 550}}"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:53:30.688265607 +0000 UTC m=+1220.787397739 H100 5}"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.688Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:53:30.688Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:53:30.688Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:53:30.694Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:53:30.694Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:54:30.696Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.709Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.709Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.238132, beta= 0.047585, gamma= 6.129461, delta= 0.003362"}
{"level":"INFO","ts":"2025-11-19T19:54:30.710Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.383824"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.710Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.676132, beta=0.044342, gamma=6.033899, delta=0.003362, NIS=0.38"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.710Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.676132, beta=0.044342, gamma=6.033899, delta=0.003362, NIS=0.383824"}
{"level":"INFO","ts":"2025-11-19T19:54:30.710Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.676132, beta: 0.044342, gamma: 6.033899, delta: 0.003362"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.676132,    beta: 0.044341568   },   prefillParms: {    gamma: 6.0338993,    delta: 0.00336202   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 10.78,    ttftAverage: 21.51,    load: {     arrivalRate: 1143.05,     avgInTokens: 259,     avgOutTokens: 527    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1143.05; inTk=259; outTk=527; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=-300, itl=12.53059, ttft=62.088676, rho=0.12377794, maxRPM=892.9208}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.53059 62.088676 {1143.05 259 527}}"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:54:30.721290739 +0000 UTC m=+1280.820422871 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.721Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:54:30.721Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:54:30.721Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:54:30.728Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:54:30.728Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:55:30.729Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.745Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.745Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.676132, beta= 0.044342, gamma= 6.033899, delta= 0.003362"}
{"level":"INFO","ts":"2025-11-19T19:55:30.747Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 4.844946"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.747Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.401730, beta=0.038907, gamma=5.191071, delta=0.003326, NIS=4.84"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.747Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.401730, beta=0.038907, gamma=5.191071, delta=0.003326, NIS=4.844946"}
{"level":"INFO","ts":"2025-11-19T19:55:30.747Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.401730, beta: 0.038907, gamma: 5.191071, delta: 0.003326"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.40173,    beta: 0.038906716   },   prefillParms: {    gamma: 5.191071,    delta: 0.0033261392   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.32,    ttftAverage: 24.88,    load: {     arrivalRate: 1569.95,     avgInTokens: 264,     avgOutTokens: 470    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1569.95; inTk=264; outTk=470; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=12.4506035, ttft=74.00227, rho=0.1511009, maxRPM=1196.3058}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.4506035 74.00227 {1569.95 264 470}}"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:55:30.757982854 +0000 UTC m=+1340.857114986 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.757Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:55:30.758Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:55:30.758Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:55:30.765Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:55:30.765Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:56:30.766Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.781Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.781Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.401730, beta= 0.038907, gamma= 5.191071, delta= 0.003326"}
{"level":"INFO","ts":"2025-11-19T19:56:30.783Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 7.088017"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.783Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.148712, beta=0.037250, gamma=4.197200, delta=0.003267, NIS=7.09"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.783Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.148712, beta=0.037250, gamma=4.197200, delta=0.003267, NIS=7.088017"}
{"level":"INFO","ts":"2025-11-19T19:56:30.783Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.148712, beta: 0.037250, gamma: 4.197200, delta: 0.003267"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.148712,    beta: 0.037250448   },   prefillParms: {    gamma: 4.1972003,    delta: 0.003266945   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.5,    ttftAverage: 25.6,    load: {     arrivalRate: 1675.65,     avgInTokens: 288,     avgOutTokens: 508    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1675.65; inTk=288; outTk=508; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=12.5396385, ttft=89.84596, rho=0.17584077, maxRPM=1207.2687}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.5396385 89.84596 {1675.65 288 508}}"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:56:30.799341766 +0000 UTC m=+1400.898473897 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.799Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:56:30.799Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:56:30.799Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:56:30.806Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:56:30.806Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:57:30.807Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.825Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.826Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.148712, beta= 0.037250, gamma= 4.197200, delta= 0.003267"}
{"level":"INFO","ts":"2025-11-19T19:57:30.828Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 4.232496"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.828Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.024434, beta=0.037245, gamma=3.357709, delta=0.003233, NIS=4.23"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.828Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.024434, beta=0.037245, gamma=3.357709, delta=0.003233, NIS=4.232496"}
{"level":"INFO","ts":"2025-11-19T19:57:30.828Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.024434, beta: 0.037245, gamma: 3.357709, delta: 0.003233"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.840Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.840Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.024434,    beta: 0.037244957   },   prefillParms: {    gamma: 3.3577094,    delta: 0.0032326616   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.17,    ttftAverage: 24.69,    load: {     arrivalRate: 1649.44,     avgInTokens: 268,     avgOutTokens: 491    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1649.44; inTk=268; outTk=491; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=12.147936, ttft=76.01334, rho=0.1618433, maxRPM=1276.819}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.147936 76.01334 {1649.44 268 491}}"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:57:30.841192584 +0000 UTC m=+1460.940324719 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.841Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:57:30.841Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:57:30.841Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:57:30.848Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:57:30.848Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:58:30.850Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.866Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.866Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.024434, beta= 0.037245, gamma= 3.357709, delta= 0.003233"}
{"level":"INFO","ts":"2025-11-19T19:58:30.867Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.438541"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.867Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.024200, beta=0.037254, gamma=2.596003, delta=0.003206, NIS=3.44"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.867Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.024200, beta=0.037254, gamma=2.596003, delta=0.003206, NIS=3.438541"}
{"level":"INFO","ts":"2025-11-19T19:58:30.867Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.024200, beta: 0.037254, gamma: 2.596003, delta: 0.003206"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.0242,    beta: 0.037254084   },   prefillParms: {    gamma: 2.5960026,    delta: 0.0032062116   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.97,    ttftAverage: 24.44,    load: {     arrivalRate: 1544.28,     avgInTokens: 275,     avgOutTokens: 494    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1544.28; inTk=275; outTk=494; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=11.910582, ttft=70.909195, rho=0.14937153, maxRPM=1268.6522}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 11.910582 70.909195 {1544.28 275 494}}"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:58:30.883698569 +0000 UTC m=+1520.982830701 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.883Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:58:30.883Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:58:30.883Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:58:30.890Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:58:30.890Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T19:59:30.890Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.906Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.906Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.024200, beta= 0.037254, gamma= 2.596003, delta= 0.003206"}
{"level":"INFO","ts":"2025-11-19T19:59:30.907Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.721928"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.907Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.104848, beta=0.037425, gamma=1.840633, delta=0.003178, NIS=3.72"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.907Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.104848, beta=0.037425, gamma=1.840633, delta=0.003178, NIS=3.721928"}
{"level":"INFO","ts":"2025-11-19T19:59:30.907Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.104848, beta: 0.037425, gamma: 1.840633, delta: 0.003178"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.916Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.916Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.104848,    beta: 0.03742546   },   prefillParms: {    gamma: 1.840633,    delta: 0.0031781339   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.33,    ttftAverage: 24.87,    load: {     arrivalRate: 1368.42,     avgInTokens: 267,     avgOutTokens: 587    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=1368.42; inTk=267; outTk=587; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=12.23263, ttft=72.75802, rho=0.16127665, maxRPM=1052.1555}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 12.23263 72.75802 {1368.42 267 587}}"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 19:59:30.917139843 +0000 UTC m=+1581.016271975 H100 2}"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.917Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T19:59:30.917Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T19:59:30.917Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T19:59:30.924Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T19:59:30.924Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T20:00:30.925Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.939Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.939Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.104848, beta= 0.037425, gamma= 1.840633, delta= 0.003178"}
{"level":"INFO","ts":"2025-11-19T20:00:30.939Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.303948"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.939Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.387712, beta=0.036002, gamma=1.668516, delta=0.003178, NIS=0.30"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.939Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.387712, beta=0.036002, gamma=1.668516, delta=0.003178, NIS=0.303948"}
{"level":"INFO","ts":"2025-11-19T20:00:30.939Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.387712, beta: 0.036002, gamma: 1.668516, delta: 0.003178"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.3877125,    beta: 0.036002252   },   prefillParms: {    gamma: 1.6685164,    delta: 0.0031776289   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 10.81,    ttftAverage: 21.97,    load: {     arrivalRate: 815.1,     avgInTokens: 246,     avgOutTokens: 495    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=815.1; inTk=246; outTk=495; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-100, itl=12.4702, ttft=68.596825, rho=0.16527201, maxRPM=1233.5825}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 12.4702 68.596825 {815.1 246 495}}"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 20:00:30.950331274 +0000 UTC m=+1641.049463405 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.950Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T20:00:30.950Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T20:00:30.950Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T20:00:30.957Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T20:00:30.957Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T20:01:30.958Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.974Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.974Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.387712, beta= 0.036002, gamma= 1.668516, delta= 0.003178"}
{"level":"INFO","ts":"2025-11-19T20:01:30.976Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 4.765232"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.976Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.380416, beta=0.035891, gamma=0.908193, delta=0.003141, NIS=4.77"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.976Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.380416, beta=0.035891, gamma=0.908193, delta=0.003141, NIS=4.765232"}
{"level":"INFO","ts":"2025-11-19T20:01:30.976Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.380416, beta: 0.035891, gamma: 0.908193, delta: 0.003141"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.380416,    beta: 0.035891373   },   prefillParms: {    gamma: 0.9081932,    delta: 0.003140734   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.97,    ttftAverage: 25.41,    load: {     arrivalRate: 869.33,     avgInTokens: 257,     avgOutTokens: 514    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=869.33; inTk=257; outTk=514; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=12.899036, ttft=80.03921, rho=0.189522, maxRPM=1193.2971}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 12.899036 80.03921 {869.33 257 514}}"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 20:01:30.987505357 +0000 UTC m=+1701.086637488 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.987Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T20:01:30.987Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T20:01:30.987Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T20:01:30.994Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T20:01:30.994Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T20:02:30.995Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.009Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.009Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.380416, beta= 0.035891, gamma= 0.908193, delta= 0.003141"}
{"level":"INFO","ts":"2025-11-19T20:02:31.011Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 5.891922"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.011Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.328412, beta=0.035678, gamma=0.149014, delta=0.003095, NIS=5.89"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.011Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.328412, beta=0.035678, gamma=0.149014, delta=0.003095, NIS=5.891922"}
{"level":"INFO","ts":"2025-11-19T20:02:31.011Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.328412, beta: 0.035678, gamma: 0.149014, delta: 0.003095"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.026Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.026Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.026Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.026Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.328412,    beta: 0.03567805   },   prefillParms: {    gamma: 0.14901422,    delta: 0.003094531   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 13.11,    ttftAverage: 26.19,    load: {     arrivalRate: 914.67,     avgInTokens: 269,     avgOutTokens: 513    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=914.67; inTk=269; outTk=513; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=13.043625, ttft=86.83117, rho=0.20142888, maxRPM=1213.1814}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 13.043625 86.83117 {914.67 269 513}}"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 20:02:31.027095525 +0000 UTC m=+1761.126227656 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.027Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T20:02:31.027Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T20:02:31.027Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T20:02:31.033Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T20:02:31.033Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T20:03:31.034Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.052Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.052Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.328412, beta= 0.035678, gamma= 0.149014, delta= 0.003095"}
{"level":"INFO","ts":"2025-11-19T20:03:31.052Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.150736"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.052Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.294927, beta=0.035746, gamma=0.014901, delta=0.003080, NIS=2.15"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.052Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.294927, beta=0.035746, gamma=0.014901, delta=0.003080, NIS=2.150736"}
{"level":"INFO","ts":"2025-11-19T20:03:31.052Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.294927, beta: 0.035746, gamma: 0.014901, delta: 0.003080"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.067Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.067Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.067Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.067Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.294927,    beta: 0.035745997   },   prefillParms: {    gamma: 0.0149014,    delta: 0.0030798658   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.067Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.067Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.02,    ttftAverage: 23.5,    load: {     arrivalRate: 783.33,     avgInTokens: 262,     avgOutTokens: 471    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.068Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=783.33; inTk=262; outTk=471; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=11.988654, ttft=60.822712, rho=0.14522944, maxRPM=1325.5708}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.068Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 11.988654 60.822712 {783.33 262 471}}"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.068Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.068Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.068Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 20:03:31.06802155 +0000 UTC m=+1821.167153682 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.068Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.068Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T20:03:31.068Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T20:03:31.068Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T20:03:31.075Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T20:03:31.075Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T20:04:31.076Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.094Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.094Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.294927, beta= 0.035746, gamma= 0.014901, delta= 0.003080"}
{"level":"INFO","ts":"2025-11-19T20:04:31.096Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.831931"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.096Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=9.200001, beta=0.035280, gamma=0.001490, delta=0.003050, NIS=3.83"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.096Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=9.200001, beta=0.035280, gamma=0.001490, delta=0.003050, NIS=3.831931"}
{"level":"INFO","ts":"2025-11-19T20:04:31.096Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 9.200001, beta: 0.035280, gamma: 0.001490, delta: 0.003050"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.111Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.111Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.111Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.111Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.200001,    beta: 0.035279814   },   prefillParms: {    gamma: 0.0014901,    delta: 0.0030504037   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.111Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.112Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.66,    ttftAverage: 24.66,    load: {     arrivalRate: 884.67,     avgInTokens: 249,     avgOutTokens: 513    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.112Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=884.67; inTk=249; outTk=513; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=12.640368, ttft=74.070274, rho=0.18850897, maxRPM=1256.138}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.112Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 12.640368 74.070274 {884.67 249 513}}"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.112Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.112Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.112Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 20:04:31.112074787 +0000 UTC m=+1881.211206919 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.112Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.112Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T20:04:31.112Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T20:04:31.112Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T20:04:31.118Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T20:04:31.118Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T20:05:31.119Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.135Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.135Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 9.200001, beta= 0.035280, gamma= 0.001490, delta= 0.003050"}
{"level":"INFO","ts":"2025-11-19T20:05:31.135Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 2.806913"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.135Z","msg":"Model tuner results: model=ibm-granite/granite-3.3-8b-instruct, accelerator=H100, alpha=10.316335, beta=0.030218, gamma=0.000149, delta=0.003048, NIS=2.81"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.135Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=10.316335, beta=0.030218, gamma=0.000149, delta=0.003048, NIS=2.806913"}
{"level":"INFO","ts":"2025-11-19T20:05:31.135Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 10.316335, beta: 0.030218, gamma: 0.000149, delta: 0.003048"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 10.316335,    beta: 0.030218277   },   prefillParms: {    gamma: 0.000149,    delta: 0.003047855   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 11.82,    ttftAverage: 24.63,    load: {     arrivalRate: 353.33,     avgInTokens: 266,     avgOutTokens: 563    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=353.33; inTk=266; outTk=563; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=11.502566, ttft=31.82569, rho=0.074717656, maxRPM=1079.9484}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 11.502566 31.82569 {353.33 266 563}}"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 20:05:31.151380154 +0000 UTC m=+1941.250512292 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.151Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T20:05:31.151Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T20:05:31.151Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T20:05:31.157Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T20:05:31.158Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-19T20:06:31.159Z","msg":"Found SLO for model - model: ibm-granite/granite-3.3-8b-instruct, class: Premium, slo-tpot: 15, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.171Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.171Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 10.316335, beta= 0.030218, gamma= 0.000149, delta= 0.003048"}
{"level":"WARN","ts":"2025-11-19T20:06:31.171Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-19T20:06:31.171Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=10.316335, beta=0.030218, gamma=0.000149, delta=0.003048"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.171Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.171Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.171Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: ibm-granite/granite-3.3-8b-instruct,     slo-itl: 15,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"System data prepared for optimization: - { models: [  {   name: ibm-granite/granite-3.3-8b-instruct,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 9.33137,    beta: 0.068627   },   prefillParms: {    gamma: 23.49,    delta: 0.003931   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: ibm-granite/granite-3.3-8b-instruct,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=ibm-granite/granite-3.3-8b-instruct; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.399998, ttft=23.49393, rho=0, maxRPM=452015.12}; slo-itl=15, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.399998 23.49393 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-19 20:06:31.172091569 +0000 UTC m=+2001.271223699 H100 1}"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.172Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-19T20:06:31.172Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-19T20:06:31.172Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-19T20:06:31.178Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-19T20:06:31.178Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
