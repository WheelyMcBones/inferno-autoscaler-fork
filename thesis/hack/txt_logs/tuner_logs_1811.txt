{"level":"INFO","ts":"2025-11-18T18:12:14.584Z","msg":"Zap logger initialized"}
{"level":"INFO","ts":"2025-11-18T18:12:14.587Z","msg":"Creating metrics emitter instance"}
{"level":"INFO","ts":"2025-11-18T18:12:14.587Z","msg":"Metrics emitter created successfully"}
{"level":"INFO","ts":"2025-11-18T18:12:14.587Z","msg":"Using Prometheus configuration from environment variablesaddresshttps://thanos-querier.openshift-monitoring.svc.cluster.local:9091"}
{"level":"WARN","ts":"2025-11-18T18:12:14.587Z","msg":"TLS certificate verification is disabled - this is not recommended for production"}
{"level":"INFO","ts":"2025-11-18T18:12:14.587Z","msg":"Initializing Prometheus client -> address: https://thanos-querier.openshift-monitoring.svc.cluster.local:9091 tls_enabled: true"}
{"level":"INFO","ts":"2025-11-18T18:12:14.587Z","msg":"CA certificate loaded successfullypath/etc/ssl/certs/prometheus-ca.crt"}
{"level":"INFO","ts":"2025-11-18T18:12:14.587Z","msg":"TLS configuration applied to Prometheus HTTPS transport"}
{"level":"INFO","ts":"2025-11-18T18:12:14.587Z","msg":"Bearer token loaded from filepath/var/run/secrets/kubernetes.io/serviceaccount/token"}
{"level":"INFO","ts":"2025-11-18T18:12:14.660Z","msg":"Prometheus API validation successful with queryqueryup"}
{"level":"INFO","ts":"2025-11-18T18:12:14.660Z","msg":"Prometheus client and API wrapper initialized and validated successfully"}
{"level":"INFO","ts":"2025-11-18T18:12:14.660Z","msg":"Starting manager"}
{"level":"INFO","ts":"2025-11-18T18:12:14.660Z","msg":"Registering custom metrics with Prometheus registry"}
{"level":"info","ts":"2025-11-18T18:12:14Z","logger":"controller-runtime.metrics","msg":"Starting metrics server"}
{"level":"INFO","ts":"2025-11-18T18:12:14.660Z","msg":"disabling http/2"}
{"level":"info","ts":"2025-11-18T18:12:14Z","msg":"starting server","name":"health probe","addr":"[::]:8081"}
I1118 18:12:14.661111       1 leaderelection.go:257] attempting to acquire leader lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai...
{"level":"info","ts":"2025-11-18T18:12:15Z","logger":"controller-runtime.metrics","msg":"Serving metrics server","bindAddress":":8443","secure":true}
I1118 18:12:32.130315       1 leaderelection.go:271] successfully acquired lease workload-variant-autoscaler-system/72dd1cf1.llm-d.ai
{"level":"info","ts":"2025-11-18T18:12:32Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1.ConfigMap"}
{"level":"info","ts":"2025-11-18T18:12:32Z","msg":"Starting EventSource","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","source":"kind source: *v1alpha1.VariantAutoscaling"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.246Z","msg":"ConfigMap watch enqueueing requests: count=1"}
{"level":"info","ts":"2025-11-18T18:12:33Z","msg":"Starting Controller","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling"}
{"level":"info","ts":"2025-11-18T18:12:33Z","msg":"Starting workers","controller":"variantAutoscaling","controllerGroup":"llmd.ai","controllerKind":"VariantAutoscaling","worker count":1}
{"level":"INFO","ts":"2025-11-18T18:12:33.277Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.470000, beta= 0.044000, gamma= 15.415000, delta= 0.000337"}
{"level":"WARN","ts":"2025-11-18T18:12:33.389Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"VA status already has valid tuner parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler (skipping update): alpha=7.470, beta=0.044, gamma=15.415, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=7.514, ttft=15.415337, rho=0, maxRPM=676453.25}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.514 15.415337 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:12:33.38972617 +0000 UTC m=+18.882446664 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.389Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:12:33.389Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:12:33.389Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:12:33.395Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:12:33.395Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:13:33.395Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.470000, beta= 0.044000, gamma= 15.415000, delta= 0.000337"}
{"level":"WARN","ts":"2025-11-18T18:13:33.413Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"VA status already has valid tuner parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler (skipping update): alpha=7.470, beta=0.044, gamma=15.415, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=7.514, ttft=15.415337, rho=0, maxRPM=676453.25}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.514 15.415337 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:13:33.413611375 +0000 UTC m=+78.906331869 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.413Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:13:33.413Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:13:33.413Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:13:33.419Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:13:33.419Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:14:33.419Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.470000, beta= 0.044000, gamma= 15.415000, delta= 0.000337"}
{"level":"WARN","ts":"2025-11-18T18:14:33.439Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 39.88 7.84 1}. Using fallback parameters."}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"VA status already has valid tuner parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler (skipping update): alpha=7.470, beta=0.044, gamma=15.415, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 7.84,    ttftAverage: 39.88,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=7.514, ttft=15.415337, rho=0, maxRPM=676453.25}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.514 15.415337 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:14:33.439766911 +0000 UTC m=+138.932487411 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.439Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:14:33.439Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:14:33.439Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:14:33.445Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:14:33.445Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:15:33.445Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.482Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.482Z","msg":"Using initial state from spec for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.470000, beta= 0.044000, gamma= 15.415000, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:15:33.483Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.034487"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.483Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.382934, beta=0.043824, gamma=15.415886, delta=0.000337, NIS=0.03"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.483Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.382934, beta=0.043824, gamma=15.415886, delta=0.000337, NIS=0.034487"}
{"level":"INFO","ts":"2025-11-18T18:15:33.483Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.382934, beta: 0.043824, gamma: 15.415886, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.3829336,    beta: 0.043823894   },   prefillParms: {    gamma: 15.415886,    delta: 0.00033700612   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.89,    ttftAverage: 20.78,    load: {     arrivalRate: 715.18,     avgInTokens: 246,     avgOutTokens: 478    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=715.18; inTk=246; outTk=478; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.905424, ttft=20.187788, rho=0.11046819, maxRPM=735.4481}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.905424 20.187788 {715.18 246 478}}"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:15:33.493841585 +0000 UTC m=+198.986562090 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.493Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:15:33.493Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:15:33.493Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:15:33.502Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:15:33.502Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:16:33.503Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.550Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.550Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.382934, beta= 0.043824, gamma= 15.415886, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:16:33.552Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.258898"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.552Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.203609, beta=0.043464, gamma=15.414364, delta=0.000337, NIS=0.26"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.552Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.203609, beta=0.043464, gamma=15.414364, delta=0.000337, NIS=0.258898"}
{"level":"INFO","ts":"2025-11-18T18:16:33.552Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.203609, beta: 0.043464, gamma: 15.414364, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.563Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.564Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.564Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.564Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.2036085,    beta: 0.04346363   },   prefillParms: {    gamma: 15.414364,    delta: 0.00033699567   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.564Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.564Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.56,    ttftAverage: 19.11,    load: {     arrivalRate: 696.3,     avgInTokens: 221,     avgOutTokens: 487    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.565Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=696.3; inTk=221; outTk=487; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.613562, ttft=19.54388, rho=0.10634293, maxRPM=778.7231}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.565Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.613562 19.54388 {696.3 221 487}}"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.565Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.565Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.565Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:16:33.565129104 +0000 UTC m=+259.057849600 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.565Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.565Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:16:33.565Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:16:33.565Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:16:33.575Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:16:33.575Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:17:33.577Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.591Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.591Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.203609, beta= 0.043464, gamma= 15.414364, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:17:33.591Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.004409"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.591Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.226817, beta=0.043491, gamma=15.413539, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.592Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.226817, beta=0.043491, gamma=15.413539, delta=0.000337, NIS=0.004409"}
{"level":"INFO","ts":"2025-11-18T18:17:33.592Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.226817, beta: 0.043491, gamma: 15.413539, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.2268167,    beta: 0.04349122   },   prefillParms: {    gamma: 15.413539,    delta: 0.000336999   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.43,    ttftAverage: 19.26,    load: {     arrivalRate: 689.49,     avgInTokens: 240,     avgOutTokens: 456    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=689.49; inTk=240; outTk=456; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.422792, ttft=19.49735, rho=0.09666478, maxRPM=823.9367}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.422792 19.49735 {689.49 240 456}}"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:17:33.601292753 +0000 UTC m=+319.094013246 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.601Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:17:33.601Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:17:33.601Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:17:33.606Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:17:33.606Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:18:33.607Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.621Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.621Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.226817, beta= 0.043491, gamma= 15.413539, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:18:33.621Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.219383"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.621Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.080405, beta=0.042875, gamma=15.407756, delta=0.000337, NIS=0.22"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.621Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.080405, beta=0.042875, gamma=15.407756, delta=0.000337, NIS=0.219383"}
{"level":"INFO","ts":"2025-11-18T18:18:33.621Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.080405, beta: 0.042875, gamma: 15.407756, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.625Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.0804048,    beta: 0.04287457   },   prefillParms: {    gamma: 15.407756,    delta: 0.00033699066   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.74,    ttftAverage: 18.85,    load: {     arrivalRate: 815.72,     avgInTokens: 216,     avgOutTokens: 466    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=815.72; inTk=216; outTk=466; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.787911, ttft=20.004406, rho=0.1213857, maxRPM=861.98175}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.787911 20.004406 {815.72 216 466}}"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:18:33.626351018 +0000 UTC m=+379.119071514 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.626Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:18:33.626Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:18:33.626Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:18:33.631Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:18:33.631Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:19:33.632Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.644Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.644Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.080405, beta= 0.042875, gamma= 15.407756, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:19:33.645Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.075996"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.645Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.177145, beta=0.042969, gamma=15.403936, delta=0.000337, NIS=0.08"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.645Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.177145, beta=0.042969, gamma=15.403936, delta=0.000337, NIS=0.075996"}
{"level":"INFO","ts":"2025-11-18T18:19:33.645Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.177145, beta: 0.042969, gamma: 15.403936, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.177145,    beta: 0.042968575   },   prefillParms: {    gamma: 15.403936,    delta: 0.00033699704   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.62,    ttftAverage: 19.24,    load: {     arrivalRate: 694.28,     avgInTokens: 240,     avgOutTokens: 496    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=694.28; inTk=240; outTk=496; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.590374, ttft=19.946331, rho=0.107739545, maxRPM=780.923}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.590374 19.946331 {694.28 240 496}}"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:19:33.654785172 +0000 UTC m=+439.147505666 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.654Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:19:33.654Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:19:33.654Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:19:33.660Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:19:33.660Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:20:33.661Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.676Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.676Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.177145, beta= 0.042969, gamma= 15.403936, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:20:33.677Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.098220"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.677Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.286743, beta=0.043110, gamma=15.401803, delta=0.000337, NIS=0.10"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.677Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.286743, beta=0.043110, gamma=15.401803, delta=0.000337, NIS=0.098220"}
{"level":"INFO","ts":"2025-11-18T18:20:33.677Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.286743, beta: 0.043110, gamma: 15.401803, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.686Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.2867427,    beta: 0.04310997   },   prefillParms: {    gamma: 15.401803,    delta: 0.0003369993   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.67,    ttftAverage: 19.03,    load: {     arrivalRate: 738.58,     avgInTokens: 218,     avgOutTokens: 450    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=738.58; inTk=218; outTk=450; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.636164, ttft=19.40557, rho=0.10448896, maxRPM=824.00525}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.636164 19.40557 {738.58 218 450}}"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:20:33.687207389 +0000 UTC m=+499.179927890 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.687Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:20:33.687Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:20:33.687Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:20:33.693Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:20:33.693Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:21:33.694Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.712Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.712Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.286743, beta= 0.043110, gamma= 15.401803, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:21:33.713Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.357804"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.713Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.316325, beta=0.037315, gamma=15.380268, delta=0.000337, NIS=1.36"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.713Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.316325, beta=0.037315, gamma=15.380268, delta=0.000337, NIS=1.357804"}
{"level":"INFO","ts":"2025-11-18T18:21:33.713Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.316325, beta: 0.037315, gamma: 15.380268, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.316325,    beta: 0.037314765   },   prefillParms: {    gamma: 15.380268,    delta: 0.0003369353   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 12.74,    ttftAverage: 25.19,    load: {     arrivalRate: 1490.98,     avgInTokens: 245,     avgOutTokens: 468    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1490.98; inTk=245; outTk=468; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=100, itl=9.3976345, ttft=19.984621, rho=0.10698655, maxRPM=907.0348}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.3976345 19.984621 {1490.98 245 468}}"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:21:33.722406194 +0000 UTC m=+559.215126687 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.722Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:21:33.722Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:21:33.722Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:21:33.728Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:21:33.728Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:22:33.729Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.744Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.744Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.316325, beta= 0.037315, gamma= 15.380268, delta= 0.000337"}
{"level":"WARN","ts":"2025-11-18T18:22:33.745Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=7.316325, beta=0.037315, gamma=15.380268, delta=0.000337, NIS=1.357804). Validation error: tuning validation failed: normalized innovation squared (NIS=11.70) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-18T18:22:33.745Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=11.70) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-18T18:22:33.745Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=7.316325, beta=0.037315, gamma=15.380268, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.754Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.754Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.754Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 11.31,    ttftAverage: 22.05,    load: {     arrivalRate: 1123.29,     avgInTokens: 216,     avgOutTokens: 510    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1123.29; inTk=216; outTk=510; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.516897, ttft=18.801313, rho=0.08890706, maxRPM=663.45654}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.516897 18.801313 {1123.29 216 510}}"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:22:33.755134342 +0000 UTC m=+619.247854835 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.755Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:22:33.755Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:22:33.755Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:22:33.760Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:22:33.760Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:23:33.761Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.773Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.773Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.316325, beta= 0.037315, gamma= 15.380268, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:23:33.773Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 3.247058"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.773Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.335760, beta=0.033946, gamma=15.392261, delta=0.000337, NIS=3.25"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.773Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.335760, beta=0.033946, gamma=15.392261, delta=0.000337, NIS=3.247058"}
{"level":"INFO","ts":"2025-11-18T18:23:33.773Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.335760, beta: 0.033946, gamma: 15.392261, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.33576,    beta: 0.033946406   },   prefillParms: {    gamma: 15.392261,    delta: 0.00033700513   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.33,    ttftAverage: 19.24,    load: {     arrivalRate: 757.07,     avgInTokens: 245,     avgOutTokens: 396    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=757.07; inTk=245; outTk=396; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.147238, ttft=17.365978, rho=0.0447357, maxRPM=725.9322}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.147238 17.365978 {757.07 245 396}}"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:23:33.783945497 +0000 UTC m=+679.276666008 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.783Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:23:33.784Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:23:33.784Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:23:33.789Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:23:33.789Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:24:33.790Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.805Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.805Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.335760, beta= 0.033946, gamma= 15.392261, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:24:33.806Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.485047"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.806Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.850008, beta=0.033063, gamma=15.387136, delta=0.000337, NIS=1.49"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.806Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.850008, beta=0.033063, gamma=15.387136, delta=0.000337, NIS=1.485047"}
{"level":"INFO","ts":"2025-11-18T18:24:33.806Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.850008, beta: 0.033063, gamma: 15.387136, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.850008,    beta: 0.033062562   },   prefillParms: {    gamma: 15.3871355,    delta: 0.00033699285   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.64,    ttftAverage: 19.26,    load: {     arrivalRate: 1612.2,     avgInTokens: 224,     avgOutTokens: 433    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1612.2; inTk=224; outTk=433; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.76584, ttft=19.761244, rho=0.111221954, maxRPM=885.1169}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.76584 19.761244 {1612.2 224 433}}"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:24:33.8156799 +0000 UTC m=+739.308400400 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.815Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:24:33.815Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:24:33.815Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:24:33.821Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:24:33.821Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:25:33.822Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.834Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.834Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.850008, beta= 0.033063, gamma= 15.387136, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:25:33.835Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.075717"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.835Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.747109, beta=0.032926, gamma=15.381063, delta=0.000337, NIS=0.08"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.835Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.747109, beta=0.032926, gamma=15.381063, delta=0.000337, NIS=0.075717"}
{"level":"INFO","ts":"2025-11-18T18:25:33.835Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.747109, beta: 0.032926, gamma: 15.381063, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.747109,    beta: 0.03292613   },   prefillParms: {    gamma: 15.381063,    delta: 0.0003369951   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.82,    ttftAverage: 19.51,    load: {     arrivalRate: 1581.58,     avgInTokens: 221,     avgOutTokens: 483    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1581.58; inTk=221; outTk=483; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.848848, ttft=20.135006, rho=0.12271866, maxRPM=835.73364}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.848848 20.135006 {1581.58 221 483}}"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:25:33.84444711 +0000 UTC m=+799.337167604 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.844Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:25:33.844Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:25:33.844Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:25:33.850Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:25:33.850Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:26:33.851Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.865Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.865Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.747109, beta= 0.032926, gamma= 15.381063, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:26:33.866Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.002375"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.866Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.730295, beta=0.032921, gamma=15.374997, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.866Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.730295, beta=0.032921, gamma=15.374997, delta=0.000337, NIS=0.002375"}
{"level":"INFO","ts":"2025-11-18T18:26:33.866Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.730295, beta: 0.032921, gamma: 15.374997, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.730295,    beta: 0.03292146   },   prefillParms: {    gamma: 15.374997,    delta: 0.00033699686   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.57,    ttftAverage: 18.86,    load: {     arrivalRate: 1515.55,     avgInTokens: 215,     avgOutTokens: 454    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1515.55; inTk=215; outTk=454; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.574693, ttft=19.43419, rho=0.10746913, maxRPM=895.8793}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.574693 19.43419 {1515.55 215 454}}"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:26:33.876470176 +0000 UTC m=+859.369190670 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.876Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:26:33.876Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:26:33.876Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:26:33.881Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:26:33.881Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:27:33.883Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.908Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.908Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.730295, beta= 0.032921, gamma= 15.374997, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:27:33.909Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.108185"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.909Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.687745, beta=0.031967, gamma=15.338614, delta=0.000337, NIS=0.11"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.909Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.687745, beta=0.031967, gamma=15.338614, delta=0.000337, NIS=0.108185"}
{"level":"INFO","ts":"2025-11-18T18:27:33.909Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.687745, beta: 0.031967, gamma: 15.338614, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.6877446,    beta: 0.031967126   },   prefillParms: {    gamma: 15.338614,    delta: 0.0003369437   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 12.63,    ttftAverage: 24.58,    load: {     arrivalRate: 3166.84,     avgInTokens: 237,     avgOutTokens: 461    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=3166.84; inTk=237; outTk=461; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=200, itl=9.588715, ttft=20.087341, rho=0.11419221, maxRPM=926.16956}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 9.588715 20.087341 {3166.84 237 461}}"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:27:33.91396529 +0000 UTC m=+919.406685791 H100 4}"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.913Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:27:33.914Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:27:33.914Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:27:33.919Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:27:33.919Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:28:33.920Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.940Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.940Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.687745, beta= 0.031967, gamma= 15.338614, delta= 0.000337"}
{"level":"WARN","ts":"2025-11-18T18:28:33.940Z","msg":"Tuner NIS validation failed for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - Keeping previous state (alpha=7.687745, beta=0.031967, gamma=15.338614, delta=0.000337, NIS=0.108185). Validation error: tuning validation failed: normalized innovation squared (NIS=10.94) exceeds threshold (7.38), rejecting update as outlier"}
{"level":"WARN","ts":"2025-11-18T18:28:33.940Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: tuning validation failed: normalized innovation squared (NIS=10.94) exceeds threshold (7.38), rejecting update as outlier. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-18T18:28:33.940Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=7.687745, beta=0.031967, gamma=15.338614, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 11.51,    ttftAverage: 22.27,    load: {     arrivalRate: 2456.95,     avgInTokens: 207,     avgOutTokens: 523    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=2456.95; inTk=207; outTk=523; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=0, itl=9.835179, ttft=19.164831, rho=0.10303531, maxRPM=647.0157}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 9.835179 19.164831 {2456.95 207 523}}"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:28:33.95091129 +0000 UTC m=+979.443631784 H100 4}"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.950Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:28:33.950Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:28:33.950Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:28:33.956Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:28:33.956Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:29:33.957Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.976Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.976Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.687745, beta= 0.031967, gamma= 15.338614, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:29:33.977Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 4.711631"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.977Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.876982, beta=0.028391, gamma=15.360911, delta=0.000337, NIS=4.71"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.977Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.876982, beta=0.028391, gamma=15.360911, delta=0.000337, NIS=4.711631"}
{"level":"INFO","ts":"2025-11-18T18:29:33.977Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.876982, beta: 0.028391, gamma: 15.360911, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.876982,    beta: 0.028390756   },   prefillParms: {    gamma: 15.360911,    delta: 0.00033700795   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 10.05,    ttftAverage: 20.05,    load: {     arrivalRate: 1892.89,     avgInTokens: 229,     avgOutTokens: 415    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1892.89; inTk=229; outTk=415; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=0, itl=9.819695, ttft=17.923498, rho=0.06290035, maxRPM=556.30853}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 9.819695 17.923498 {1892.89 229 415}}"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:29:33.986744055 +0000 UTC m=+1039.479464548 H100 4}"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.986Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:29:33.986Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:29:33.986Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:29:33.991Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:29:33.991Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:30:33.992Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.008Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.008Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.876982, beta= 0.028391, gamma= 15.360911, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:30:34.009Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 1.543926"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.009Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.352426, beta=0.027622, gamma=15.362002, delta=0.000337, NIS=1.54"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.009Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.352426, beta=0.027622, gamma=15.362002, delta=0.000337, NIS=1.543926"}
{"level":"INFO","ts":"2025-11-18T18:30:34.009Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.352426, beta: 0.027622, gamma: 15.362002, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.352426,    beta: 0.027622312   },   prefillParms: {    gamma: 15.362002,    delta: 0.00033699628   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 9.97,    ttftAverage: 20.52,    load: {     arrivalRate: 3403.18,     avgInTokens: 239,     avgOutTokens: 433    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=3403.18; inTk=239; outTk=433; sol=1, sat=false, alloc={acc=H100; numRep=5; maxBatch=512; cost=500, val=100, itl=9.698999, ttft=19.288391, rho=0.09326079, maxRPM=810.7464}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=5, limit=0, cost=500 \ntotalCost=500 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 5 512 500 9.698999 19.288391 {3403.18 239 433}}"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:30:34.013332063 +0000 UTC m=+1099.506052559 H100 5}"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.013Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:30:34.013Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 5, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:30:34.013Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:30:34.019Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:30:34.019Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:31:34.022Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.065Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.065Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.352426, beta= 0.027622, gamma= 15.362002, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:31:34.066Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.139204"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.066Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.191266, beta=0.027705, gamma=15.353312, delta=0.000337, NIS=0.14"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.066Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.191266, beta=0.027705, gamma=15.353312, delta=0.000337, NIS=0.139204"}
{"level":"INFO","ts":"2025-11-18T18:31:34.066Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.191266, beta: 0.027705, gamma: 15.353312, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.191266,    beta: 0.027704801   },   prefillParms: {    gamma: 15.3533125,    delta: 0.00033699654   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 5,    maxBatch: 256,    cost: 500,    itlAverage: 9.31,    ttftAverage: 18.02,    load: {     arrivalRate: 2945.52,     avgInTokens: 236,     avgOutTokens: 444    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=2945.52; inTk=236; outTk=444; sol=1, sat=false, alloc={acc=H100; numRep=4; maxBatch=512; cost=400, val=-100, itl=9.684404, ttft=19.63961, rho=0.10330967, maxRPM=866.6686}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=4, limit=0, cost=400 \ntotalCost=400 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 4 512 400 9.684404 19.63961 {2945.52 236 444}}"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:31:34.075677449 +0000 UTC m=+1159.568397943 H100 4}"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.075Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:31:34.075Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 5, desired-replicas: 4, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:31:34.075Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:31:34.081Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:31:34.081Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:32:34.082Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.103Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.103Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.191266, beta= 0.027705, gamma= 15.353312, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:32:34.104Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.416710"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.104Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=7.937514, beta=0.027404, gamma=15.325103, delta=0.000337, NIS=0.42"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.104Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=7.937514, beta=0.027404, gamma=15.325103, delta=0.000337, NIS=0.416710"}
{"level":"INFO","ts":"2025-11-18T18:32:34.104Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 7.937514, beta: 0.027404, gamma: 15.325103, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.113Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.113Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.113Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.113Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.937514,    beta: 0.027403684   },   prefillParms: {    gamma: 15.325103,    delta: 0.00033698807   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.113Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.114Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 4,    maxBatch: 256,    cost: 400,    itlAverage: 9.31,    ttftAverage: 17.36,    load: {     arrivalRate: 2954.59,     avgInTokens: 225,     avgOutTokens: 446    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.114Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=2954.59; inTk=225; outTk=446; sol=1, sat=false, alloc={acc=H100; numRep=3; maxBatch=512; cost=300, val=-100, itl=9.970015, ttft=20.948757, rho=0.14290793, maxRPM=996.5864}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=3, limit=0, cost=300 \ntotalCost=300 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.114Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 3 512 300 9.970015 20.948757 {2954.59 225 446}}"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.114Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.114Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.114Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:32:34.11404713 +0000 UTC m=+1219.606767624 H100 3}"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.114Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.114Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:32:34.114Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 4, desired-replicas: 3, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:32:34.114Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:32:34.120Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:32:34.120Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:33:34.120Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.134Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.134Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 7.937514, beta= 0.027404, gamma= 15.325103, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:33:34.135Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.027927"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.135Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.006370, beta=0.027353, gamma=15.325438, delta=0.000337, NIS=0.03"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.135Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.006370, beta=0.027353, gamma=15.325438, delta=0.000337, NIS=0.027927"}
{"level":"INFO","ts":"2025-11-18T18:33:34.135Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.006370, beta: 0.027353, gamma: 15.325438, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.00637,    beta: 0.027353102   },   prefillParms: {    gamma: 15.325438,    delta: 0.00033700033   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 3,    maxBatch: 256,    cost: 300,    itlAverage: 9.01,    ttftAverage: 18.39,    load: {     arrivalRate: 1559.88,     avgInTokens: 250,     avgOutTokens: 448    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1559.88; inTk=250; outTk=448; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=-100, itl=9.560367, ttft=20.11189, rho=0.10900869, maxRPM=960.28876}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.560367 20.11189 {1559.88 250 448}}"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:33:34.144870757 +0000 UTC m=+1279.637591250 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.144Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:33:34.144Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 3, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:33:34.144Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:33:34.150Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:33:34.150Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:34:34.152Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.166Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.166Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.006370, beta= 0.027353, gamma= 15.325438, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:34:34.166Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.291456"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.166Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.217718, beta=0.027550, gamma=15.327290, delta=0.000337, NIS=0.29"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.166Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.217718, beta=0.027550, gamma=15.327290, delta=0.000337, NIS=0.291456"}
{"level":"INFO","ts":"2025-11-18T18:34:34.166Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.217718, beta: 0.027550, gamma: 15.327290, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.217718,    beta: 0.027549546   },   prefillParms: {    gamma: 15.32729,    delta: 0.0003370014   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.5,    ttftAverage: 19,    load: {     arrivalRate: 1340.78,     avgInTokens: 239,     avgOutTokens: 410    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1340.78; inTk=239; outTk=410; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.439484, ttft=18.899221, rho=0.08466398, maxRPM=929.7109}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.439484 18.899221 {1340.78 239 410}}"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:34:34.176956417 +0000 UTC m=+1339.669676911 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.176Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:34:34.177Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:34:34.177Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:34:34.182Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:34:34.182Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:35:34.183Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.196Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.196Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.217718, beta= 0.027550, gamma= 15.327290, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:35:34.196Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.031032"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.197Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.153784, beta=0.027359, gamma=15.317420, delta=0.000337, NIS=0.03"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.197Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.153784, beta=0.027359, gamma=15.317420, delta=0.000337, NIS=0.031032"}
{"level":"INFO","ts":"2025-11-18T18:35:34.197Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.153784, beta: 0.027359, gamma: 15.317420, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.206Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.206Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.206Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.153784,    beta: 0.02735905   },   prefillParms: {    gamma: 15.31742,    delta: 0.0003369952   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.88,    ttftAverage: 20.09,    load: {     arrivalRate: 1671.82,     avgInTokens: 250,     avgOutTokens: 454    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1671.82; inTk=250; outTk=454; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.898096, ttft=20.688814, rho=0.12257092, maxRPM=876.4794}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.898096 20.688814 {1671.82 250 454}}"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:35:34.20712305 +0000 UTC m=+1399.699843551 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.207Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:35:34.207Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:35:34.207Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:35:34.213Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:35:34.213Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:36:34.214Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.229Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.229Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.153784, beta= 0.027359, gamma= 15.317420, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:36:34.229Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.030387"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.229Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.082376, beta=0.027367, gamma=15.303954, delta=0.000337, NIS=0.03"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.229Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.082376, beta=0.027367, gamma=15.303954, delta=0.000337, NIS=0.030387"}
{"level":"INFO","ts":"2025-11-18T18:36:34.229Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.082376, beta: 0.027367, gamma: 15.303954, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.0823765,    beta: 0.027367268   },   prefillParms: {    gamma: 15.303954,    delta: 0.00033699503   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.49,    ttftAverage: 18.88,    load: {     arrivalRate: 1472.65,     avgInTokens: 249,     avgOutTokens: 437    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1472.65; inTk=249; outTk=437; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.508737, ttft=19.677368, rho=0.09984218, maxRPM=945.9065}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.508737 19.677368 {1472.65 249 437}}"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:36:34.239415727 +0000 UTC m=+1459.732136221 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.239Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:36:34.239Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:36:34.239Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:36:34.244Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:36:34.244Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:37:34.245Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.268Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.268Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.082376, beta= 0.027367, gamma= 15.303954, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:37:34.269Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.009583"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.269Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.045152, beta=0.027327, gamma=15.294284, delta=0.000337, NIS=0.01"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.269Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.045152, beta=0.027327, gamma=15.294284, delta=0.000337, NIS=0.009583"}
{"level":"INFO","ts":"2025-11-18T18:37:34.269Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.045152, beta: 0.027327, gamma: 15.294284, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.272Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.045152,    beta: 0.027327118   },   prefillParms: {    gamma: 15.294284,    delta: 0.0003369965   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.59,    ttftAverage: 19.25,    load: {     arrivalRate: 1480.42,     avgInTokens: 235,     avgOutTokens: 471    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1480.42; inTk=235; outTk=471; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.60034, ttft=19.801231, rho=0.109199315, maxRPM=896.45416}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.60034 19.801231 {1480.42 235 471}}"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:37:34.273215906 +0000 UTC m=+1519.765936406 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.273Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:37:34.273Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:37:34.273Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:37:34.279Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:37:34.279Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:38:34.280Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.300Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.300Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.045152, beta= 0.027327, gamma= 15.294284, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:38:34.300Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.000211"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.300Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.042262, beta=0.027326, gamma=15.288462, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.300Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.042262, beta=0.027326, gamma=15.288462, delta=0.000337, NIS=0.000211"}
{"level":"INFO","ts":"2025-11-18T18:38:34.300Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.042262, beta: 0.027326, gamma: 15.288462, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.309Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.042262,    beta: 0.027326236   },   prefillParms: {    gamma: 15.288462,    delta: 0.0003369983   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 9.49,    ttftAverage: 19.06,    load: {     arrivalRate: 1532.68,     avgInTokens: 229,     avgOutTokens: 428    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=1532.68; inTk=229; outTk=428; sol=1, sat=false, alloc={acc=H100; numRep=2; maxBatch=512; cost=200, val=0, itl=9.490776, ttft=19.37924, rho=0.10157849, maxRPM=987.82733}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=2, limit=0, cost=200 \ntotalCost=200 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 2 512 200 9.490776 19.37924 {1532.68 229 428}}"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:38:34.310194441 +0000 UTC m=+1579.802914942 H100 2}"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.310Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:38:34.310Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 2, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:38:34.310Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:38:34.315Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:38:34.315Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:39:34.317Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.330Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.330Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.042262, beta= 0.027326, gamma= 15.288462, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:39:34.330Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.014350"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.330Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.096007, beta=0.027171, gamma=15.295763, delta=0.000337, NIS=0.01"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.330Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.096007, beta=0.027171, gamma=15.295763, delta=0.000337, NIS=0.014350"}
{"level":"INFO","ts":"2025-11-18T18:39:34.330Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.096007, beta: 0.027171, gamma: 15.295763, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.096007,    beta: 0.027171168   },   prefillParms: {    gamma: 15.295763,    delta: 0.0003370011   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 2,    maxBatch: 256,    cost: 200,    itlAverage: 8.77,    ttftAverage: 17.71,    load: {     arrivalRate: 709.76,     avgInTokens: 245,     avgOutTokens: 449    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=709.76; inTk=245; outTk=449; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=-100, itl=9.496978, ttft=19.552904, rho=0.098751806, maxRPM=920.7677}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.496978 19.552904 {709.76 245 449}}"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:39:34.334726643 +0000 UTC m=+1639.827447143 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.334Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:39:34.334Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 2, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:39:34.334Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:39:34.339Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:39:34.339Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:40:34.341Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.363Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.363Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.096007, beta= 0.027171, gamma= 15.295763, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:40:34.364Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.001269"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.364Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.109001, beta=0.027184, gamma=15.302636, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.364Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.109001, beta=0.027184, gamma=15.302636, delta=0.000337, NIS=0.001269"}
{"level":"INFO","ts":"2025-11-18T18:40:34.364Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.109001, beta: 0.027184, gamma: 15.302636, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.109001,    beta: 0.027184268   },   prefillParms: {    gamma: 15.302636,    delta: 0.00033700137   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.07,    ttftAverage: 18.54,    load: {     arrivalRate: 570.34,     avgInTokens: 243,     avgOutTokens: 396    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=570.34; inTk=243; outTk=396; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.066278, ttft=18.18639, rho=0.06682496, maxRPM=1035.9435}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.066278 18.18639 {570.34 243 396}}"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:40:34.373511421 +0000 UTC m=+1699.866231915 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.373Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:40:34.373Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:40:34.373Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:40:34.380Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:40:34.380Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:41:34.381Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.394Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.394Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.109001, beta= 0.027184, gamma= 15.302636, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:41:34.395Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.011305"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.395Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.073721, beta=0.027014, gamma=15.289079, delta=0.000337, NIS=0.01"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.395Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.073721, beta=0.027014, gamma=15.289079, delta=0.000337, NIS=0.011305"}
{"level":"INFO","ts":"2025-11-18T18:41:34.395Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.073721, beta: 0.027014, gamma: 15.289079, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.073721,    beta: 0.027013618   },   prefillParms: {    gamma: 15.289079,    delta: 0.00033699552   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.69,    ttftAverage: 19.38,    load: {     arrivalRate: 771.08,     avgInTokens: 235,     avgOutTokens: 474    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=771.08; inTk=235; outTk=474; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.700607, ttft=20.058508, rho=0.115673184, maxRPM=887.9209}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.700607 20.058508 {771.08 235 474}}"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:41:34.404628187 +0000 UTC m=+1759.897348687 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.404Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:41:34.404Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:41:34.404Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:41:34.412Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:41:34.412Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:42:34.413Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.428Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.428Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.073721, beta= 0.027014, gamma= 15.289079, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:42:34.429Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.000883"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.429Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.063533, beta=0.027002, gamma=15.282167, delta=0.000337, NIS=0.00"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.429Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.063533, beta=0.027002, gamma=15.282167, delta=0.000337, NIS=0.000883"}
{"level":"INFO","ts":"2025-11-18T18:42:34.429Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.063533, beta: 0.027002, gamma: 15.282167, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.063533,    beta: 0.02700183   },   prefillParms: {    gamma: 15.282167,    delta: 0.0003369979   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.68,    ttftAverage: 19.55,    load: {     arrivalRate: 724.95,     avgInTokens: 228,     avgOutTokens: 503    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=724.95; inTk=228; outTk=503; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.682856, ttft=19.890059, rho=0.11517747, maxRPM=841.7295}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.682856 19.890059 {724.95 228 503}}"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:42:34.439564932 +0000 UTC m=+1819.932285426 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.439Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:42:34.439Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:42:34.439Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:42:34.445Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:42:34.445Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:43:34.446Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.459Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.459Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.063533, beta= 0.027002, gamma= 15.282167, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:43:34.459Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.022266"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.459Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.127117, beta=0.026952, gamma=15.277336, delta=0.000337, NIS=0.02"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.459Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.127117, beta=0.026952, gamma=15.277336, delta=0.000337, NIS=0.022266"}
{"level":"INFO","ts":"2025-11-18T18:43:34.459Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.127117, beta: 0.026952, gamma: 15.277336, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.127117,    beta: 0.026951624   },   prefillParms: {    gamma: 15.277336,    delta: 0.0003369991   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.47,    ttftAverage: 19.11,    load: {     arrivalRate: 703.36,     avgInTokens: 245,     avgOutTokens: 434    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=703.36; inTk=245; outTk=434; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.45345, ttft=19.340483, rho=0.09416334, maxRPM=944.47644}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.45345 19.340483 {703.36 245 434}}"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:43:34.46971567 +0000 UTC m=+1879.962436164 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.469Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:43:34.469Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:43:34.469Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:43:34.475Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:43:34.475Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:44:34.476Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.490Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.490Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.127117, beta= 0.026952, gamma= 15.277336, delta= 0.000337"}
{"level":"INFO","ts":"2025-11-18T18:44:34.491Z","msg":"Tuner validation succeeded for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler, server ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler - New NIS: 0.045389"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.491Z","msg":"Model tuner results: model=unsloth/Meta-Llama-3.1-8B, accelerator=H100, alpha=8.045487, beta=0.026829, gamma=15.267756, delta=0.000337, NIS=0.05"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.491Z","msg":"Updated tuner status for variant ms-inference-scheduling-llm-d-modelservice-decode: alpha=8.045487, beta=0.026829, gamma=15.267756, delta=0.000337, NIS=0.045389"}
{"level":"INFO","ts":"2025-11-18T18:44:34.491Z","msg":"Tuned performance parameters: variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler - alpha: 8.045487, beta: 0.026829, gamma: 15.267756, delta: 0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  },  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 8.045487,    beta: 0.026829418   },   prefillParms: {    gamma: 15.2677555,    delta: 0.00033699715   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 9.5,    ttftAverage: 18.84,    load: {     arrivalRate: 718.72,     avgInTokens: 217,     avgOutTokens: 473    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=718.72; inTk=217; outTk=473; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=9.523091, ttft=19.295229, rho=0.105613336, maxRPM=909.372}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 9.523091 19.295229 {718.72 217 473}}"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:44:34.500656623 +0000 UTC m=+1939.993377123 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.500Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:44:34.500Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:44:34.500Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:44:34.506Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:44:34.506Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:45:34.508Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.520Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.520Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.045487, beta= 0.026829, gamma= 15.267756, delta= 0.000337"}
{"level":"WARN","ts":"2025-11-18T18:45:34.520Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-18T18:45:34.520Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=8.045487, beta=0.026829, gamma=15.267756, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.520Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.520Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  },  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.520Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.520Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.520Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.521Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.521Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=7.514, ttft=15.415337, rho=0, maxRPM=676453.25}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.521Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.514 15.415337 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.521Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.521Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.521Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:45:34.52107437 +0000 UTC m=+2000.013794869 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.521Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.521Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:45:34.521Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:45:34.521Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:45:34.526Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:45:34.526Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
{"level":"INFO","ts":"2025-11-18T18:46:34.527Z","msg":"Found SLO for model - model: unsloth/Meta-Llama-3.1-8B, class: Premium, slo-tpot: 10, slo-ttft: 1000"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Experimental model tuner is enabled globally (EXPERIMENTAL_MODEL_TUNER_ENABLED=true), tuning model performance parameters for active VAs"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Using state vals from VA status to tune variant ms-inference-scheduling-llm-d-modelservice-decode: alpha= 8.045487, beta= 0.026829, gamma= 15.267756, delta= 0.000337"}
{"level":"WARN","ts":"2025-11-18T18:46:34.541Z","msg":"Failed to tune server for variant ms-inference-scheduling-llm-d-modelservice-decode - error: failed to get/create tuner: failed to create tuner: invalid environment: &{0 0 0 256 0 0 1}. Using fallback parameters."}
{"level":"INFO","ts":"2025-11-18T18:46:34.541Z","msg":"Keeping previously tuned parameters for variant ms-inference-scheduling-llm-d-modelservice-decode/llm-d-inference-scheduler: alpha=8.045487, beta=0.026829, gamma=15.267756, delta=0.000337"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"System data prepared for optimization: - { count: []}"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"System data prepared for optimization: - { accelerators: [  {   name: A100,   type: NVIDIA-A100-PCIE-80GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 40  },  {   name: G2,   type: Intel-Gaudi-2-96GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 23  },  {   name: H100,   type: NVIDIA-H100-80GB-HBM3,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 100  },  {   name: L40S,   type: NVIDIA-L40S,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 32  },  {   name: MI300X,   type: AMD-MI300X-192GB,   multiplicity: 1,   memSize: 0,   memBW: 0,   power: {    idle: 0,    full: 0,    midPower: 0,    midUtil: 0   },   cost: 65  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"System data prepared for optimization: - { serviceClasses: [  {   name: Freemium,   priority: 10,   modelTargets: [    {     model: ibm/granite-13b,     slo-itl: 200,     slo-ttft: 2000,     slo-tps: 0    },    {     model: meta/llama0-7b,     slo-itl: 150,     slo-ttft: 1500,     slo-tps: 0    }   ]  },  {   name: Premium,   priority: 1,   modelTargets: [    {     model: default/default,     slo-itl: 24,     slo-ttft: 500,     slo-tps: 0    },    {     model: meta/llama0-70b,     slo-itl: 80,     slo-ttft: 500,     slo-tps: 0    },    {     model: unsloth/Meta-Llama-3.1-8B,     slo-itl: 10,     slo-ttft: 1000,     slo-tps: 0    }   ]  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"System data prepared for optimization: - { models: [  {   name: unsloth/Meta-Llama-3.1-8B,   acc: L40S,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 22.619,    beta: 0.181   },   prefillParms: {    gamma: 226.19,    delta: 0.018   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: H100,   accCount: 1,   maxBatchSize: 512,   atTokens: 0,   decodeParms: {    alpha: 7.47,    beta: 0.044   },   prefillParms: {    gamma: 15.415,    delta: 0.000337   }  },  {   name: unsloth/Meta-Llama-3.1-8B,   acc: A100,   accCount: 1,   maxBatchSize: 4,   atTokens: 0,   decodeParms: {    alpha: 20.58,    beta: 0.41   },   prefillParms: {    gamma: 5.2,    delta: 0.1   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"System data prepared for optimization: - { optimizer: {  unlimited: true,  delayedBestEffort: false,  saturationPolicy:  }}"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"System data prepared for optimization: - { servers: [  {   name: ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler,   class: Premium,   model: unsloth/Meta-Llama-3.1-8B,   keepAccelerator: true,   minNumReplicas: 1,   maxBatchSize: 512,   currentAlloc: {    accelerator: H100,    numReplicas: 1,    maxBatch: 256,    cost: 100,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   },   desiredAlloc: {    accelerator: ,    numReplicas: 0,    maxBatch: 0,    cost: 0,    itlAverage: 0,    ttftAverage: 0,    load: {     arrivalRate: 0,     avgInTokens: 0,     avgOutTokens: 0    }   }  } ]}"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Optimization solution - system: Solution: \ns=ms-inference-scheduling-llm-d-modelservice-decode:llm-d-inference-scheduler; c=Premium; m=unsloth/Meta-Llama-3.1-8B; rate=0; inTk=0; outTk=0; sol=1, sat=false, alloc={acc=H100; numRep=1; maxBatch=512; cost=100, val=0, itl=7.514, ttft=15.415337, rho=0, maxRPM=676453.25}; slo-itl=10, slo-ttft=1000, slo-tps=0 \nAllocationByType: \nname=NVIDIA-H100-80GB-HBM3, count=1, limit=0, cost=100 \ntotalCost=100 \n"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Setting accelerator name: Name=H100, allocationData={H100 1 512 100 7.514 15.415337 {0 0 0}}"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Optimization completed successfully, emitting optimization metrics"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Optimized allocation map - numKeys: 1, updateList_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Optimized allocation entry - key: ms-inference-scheduling-llm-d-modelservice-decode, value: {2025-11-18 18:46:34.541793763 +0000 UTC m=+2060.034514256 H100 1}"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Optimization metrics emitted, starting to process variants - variant_count: 1"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.541Z","msg":"Processing variant - index: 0, variantAutoscaling-name: ms-inference-scheduling-llm-d-modelservice-decode, namespace: llm-d-inference-scheduler, has_optimized_alloc: true"}
{"level":"INFO","ts":"2025-11-18T18:46:34.541Z","msg":"EmitReplicaMetrics completed - variant: ms-inference-scheduling-llm-d-modelservice-decode, current-replicas: 1, desired-replicas: 1, accelerator: H100"}
{"level":"INFO","ts":"2025-11-18T18:46:34.541Z","msg":"Successfully emitted optimization signals for external autoscalers - variant: ms-inference-scheduling-llm-d-modelservice-decode"}
{"level":"DEBUG","ts":"2025-11-18T18:46:34.547Z","msg":"Completed variant processing loop"}
{"level":"INFO","ts":"2025-11-18T18:46:34.547Z","msg":"Reconciliation completed - variants_processed: 1, optimization_successful: true"}
